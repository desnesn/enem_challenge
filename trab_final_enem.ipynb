{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cX_0AoJKwHv",
        "outputId": "ada18396-0963-4663-a187-de7da0e5f0dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.9/dist-packages (1.7.2)\n"
          ]
        }
      ],
      "source": [
        "###########\n",
        "# IMPORTS #\n",
        "###########\n",
        "\n",
        "!pip install openai\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torchinfo\n",
        "\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer  # Or BertTokenizer\n",
        "from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n",
        "from transformers import AutoModel  # or BertModel, for BERT without pretraining heads\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import pipeline\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "#from urllib.parse import urlparse\n",
        "\n",
        "import json\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import seaborn as sn\n",
        "import time\n",
        "import torch\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2e2i6vkLjsv",
        "outputId": "8d05b18a-f2ea-46df-faa4-ac717bad2c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYkJFXyP6v9X"
      },
      "outputs": [],
      "source": [
        "#######\n",
        "# GPU #\n",
        "#######\n",
        "\n",
        "# ! pip install accelerate\n",
        "# from accelerate import Accelerator\n",
        "\n",
        "# # use_fp16 = True\n",
        "# use_fp16 = False\n",
        "\n",
        "# if torch.cuda.is_available(): \n",
        "#     dev = \"cuda:0\"\n",
        "#     accelerator = Accelerator(mixed_precision='fp16') if use_fp16 else Accelerator(mixed_precision='no')\n",
        "# else:\n",
        "#     dev = \"cpu\"\n",
        "#     accelerator = Accelerator(mixed_precision='no')\n",
        "\n",
        "# device = accelerator.device\n",
        "# print('Using {}'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StRBb8yP-JLP"
      },
      "outputs": [],
      "source": [
        "########\n",
        "# TIME #\n",
        "########\n",
        "\n",
        "# start = time.time()\n",
        "\n",
        "# # CODE TO BE TIMED #\n",
        "\n",
        "# elapsed_time = time.time() - start\n",
        "\n",
        "# et = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
        "# print(f\"Elapsed time: {et}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbwokEBs6r1H"
      },
      "outputs": [],
      "source": [
        "###################\n",
        "# SAVE/LOAD MODEL #\n",
        "###################\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# def save_model(path, model, step):\n",
        "#     if os.path.exists(path):\n",
        "#         save_model_path = path\n",
        "#         torch.save({'step': step,\n",
        "#                     'model_state_dict': model.cpu().state_dict()\n",
        "#         }, save_model_path)\n",
        "\n",
        "# def load_model(path, model):\n",
        "#     if os.path.exists(path):\n",
        "#         checkpoint = torch.load(path)\n",
        "#         model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "#     return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTlzdDxD_N-j"
      },
      "outputs": [],
      "source": [
        "################\n",
        "# DATA CLASSES #\n",
        "################\n",
        "\n",
        "class ENEM_CLASS():\n",
        "    def __init__(self, link):\n",
        "\n",
        "        file_name = !basename {link}\n",
        "\n",
        "        if not os.path.exists(\"/content/\" + file_name[0]):\n",
        "            ! wget -q -O {file_name[0]} {link}\n",
        "            ! unzip -qq -o {file_name[0]}\n",
        "\n",
        "        self.enem_version = []\n",
        "        self.questions = []\n",
        "        self.headers = []\n",
        "        self.statements = []\n",
        "        self.answers = []\n",
        "\n",
        "        for filename in sorted(os.listdir('/content')):\n",
        "            if filename.endswith(\".xml\"):\n",
        "\n",
        "                # print(filename)\n",
        "                # self.tree = ET.parse('2009-1.xml')\n",
        "\n",
        "                tree = ET.parse(filename)\n",
        "                root = tree.getroot()\n",
        "\n",
        "                for question, header, statement, answers in zip(root.iter('question'),\n",
        "                                                                root.iter('header'),\n",
        "                                                                root.iter('statement'),\n",
        "                                                                root.iter('answers')):\n",
        "                    \n",
        "                    # Based on the question dict, choose which questions will go into the data :\n",
        "                    # {'CE': 'No', 'DS': 'No', 'EK': 'Yes', 'IC': 'No', 'MR': 'No', 'TC': 'Yes', 'id': '90', 'image': 'No'}\n",
        "                    #if question.attrib['image'] == 'No': # or (question[''] == 'YES') ???\n",
        "                    if question.attrib['IC'] == 'No' and  question.attrib['CE'] == 'No' and question.attrib['MR'] == 'No': \n",
        "                    #if True:\n",
        "\n",
        "                        self.enem_version.append(os.path.splitext(filename)[0])\n",
        "\n",
        "                        # Pergunta de imagens tem headers e alternativas vazias? - if acima exclui essas questões!\n",
        "                        # header_text = re.sub(r'\\n', '', header.text) if header.text else \"\"\n",
        "                        # statement_text = re.sub(r'\\n', '', statement.text) if statement.text else \"\"\n",
        "                        # option_text = re.sub(r'\\n', '', option.text) if option.text else \"\"\n",
        "\n",
        "                        # Tirar \\n no meio do texto\n",
        "                        header_text = re.sub(r'\\n', '', header.text)\n",
        "                        statement_text = re.sub(r'\\n', '', statement.text)\n",
        "\n",
        "                        # Tirar espaços extras do início, fim e do meio ♫\n",
        "                        header_text = re.sub(r\"^\\s+|\\s+$\", '', header_text)\n",
        "                        header_text = re.sub(r\"[\\ ]{2}\", ' ', header_text)\n",
        "\n",
        "                        statement_text = re.sub(r\"^\\s+|\\s+$\", '', statement_text)\n",
        "                        statement_text = re.sub(r\"[\\ ]{2}\", ' ', statement_text)\n",
        "\n",
        "                        self.questions.append(question.attrib)\n",
        "                        self.headers.append(header_text)\n",
        "                        self.statements.append(statement_text)\n",
        "\n",
        "                        options = []\n",
        "                        options_text = []\n",
        "\n",
        "                        for option in list(answers):#answers.getchildren():\n",
        "\n",
        "                            options.append(option.attrib)\n",
        "\n",
        "                            # Tirar \\n no meio do texto\n",
        "                            option_text = re.sub(r'\\n', '', option.text)\n",
        "\n",
        "                            # Tirar espaços extras do início, fim e do meio ♫\n",
        "                            option_text = re.sub(r\"^\\s+|\\s+$\", '', option_text)\n",
        "                            option_text = re.sub(r\"[\\ ]{2}\", ' ', option_text)\n",
        "\n",
        "                            options_text.append(option_text)\n",
        "\n",
        "                        self.answers.append((options, options_text))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.enem_version[idx], self.questions[idx], self.headers[idx], self.statements[idx], self.answers[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def print_question(self, idx):\n",
        "        \n",
        "        header = \"Questão \" + str(idx)\n",
        "        print()\n",
        "        print(\"#\" * (len(header)+4))\n",
        "        print(f'# {header} #')\n",
        "        print(\"#\" * (len(header)+4))\n",
        "        print()\n",
        "\n",
        "        print(f'Ano/Versão: {self.enem_version[idx]}\\n')\n",
        "\n",
        "        # print(f'Cabeçalho:\\n{self.headers[idx]}\\n')\n",
        "        print('Cabeçalho:\\n')\n",
        "        header = self.headers[idx].split(' ')\n",
        "        for i, tok in enumerate(header):\n",
        "            if ((i % 15 == 0) and (i != 0)) and (i != (len(header)-1)):\n",
        "                print(tok, end='\\n')\n",
        "            else:\n",
        "                print(tok, end=' ')\n",
        "        print('\\n')\n",
        "    \n",
        "        # print(f'Enunciado:\\n{self.statements[idx]}\\n')\n",
        "        print('Enunciado:\\n')\n",
        "        statement = self.statements[idx].split(' ')\n",
        "        for i, tok in enumerate(statement):\n",
        "            if ((i % 15 == 0) and (i != 0)) and (i != (len(statement)-1)):\n",
        "                print(tok, end='\\n')\n",
        "            else:\n",
        "                print(tok, end=' ')\n",
        "        print('\\n')\n",
        "\n",
        "        print(f'Alternativas:')\n",
        "\n",
        "        for alternative, answer in zip(self.answers[idx][0], self.answers[idx][1]):\n",
        "            if (alternative['correct'] == 'No'):\n",
        "                print(f\" {alternative['id']}  - {answer}\")\n",
        "            else:\n",
        "                print(f\"[{alternative['id']}] - {answer}\")\n",
        "\n",
        "    def print_all_questions(self):\n",
        "        for idx in range(len(self)):\n",
        "            self.print_question(idx)\n",
        "            print()\n",
        "\n",
        "    def get_right_alternative(self, idx):\n",
        "        for alternative, answer in zip(self.answers[idx][0], self.answers[idx][1]):\n",
        "            if (alternative['correct'] == 'Yes'):\n",
        "                return alternative['id'], answer\n",
        "    \n",
        "    def get_answers(self, idx):\n",
        "        return list(zip(*ENEM.answers))[1][idx]\n",
        "\n",
        "    def get_question_year(self, idx):\n",
        "        return self.enem_version[idx]\n",
        "\n",
        "class ENEM_data_CLASS(torch.utils.data.Dataset):\n",
        "    def __init__(self, ENEM, tokenizer, max_length):\n",
        "        super(ENEM_data_CLASS, self).__init__()\n",
        "\n",
        "        self.ENEM = ENEM\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.headers_tokenized = tokenizer(self.ENEM.headers, max_length = self.max_length, padding = True, truncation = True)\n",
        "        self.statements_tokenized = tokenizer(self.ENEM.statements, max_length = self.max_length, padding = True, truncation = True)\n",
        "        \n",
        "        self.headers_ids = self.headers_tokenized['input_ids']\n",
        "        self.headers_masks = self.headers_tokenized['attention_mask']\n",
        "\n",
        "        self.statements_ids = self.statements_tokenized['input_ids']\n",
        "        self.statements_masks = self.statements_tokenized['attention_mask']\n",
        "\n",
        "        self.answers = []\n",
        "        for idx in range(len(self.ENEM.answers)):\n",
        "            options_text = list(zip(*ENEM.answers))[1][idx]\n",
        "            options_tokenized = tokenizer(options_text, max_length = max_length, padding = True, truncation = True)\n",
        "\n",
        "            options_ids = options_tokenized['input_ids']\n",
        "            options_masks = options_tokenized['attention_mask']\n",
        "\n",
        "            self.answers.append((options_ids, options_masks))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ENEM)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.headers_ids[idx],self.headers_masks[idx]), (self.statements_ids[idx], self.statements_masks[idx]), (self.answers[idx][0], self.answers[idx][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "3b4s5nrt9i-Y",
        "outputId": "b5a1802b-8171-415c-ef8a-3936b3a9c078"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-378a140bc71c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.ime.usp.br/~ddm/project/enem/ENEMdataset.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mENEM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENEM_CLASS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Amount of questions in model: {len(ENEM)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6bdaa5a17fa1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, link)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0;31m# Tirar \\n no meio do texto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                         \u001b[0moption_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0;31m# Tirar espaços extras do início, fim e do meio ♫\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ],
      "source": [
        "##############\n",
        "# ENEM_CLASS #\n",
        "##############\n",
        "\n",
        "link = \"https://www.ime.usp.br/~ddm/project/enem/ENEMdataset.zip\"\n",
        "\n",
        "ENEM = ENEM_CLASS(link)\n",
        "\n",
        "print(f'Amount of questions in model: {len(ENEM)}')\n",
        "#ENEM.print_all_questions()\n",
        "\n",
        "# QUESTION 89 #\n",
        "\n",
        "ENEM.print_question(89)\n",
        "\n",
        "print()\n",
        "print(f'Get all items from 89:')\n",
        "print(ENEM.__getitem__(89))\n",
        "print()\n",
        "print(f'Get item 4 from 89:')\n",
        "print(ENEM.__getitem__(89)[4])\n",
        "print()\n",
        "print(f'Get right answer from 89')\n",
        "print(ENEM.get_right_alternative(89))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "bb27306e8f4045e6892b363e5601921a",
            "b28e9e8c4d234a76b02be0063072f4fb",
            "8bb8297e19bd49e5b1c211a71d8fb978",
            "afe5b13132e9458ab3f6619165122be9",
            "b646376fb3654b4cb4cf588f0cde7b44",
            "90937e682abf42efa5eca89b9a13f5e2",
            "e6cab4f9c4654b5d9759e706bcccafab",
            "bc36f4504f0b43c98d1c92b9d7aca71b",
            "f621995884a3434491b374f6388f621a",
            "065642e84f8f4b0dae0606379b3fb32a",
            "e243d695f2424d87b70af1bdc63a50a5",
            "7cfaf560bac043ee842f5e3e19e3528c",
            "2f7ad21569014aa9911bc5a9cd5ac619",
            "2a7b77d0bc5d422d961230bb2b6d64ba",
            "1a74d7070fd8496990f13095d384e866",
            "929d0753f9fd4f4185ab3d19a9452070",
            "1a64ca82a7f048dda3b2aec0c4da2b1e",
            "8955a4ed74b34454bf9eeab583260389",
            "2a76ddf04c6645c5bf16a555d1113239",
            "da5bee844381412b9c96dafc333e0f65",
            "98e3efb783824bc0a63b2fa242ad0399",
            "bc5390fc195e4f998c7e7b2ddf0dc1fb",
            "cab87a16d2cc44b4a1ab37b4941e3bed",
            "9cff9caa851c41e6a7c5d579dcba3426",
            "4d28f433297649b8b483c3d26e683566",
            "3906192cfc624400aa5fa0d0154ff8d6",
            "cadd01cddf824d1fb95fb5e9f1ef34d7",
            "f3b28c6f77aa4fb68f70c23c148926e6",
            "c9dde88d906c4dce9b7bc9fa22c474d7",
            "6d136816c2fd4b0faf4b934780fb2ca4",
            "9a8aa4ecc171490cbf39615f76a377a2",
            "d44b65ada86444f18922a8c7e5edeab3",
            "17c995187b2b45fc969cc1b8bcccbe5e",
            "5ae7699cfa9d4cdba7ec026d5d045ff7",
            "f0fbe88c9acd4729813b53af70d2b16f",
            "e5899dd43cd047debe8d9d05c7689326",
            "5be5d0a44e1641b3a65c55276de0e348",
            "3cb5a6a5e94b451f9e9e0ec61727d41b",
            "683ef738a5a2448da31aba165e50183a",
            "a761cd596ebd417cb90542e72d3c9d0d",
            "9853673e032c40e28b940c964ac52fb5",
            "2cbe32b4dc33422c8c87c035f7cd339a",
            "41b70a985be34a2792ccad4cb16e2df5",
            "1ba9f528fea743b587368c9fd5603352",
            "72a9b9258360486983d94214e654d8cf",
            "47648135613d4fee811510b6e36f6a2f",
            "75b007adbf9a42fbbb9ddb9df34a7ba0",
            "7350153aa8d44838863af90dc64ac8be",
            "f9523f41c3fe4cf0b8eae100e0659e3c",
            "5e24b4cfa9504a008bd9326207bd7520",
            "e14be2e83fae4b71abd9d986a5099a6c",
            "52848dd55d26413c9a5b61540f179621",
            "baede60fa3e74106925f0b76366838e0",
            "5bdce323583040b3a3d57b1ed5d33f3c",
            "3aaf57fa50eb4d2bba9e33fc63df46bc",
            "782595678e534938806bd68d139ddb34",
            "510e52311bd042778c0889a6778303e5",
            "8d2fb381b7964525812cc927fb24612a",
            "112681987e034363adc44ebd6b1e978a",
            "72e1e5a56ea44f2f8ddb9fdaa3e3fb51",
            "b65db33ef46e4ebcab3f4325d1ab525e",
            "4422bbca32bb4027b26a41fbb9fac831",
            "4995ea22efdb4e7199c648438bb96bdc",
            "262977a647f9445aa08fd3e99a215ab2",
            "a5ae4a6c591f4adfb02687c82ce19e98",
            "86bd839a8e66445aa7925fcefc168073"
          ]
        },
        "id": "loDE5bL4cQuk",
        "outputId": "e331a9f4-c1f2-4ae8-b780-9433ecb22e3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb27306e8f4045e6892b363e5601921a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cfaf560bac043ee842f5e3e19e3528c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cab87a16d2cc44b4a1ab37b4941e3bed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ae7699cfa9d4cdba7ec026d5d045ff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72a9b9258360486983d94214e654d8cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "782595678e534938806bd68d139ddb34"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#########\n",
        "# MODEL #\n",
        "#########\n",
        "\n",
        "model = AutoModelForPreTraining.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "ykKU6Y6b6XSL"
      },
      "outputs": [],
      "source": [
        "###################\n",
        "# ENEM_DATA_CLASS #\n",
        "###################\n",
        "\n",
        "max_length = 512\n",
        "batch_size = 32\n",
        "\n",
        "ENEM_data = ENEM_data_CLASS(ENEM, tokenizer, max_length)\n",
        "\n",
        "ENEM_data.answers\n",
        "\n",
        "ENEM_dataloader = torch.utils.data.DataLoader(ENEM_data, batch_size=batch_size, drop_last = True, shuffle = True)\n",
        "\n",
        "################\n",
        "# TEST DECODER #\n",
        "################\n",
        "\n",
        "# ENEM.print_question(89)\n",
        "\n",
        "# print()\n",
        "# print(ENEM_data.__getitem__(89))\n",
        "# print()\n",
        "\n",
        "# print(tokenizer.decode([101,   123,  1803,   125,  6688,  1495,   117,   221,   179,   146,\n",
        "#             2270,   366,  5341,   298,  5620,  1547,  9573,   117,  5084,   229,\n",
        "#             1241,   984,   117,   834, 10144,   159,   259, 14642, 11335,   119,\n",
        "#              102]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UalZNZlafVoZ"
      },
      "outputs": [],
      "source": [
        "#@title Hello World to OpenAI\n",
        "\n",
        "###############\n",
        "# HELLO WORLD #\n",
        "###############\n",
        "\n",
        "# # Considerando a questão complete a alternativa correta\n",
        "# # question = \"Responda a seguinte pergunta de multipla escolha:\\n\\nA atmosfera  terrestre  é  composta  pelos  gases nitrogênio (N2) e oxigênio (O2), que somam cerca de 99%, e por gases traços, entre eles o gás carbônico (CO2), vapor de água (H2O), metano (CH4), ozônio (O3) e o óxido nitroso (N2O), que compõem o restante 1% do ar que respiramos. Os  gases  traços,  por  serem  constituídos  por  pelo  menos três  átomos,  conseguem  absorver  o  calor  irradiado  pela Terra, aquecendo o planeta. Esse fenômeno, que acontece há bilhões de anos, é chamado de efeito estufa. A partir da Revolução  Industrial  (século  XIX),  a  concentração  de gases  traços  na  atmosfera,  em  particular  o CO2,  tem aumentado significativamente, o que resultou no aumento da  temperatura  em  escala  global.  Mais  recentemente, outro fator tornou-se diretamente envolvido no aumento da concentração de CO2 na atmosfera: o desmatamento.  BROWN, I. F.; ALECHANDRE, A. S. Conceitos básicos sobre clima,  carbono, florestas e comunidades. A.G. Moreira & S.  Schwartzman. As mudanças climáticas globais e os  ecossistemas brasileiros. Brasília: Instituto de Pesquisa Ambiental da Amazônia, 2000 (adaptado).\\n\\nConsiderando  o texto,  uma  alternativa  viável  para combater o efeito estufa é:\\n\\nA. reduzir  o  calor irradiado  pela  Terra  mediante  a substituição da produção primária pela industrialização refrigerada.\\nB. promover a queima da biomassa vegetal, responsável pelo  aumento  do  efeito  estufa  devido  à  produção  de CH4.\\nC. reduzir  o  desmatamento,  mantendo-se,  assim,  o potencial  da  vegetação  em  absorver  o  CO2  da atmosfera.\\nD. aumentar  a  concentração  atmosférica  de  H2O, molécula  capaz  de  absorver  grande  quantidade  de calor.\\nE. remover  moléculas  orgânicas  polares  da  atmosfera, diminuindo a capacidade delas de reter calor.\\n\\nAlternativa correta: C. reduzir  o  desmatamento,  mantendo-se,  assim,  o potencial  da  vegetação  em  absorver  o  CO2  da atmosfera.\\n\\nResponda a seguinte pergunta de multipla escolha:\\n\\nEstima-se  que  haja  atualmente  no  mundo  40 milhões de pessoas infectadas pelo HIV (o vírus que causa a  AIDS),  sendo  que  as taxas  de  novas infecções continuam  crescendo,  principalmente  na  África,  Ásia  e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV  teria  imenso  impacto,  pois  salvaria  milhões  de  vidas. Certamente  seria  um  marco  na  história  planetária  e também  uma  esperança  para  as  populações  carentes  de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nUma vacina eficiente contra o HIV deveria:\\n\\nA. induzir  a  imunidade,  para  proteger  o  organismo  da contaminação viral.\\nB. ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\nC. produzir  antígenos  capazes  de  se  ligarem  ao  vírus, impedindo  que  este  entre  nas  células  do  organismo humano.\\nD. ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\nE. estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nAlternativa correta:\\n\"\n",
        "# # question = \"Responda a seguinte pergunta de multipla escolha:\\n\\nQual a capital do Brasil?\\n\\nA. A capital é Brasília.\\nB. A capital é Buenos Aires.\\nC. A capital é os Estados Unidos.\\nD. A capital é Lima.\\nE. A capital é Colombia.\\n\\nAlternativa correta: A. A capital é Brasília.\\n\\nResponda a seguinte pergunta de multipla escolha:\\n\\nQual a capital do Estados Unidos?\\n\\nA. A capital é Toronto.\\nB. A capital é Lima.\\nC. A capital é os Estados Unidos.\\nD. A capital é Washington-DC.\\nE. A capital é Buenos Aires.\\n\\nAlternativa correta:\\n\"\n",
        "\n",
        "# question = \"Responda a seguinte pergunta de multipla escolha:\\n\\nQual a capital da Argentina?\\n\\nA. A capital é Brasília.\\nB. A capital é Buenos Aires.\\nC. A capital é os Estados Unidos.\\nD. A capital é Lima.\\nE. A capital é Colombia.\\n\\nAlternativa correta:\\n\"\n",
        "\n",
        "# alternative, text, alternatives_evaluation = OPENAI.prompt_openai(question)\n",
        "\n",
        "# print(question)\n",
        "# print(f'Alternativa correta do modelo: {alternative}')\n",
        "# print(f'Text da alternativa do modelo: {text}')\n",
        "# print()\n",
        "# print(alternatives_evaluation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qAnne6WrMma7"
      },
      "outputs": [],
      "source": [
        "#@title 0-shot - v0 - WORKS\n",
        "# ######################\n",
        "# # OPENAI MODEL SETUP #\n",
        "# ######################\n",
        "\n",
        "# # BACKUP - PLAIN 0-SHOT\n",
        "\n",
        "# class OPENAI_CLASS():\n",
        "#     def __init__(self, api_key, model, ENEM):\n",
        "\n",
        "#         self.ENEM = ENEM\n",
        "\n",
        "#         self.model = model\n",
        "\n",
        "#         self.openai = openai\n",
        "#         self.openai.api_key = api_key\n",
        "\n",
        "#     def get_alternatives_positions(self, text):\n",
        "\n",
        "#         alternatives = []\n",
        "\n",
        "#         # print(text)\n",
        "\n",
        "#         for i in range(len(text)-1):\n",
        "\n",
        "#             if ( re.findall(\"\\n{1}\", text[i-1]) and\n",
        "#                  re.findall(\"^[ABCDE]{1}\", text[i]) and\n",
        "#                  re.findall(\"\\.{1}\", text[i+1]) ):\n",
        "\n",
        "#                 j = i\n",
        "\n",
        "#                 # print(f'len(text) = {len(text)} | i = {i} | text[i-1]: {repr(text[i-1])} | text[i]: {text[i]} | text[i+1]: {text[i+1]}')\n",
        "\n",
        "#                 while text[j] != \"\\n\" and text[j] != '<|endoftext|>':\n",
        "#                     j += 1\n",
        "\n",
        "#                 alternatives.append( {'start': i, 'end': j} )\n",
        "\n",
        "#         return alternatives\n",
        "\n",
        "#     def prepare_prompts(self, question):\n",
        "\n",
        "#         alternatives = self.get_alternatives_positions(question)\n",
        "\n",
        "#         text_to_prompt = []\n",
        "\n",
        "#         for alt in alternatives:\n",
        "#             # davinci-003 não fecha string\n",
        "#             text_to_prompt.append(question + question[alt['start']:alt['end']] + '\\n') # + '\\n\\n')\n",
        "\n",
        "#         return text_to_prompt\n",
        "\n",
        "#     def evaluate_responses(self, responses):\n",
        "\n",
        "#         alternatives_evaluation = []\n",
        "\n",
        "#         for response in responses:\n",
        "\n",
        "#             tokens = response[\"choices\"][0][\"logprobs\"]['tokens']\n",
        "#             logprobs = response[\"choices\"][0][\"logprobs\"]['token_logprobs']\n",
        "\n",
        "#             alternatives = self.get_alternatives_positions(tokens)\n",
        "\n",
        "#             alternatives_logprobs = []\n",
        "\n",
        "#             for alt in alternatives:\n",
        "\n",
        "#                 start = alt['start']\n",
        "#                 end = alt['end']\n",
        "\n",
        "#                 alt_logprobs = list(map(float, logprobs[start:end]))\n",
        "#                 alt_n_toks = end - start\n",
        "#                 prob = math.exp( (math.fsum(alt_logprobs) / alt_n_toks) )\n",
        "\n",
        "#                 alternatives_logprobs.append( {'alternative': tokens[alt['start']],\n",
        "#                                               'text':''.join(tokens[alt['start']:alt['end']]),\n",
        "#                                               'prob': prob,\n",
        "#                                               'temp_sum': math.fsum(alt_logprobs),\n",
        "#                                               'temp_alt_n_toks': alt_n_toks} )\n",
        "\n",
        "#             alternatives_evaluation.append(alternatives_logprobs[-1])\n",
        "\n",
        "#         model_right_answer = max(alternatives_evaluation, key=lambda x:x['prob'])\n",
        "\n",
        "#         return model_right_answer, alternatives_evaluation\n",
        "\n",
        "#     def parse_question(self, idx):\n",
        "\n",
        "#         instruction = \"Responda a seguinte pergunta de multipla escolha:\"\n",
        "        \n",
        "#         base_string = self.ENEM.headers[idx] + '\\n\\n' + self.ENEM.statements[idx] + '\\n\\n'\n",
        "\n",
        "#         for alternative, answer in zip(self.ENEM.answers[idx][0], self.ENEM.answers[idx][1]):\n",
        "#             base_string += alternative['id'] + \". \" + answer + \"\\n\"\n",
        "\n",
        "#         prompt_string = instruction + \"\\n\\n\" +  base_string + \"\\n\" + \"Alternativa Correta:\\n\"\n",
        "\n",
        "#         return prompt_string\n",
        "\n",
        "#     def prompt_openai(self, question):\n",
        "\n",
        "#         prompts = self.prepare_prompts(question)\n",
        "\n",
        "#         print(f'prompt_openai: {prompts}')\n",
        "\n",
        "#         responses = []\n",
        "\n",
        "#         for text in tqdm(prompts):\n",
        "#             response = openai.Completion.create(\n",
        "#                 model=model,\n",
        "#                 prompt=text,\n",
        "#                 temperature=0,\n",
        "#                 max_tokens=1,# TODO: 512? 2048? context?\n",
        "#                 top_p=1,\n",
        "#                 frequency_penalty=0,\n",
        "#                 presence_penalty=0,\n",
        "#                 echo=True,\n",
        "#                 logprobs=5\n",
        "#             )\n",
        "\n",
        "#             responses.append(response)\n",
        "\n",
        "#         model_right_answer, alternatives_evaluation = self.evaluate_responses(responses)\n",
        "\n",
        "#         return model_right_answer['alternative'], model_right_answer['text'], alternatives_evaluation\n",
        "\n",
        "#     def ask_ENEM_question(self, idx):\n",
        "\n",
        "#         parsed_question = self.parse_question(idx)\n",
        "\n",
        "#         alternative, text, alternatives_evaluation = self.prompt_openai(parsed_question)\n",
        "\n",
        "#         return alternative, text, alternatives_evaluation, parsed_question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Os0icxEcvPiu"
      },
      "outputs": [],
      "source": [
        "#@title 0-shot / cot-few-shot - v1 - ABANDONADO\n",
        "# ######################\n",
        "# # OPENAI MODEL SETUP #\n",
        "# ######################\n",
        "\n",
        "# # RAWHIDE - CoT and 0-shot\n",
        "\n",
        "# class OPENAI_CLASS():\n",
        "#     def __init__(self, api_key, model, ENEM):\n",
        "\n",
        "#         self.ENEM = ENEM\n",
        "\n",
        "#         self.model = model\n",
        "\n",
        "#         self.openai = openai\n",
        "#         self.openai.api_key = api_key\n",
        "\n",
        "#     def get_alternatives_positions(self, text):\n",
        "\n",
        "#         # last_question_post only used on evaluate_responses()\n",
        "\n",
        "#         ######################\n",
        "#         # FIND LAST QUESTION #\n",
        "#         ######################\n",
        "\n",
        "#         # print(f'get_alternative_positions: {type(text)}')\n",
        "\n",
        "#         shots = []\n",
        "\n",
        "#         for i in range(len(text)):\n",
        "\n",
        "#             if (type(text) == list):\n",
        "#                 question = ''.join(text[i:i+19])\n",
        "#             elif (type(text) == str):\n",
        "#                 question = ''.join(text[i:i+51])\n",
        "\n",
        "#             res = re.search(r'(Responda a seguinte pergunta de multipla escolha:\\n\\n)', question)\n",
        "\n",
        "#             if (res != None):\n",
        "#                 shots.append(i)\n",
        "\n",
        "#         # print(f'shots: {shots}')\n",
        "        \n",
        "#         # print(\"#############################################\")\n",
        "#         # print(text)\n",
        "#         # print(shots)\n",
        "#         # print(\"#############################################\")\n",
        "\n",
        "#         last_question = text[shots[-1]:]\n",
        "\n",
        "#         #print()\n",
        "#         #print(shots[-1])\n",
        "#         #print(f'last_question: {last_question}')\n",
        "#         #print(text)\n",
        "\n",
        "#         # print(last_question)\n",
        "#         # print()\n",
        "\n",
        "#         ###########################################\n",
        "#         # FIND TOKENS POSITIONS FROM ALTERNATIVES #\n",
        "#         ###########################################\n",
        "\n",
        "#         alternatives = []\n",
        "\n",
        "#         for i in range(len(last_question)-1):\n",
        "\n",
        "#             if ( re.findall(\"\\n{1}\", last_question[i-1]) and\n",
        "#                  re.findall(\"^[ABCDE]{1}\", last_question[i]) and\n",
        "#                  re.findall(\"\\.{1}\", last_question[i+1]) ):\n",
        "\n",
        "#                 j = i\n",
        "\n",
        "#                 # print(f'len(text) = {len(text)} | i = {i} | text[i-1]: {repr(text[i-1])} | text[i]: {text[i]} | text[i+1]: {text[i+1]}')\n",
        "#                 # print(f'len(text) = {len(last_question)} | i = {i} | text[i-1]: {repr(last_question[i-1])} | text[i]: {last_question[i]} | text[i+1]: {last_question[i+1]}')\n",
        "\n",
        "#                 while last_question[j] != \"\\n\" and last_question[j] != '<|endoftext|>':\n",
        "#                     # print(f\"j: {j} | last_question: {last_question[j]}\")\n",
        "#                     j += 1\n",
        "\n",
        "#                 alternatives.append( { 'start': (i + shots[-1]), 'end': (j + shots[-1]) } )\n",
        "\n",
        "#         # for alt in alternatives:\n",
        "\n",
        "#         #     start = alt['start']\n",
        "#         #     end = alt['end']\n",
        "            \n",
        "#         #     print(text[start:end])\n",
        "            \n",
        "#         # print(desnes2)\n",
        "\n",
        "#         # Beginning of last question on text, alternative positions from reference of last question\n",
        "#         return shots[-1], alternatives\n",
        "\n",
        "#     def evaluate_responses(self, last_question_pos, responses, CoT):\n",
        "\n",
        "#         # print(\"evaluate_responses\")\n",
        "\n",
        "#         alternatives_evaluation = []\n",
        "\n",
        "#         for response in responses:\n",
        "\n",
        "#             tokens = response[\"choices\"][0][\"logprobs\"]['tokens']\n",
        "#             logprobs = response[\"choices\"][0][\"logprobs\"]['token_logprobs']\n",
        "\n",
        "#             last_question_pos, alternatives = self.get_alternatives_positions(tokens)\n",
        "\n",
        "#             # if (CoT):\n",
        "#             #     # Cut model generated AI answer\n",
        "#             #     # tokens = tokens[0:alternatives[-1]['start']]\n",
        "#             #     # tokens = tokens[0:alternatives[5]['end']]\n",
        "#             #     alternatives = alternatives[0:6]\n",
        "\n",
        "#             # print()\n",
        "#             # print(\"$$$$$$$$$$$$$$\")\n",
        "#             # print(tokens)\n",
        "#             # print(last_question_pos)\n",
        "#             # print(alternatives)\n",
        "#             # print(logprobs)\n",
        "#             # print(len(alternatives))\n",
        "#             # print(\"$$$$$$$$$$$$$$\")\n",
        "#             # print()\n",
        "\n",
        "#             alternatives_logprobs = []\n",
        "\n",
        "#             for alt in alternatives:\n",
        "\n",
        "#                 start = alt['start']\n",
        "#                 end = alt['end']\n",
        "\n",
        "#                 if (tokens[end+1] == '<|endoftext|>'):\n",
        "#                     end += 1\n",
        "\n",
        "#                 alt_logprobs = list(map(float, logprobs[start:end]))\n",
        "#                 alt_n_toks = end - start\n",
        "#                 prob = math.exp( (math.fsum(alt_logprobs) / alt_n_toks) )\n",
        "\n",
        "#                 alternatives_logprobs.append( {'alternative': tokens[alt['start']],\n",
        "#                                               'text':''.join(tokens[alt['start']:alt['end']]),\n",
        "#                                               'prob': prob,\n",
        "#                                               'temp_sum': math.fsum(alt_logprobs),\n",
        "#                                               'temp_alt_n_toks': alt_n_toks} )\n",
        "\n",
        "#             alternatives_evaluation.append(alternatives_logprobs[-1])\n",
        "\n",
        "#         model_right_answer = max(alternatives_evaluation, key=lambda x:x['prob'])\n",
        "\n",
        "#         return model_right_answer, alternatives_evaluation\n",
        "\n",
        "#     def prepare_prompts(self, question, CoT):\n",
        "\n",
        "#         # print(f'prepare_prompts')\n",
        "\n",
        "#         last_question_pos, alternatives = self.get_alternatives_positions(question)\n",
        "\n",
        "#         if (CoT):\n",
        "#             # Cut model generated AI answer\n",
        "#             question = question[0:alternatives[-1]['start']]\n",
        "#             alternatives = alternatives[0:5]\n",
        "\n",
        "#             # print(temp[0:2610])\n",
        "#             # print(alternatives[-1]['start'])\n",
        "\n",
        "#         text_to_prompt = []\n",
        "\n",
        "#         for alt in alternatives:\n",
        "#             # davinci-003 não fecha string\n",
        "#             # text_to_prompt.append(question + question[alt['start']:alt['end']] + '\\n')\n",
        "#             text_to_prompt.append(question + question[alt['start']:alt['end']] + '\\n' + '<|endoftext|>')\n",
        "\n",
        "#         return last_question_pos, text_to_prompt\n",
        "\n",
        "#     def prompt_openai(self, question, CoT):\n",
        "\n",
        "#         last_question_pos, prompts = self.prepare_prompts(question, CoT)\n",
        "\n",
        "#         print(f'prompt_openai: {prompts}')\n",
        "#         print()\n",
        "\n",
        "#         responses = []\n",
        "\n",
        "#         # for text in prompts:\n",
        "#         for text in tqdm(prompts):\n",
        "#             response = self.openai.Completion.create(\n",
        "#                 model=self.model,\n",
        "#                 prompt=text,\n",
        "#                 temperature=0,\n",
        "#                 max_tokens=1, # DON'T GENERATE TEXT\n",
        "#                 top_p=1,\n",
        "#                 frequency_penalty=0,\n",
        "#                 presence_penalty=0,\n",
        "#                 echo=True,\n",
        "#                 logprobs=5\n",
        "#             )\n",
        "\n",
        "#             # print(response)\n",
        "#             # print(\"#=============================#\")\n",
        "#             # print(response[\"choices\"][0]['text'])\n",
        "#             # print(\"#=============================#\")\n",
        "#             # print()\n",
        "#             # time.sleep(60)\n",
        "\n",
        "#             responses.append(response)\n",
        "\n",
        "#         model_right_answer, alternatives_evaluation = self.evaluate_responses(last_question_pos, responses, CoT)\n",
        "\n",
        "#         return model_right_answer['alternative'], model_right_answer['text'], alternatives_evaluation\n",
        "\n",
        "#     def get_CoT_from_openai(self, first_question):\n",
        "    \n",
        "#         response = self.openai.Completion.create(\n",
        "#             model=self.model,\n",
        "#             prompt=first_question,\n",
        "#             temperature=0,\n",
        "#             max_tokens=1024, # https://beta.openai.com/docs/guides/completion/inserting-text\n",
        "#             top_p=1,\n",
        "#             frequency_penalty=0,\n",
        "#             presence_penalty=0,\n",
        "#             echo=True,\n",
        "#             logprobs=5\n",
        "#         )\n",
        "\n",
        "#         reply = response[\"choices\"][0]['text']\n",
        "\n",
        "#         print(\"REPLY: \")\n",
        "#         print(reply)\n",
        "\n",
        "#         # print(desnes)\n",
        "\n",
        "#         # Delimit close string from OpenAI\n",
        "#         if (not re.findall(\"\\n$\", reply)):\n",
        "#           reply = reply + '\\n'\n",
        "\n",
        "#         return reply\n",
        "\n",
        "#     def parse_question(self, idx, CoT = \"\"):\n",
        "\n",
        "#         instruction = \"Responda a seguinte pergunta de multipla escolha:\"\n",
        "        \n",
        "#         # base_string = self.ENEM.headers[idx] + '\\n\\n' + self.ENEM.statements[idx] + '\\n\\n'\n",
        "#         base_string =  'Cabeçalho:\\n' + self.ENEM.headers[idx] + '\\n\\n' + 'Enunciado:\\n' + self.ENEM.statements[idx] + '\\n\\n' + 'Alternativas:\\n'\n",
        "\n",
        "#         for alternative, answer in zip(self.ENEM.answers[idx][0], self.ENEM.answers[idx][1]):\n",
        "#             base_string += alternative['id'] + \". \" + answer + \"\\n\"\n",
        "\n",
        "#         if (CoT):\n",
        "#             prompt_string = CoT + \"\\n\\n\" + instruction + \"\\n\\n\" +  base_string + \"\\n\" + \"Explicação:\\n\"\n",
        "#         else:\n",
        "#             prompt_string = instruction + \"\\n\\n\" +  base_string + \"\\n\" + \"Alternativa Correta:\\n\"\n",
        "\n",
        "#         return prompt_string\n",
        "\n",
        "#     def ask_ENEM_question(self, idx, CoT = \"\"):\n",
        "\n",
        "#         parsed_question = self.parse_question(idx, CoT)\n",
        "\n",
        "#         if (CoT):\n",
        "#             parsed_question = self.get_CoT_from_openai(parsed_question)\n",
        "\n",
        "#         alternative, text, alternatives_evaluation = self.prompt_openai(parsed_question, CoT)\n",
        "\n",
        "#         return alternative, text, alternatives_evaluation, parsed_question\n",
        "\n",
        "###########\n",
        "## TESTS ##\n",
        "###########\n",
        "\n",
        "# #print(ENEM.print_question(33))\n",
        "\n",
        "# # cmd1 = \"Responda a seguinte pergunta de multipla escolha assinalando a única alternativa correta e justifique\"\n",
        "# # exp1 = \"A primeira alternativa está correta porque precisamos induzir imunidade de um orgamismo para protegê-lo contra futura infecções. A segunda alternativa está errada pois não tem como fazer mudanças no genoma de um organismo. A terceira alternativa está errada pois antígenos não se ligam ao vírus. A quarta alternativa está errada pois HIV também é transmitido em humanos. A quinta alternativas está errada pois HIV não se transmite por gotículas de saliva. Portanto, a alternativa correta é:\\nA. induzir a imunidade, para proteger o organismo da contaminação viral.\"\n",
        "# # cot1 = cmd1 + \"\\n\\nCabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, Uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\nA. induzir a imunidade, para proteger o organismo da contaminação viral.\\nB. ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\nC. produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\nD. ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\nE. estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\n\" + exp1\n",
        "\n",
        "# # Solução que proponho (ja está com 2 exemplos explicaçào e pergunta no final)\n",
        "\n",
        "# cot3=\"Exemplo 1\\n\\nCabeçalho:\\nSegundo Aristóteles, “na cidade com o melhor conjunto de normas e naquela dotada de homens absolutamente justos, os cidadãos não devem viver uma vida de trabalho trivial ou de negócios — esses tipos de vida são desprezíveis e incompatíveis com as qualidades morais —, tampouco devem ser agricultores os aspirantes à cidadania, pois o lazer é indispensável ao desenvolvimento das qualidades morais e à prática das atividades políticas”. VAN ACKER, T. Grécia. A vida cotidiana na cidade-Estado. São Paulo: Atual, 1994.\\n\\nEnunciado:\\nO trecho, retirado da obra Política, de Aristóteles, permite compreender que a cidadania\\n\\nAlternativas:\\nA. possui uma dimensão histórica que deve ser criticada, pois é condenável que os políticos de qualquer época fiquem entregues à ociosidade, enquanto o resto dos cidadãos tem de trabalhar.\\nB. era entendida como uma dignidade própria dos grupos sociais superiores, fruto de uma concepção política profundamente hierarquizada da sociedade.\\nC. estava vinculada, na Grécia Antiga, a uma percepção política democrática, que levava todos os habitantes da pólis a participarem da vida cívica.\\nD. tinha profundas conexões com a justiça, razão pela qual o tempo livre dos cidadãos deveria ser dedicado às atividades vinculadas aos tribunais.\\nE. vivida pelos atenienses era, de fato, restrita àqueles que se dedicavam à política e que tinham tempo para resolver os problemas da cidade.\\n\\nEXPLICAÇÃO:\\nA alternativa A. está ERRADA. Porque faz um julgamento de valor de uma passagem histórica. Não responde o que é cidadania conforme o texto.\\nA alternativa B. está CORRETA porque interpreta acertadamente a sentença estabelecida por Aristóteles, que vincula o direito à cidadania a um grupo seleto de indivíduos limitando o pleno gozo da cidadania restringindo a um seleto grupo de pessoas superiores \\nA alternativa C. está ERRADA porque interpreta equivocadamente que todos habitantes teriam o mesmo direito cívico. O cabeçalho descreve que agricultores ou negociantes não deveriam ter o mesmo direito ao lazer como os políticos superiores. \\nA alternativa D. está ERRADA porque interpreta equivocadamente o texto já que o cabeçalho não diz nada sobre tempo livre dos cidadãos e de que deveriam se dedicar aos tribunais\\nA alternativa E. está ERRADA porque interpreta equivocadamente o texto dizendo que os que tinham direito a cidadania eram aqueles que tinham tempo para se dedicar a política. Mas isso não é mencionado no cabeçalho. Ao contrário o texto restringe a cidadania a um seleto grupo de pessoas superiores \\n\\nExemplo 2. \\n\\nCabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, Uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\nA. induzir a imunidade, para proteger o organismo da contaminação viral.\\nB. ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\nC. produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\nD. ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\nE. estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\nA alternativa A. está CORRETA porque precisamos induzir imunidade de um organismo para protegê-lo contra futura infecções. \\nA alternativa B. está ERRADA pois não é possível fazer mudanças no genoma de um organismo. \\nA alternativa C. está ERRADA pois antígenos não se ligam ao vírus. \\nA alternativa D está ERRADA pois pois HIV também é transmitido em humanos. \\nA alternativa E está ERRADA pois HIV não se transmite por gotículas de saliva. \\n\\nQual dentre as cinco alternativas do Exemplo 3 A. B. C. D. ou E. está CORRETA ou ERRADA? Só é possível uma alternativa CORRETA. Complete a EXPLICAÇÃO \\n\\nExemplo 3\\n\"\n",
        "\n",
        "# # Aquestão 38 é uma questào difícil que o zero shot tinha errado. Mas agora acerta !! \n",
        "# alternative, text, alternatives_evaluation, parsed_question = OPENAI.ask_ENEM_question(38, cot3)\n",
        "\n",
        "# print(alternative)\n",
        "# print(alternatives_evaluation)\n",
        "# print(parsed_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PQT5UCePHK1f"
      },
      "outputs": [],
      "source": [
        "#@title 0-shot / cot-few-shot - v2 - WORKS\n",
        "# ######################\n",
        "# # OPENAI MODEL SETUP #\n",
        "# ######################\n",
        "\n",
        "# # RAWHIDE - CoT v2 and 0-shot\n",
        "\n",
        "# class OPENAI_CLASS():\n",
        "#     def __init__(self, api_key, model, ENEM):\n",
        "\n",
        "#         self.ENEM = ENEM\n",
        "\n",
        "#         self.model = model\n",
        "\n",
        "#         self.openai = openai\n",
        "#         self.openai.api_key = api_key\n",
        "\n",
        "#     def get_alternatives_positions(self, question, pergunta_pos, cot = []):\n",
        "\n",
        "#         #########\n",
        "#         # SETUP #\n",
        "#         #########\n",
        "\n",
        "#         # REGEX few-shot:\n",
        "#         # A alternativa (A) está ERRADA\n",
        "        \n",
        "#         # REGEX 0shot:\n",
        "#         # B) ERRADA.\n",
        "#         # (C) ERRADA.\n",
        "        \n",
        "#         # PS: Escape ()s on regex\n",
        "#         correta_0sh = ['^', '\\({0,1}', '[ABCDE]{1}', '\\)', ' COR', 'RE', 'TA', '.']\n",
        "#         correta_cot = ['^', 'A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' COR', 'RE', 'TA']\n",
        "\n",
        "#         errada_0sh =  ['^', '\\({0,1}', '[ABCDE]{1}', '\\)', ' ER', 'R', 'ADA', '.']\n",
        "#         errada_cot = ['^', 'A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' ER', 'R', 'ADA']\n",
        "\n",
        "#         # TODO: investigate finding directly\n",
        "#         # found_right = re.search(''.join(correta_cot), repr(question))\n",
        "#         # print(found_right)\n",
        "\n",
        "#         ###########################################\n",
        "#         # FIND TOKENS POSITIONS FROM ALTERNATIVES #\n",
        "#         ###########################################\n",
        "\n",
        "#         found_right = None\n",
        "#         found_wrong = None\n",
        "        \n",
        "#         alternatives = []\n",
        "\n",
        "#         for i in range(len(question)-1):\n",
        "\n",
        "#             if (cot):\n",
        "#                 right = ''.join(question[i:i+len(correta_cot)])\n",
        "#                 found_right = re.search(''.join(correta_cot), right)\n",
        "\n",
        "#                 wrong = ''.join(question[i:i+len(errada_cot)])\n",
        "#                 found_wrong = re.search(''.join(errada_cot), wrong)\n",
        "#             else:\n",
        "#                 right = ''.join(question[i:i+len(correta_0sh)])\n",
        "#                 found_right = re.search(''.join(correta_0sh), right)\n",
        "\n",
        "#                 wrong = ''.join(question[i:i+len(errada_0sh)])\n",
        "#                 found_wrong = re.search(''.join(errada_0sh), wrong)\n",
        "\n",
        "#             if ( found_right or found_wrong ):\n",
        "\n",
        "#                 j = i\n",
        "\n",
        "#                 while question[j] != \"\\n\" and question[j] != '<|endoftext|>':\n",
        "#                     j += 1\n",
        "\n",
        "#                 alternatives.append( { 'start': (i + pergunta_pos), 'end': (j + pergunta_pos) } )\n",
        "\n",
        "#                 found_right = None\n",
        "#                 found_wrong = None\n",
        "\n",
        "#         # POG\n",
        "#         # Sometimes '(A) ERRADA' is matched twice due to (A) and A) - sometimes it isn't? WHY?\n",
        "#         if (len(alternatives) == 10):\n",
        "#             alternatives = alternatives[0:10:2]\n",
        "\n",
        "#         # Alternatives positions from reference of last question\n",
        "#         return alternatives\n",
        "\n",
        "#     def evaluate_response(self, response, cot = []):\n",
        "\n",
        "#         #########\n",
        "#         # SETUP #\n",
        "#         #########\n",
        "\n",
        "#         # text = response[\"choices\"][0]['text']\n",
        "#         tokens = response[\"choices\"][0][\"logprobs\"]['tokens']\n",
        "#         logprobs = response[\"choices\"][0][\"logprobs\"]['token_logprobs']\n",
        "\n",
        "#         #################\n",
        "#         # FIND PERGUNTA #\n",
        "#         #################\n",
        "\n",
        "#         pergunta = ['########', '####', '\\n', '#', ' PER', 'G', 'UN', 'TA', ' #', '\\n', '########', '####']\n",
        "#         pergunta_pos = 0\n",
        "\n",
        "#         for i in range(len(tokens)):\n",
        "\n",
        "#             question = ''.join(tokens[i:i+len(pergunta)])\n",
        "#             res = re.search(''.join(pergunta), question)\n",
        "\n",
        "#             if (res != None):\n",
        "#                 pergunta_pos = i\n",
        "\n",
        "#         question = tokens[pergunta_pos:]\n",
        "\n",
        "#         alternatives = self.get_alternatives_positions(question, pergunta_pos, cot)\n",
        "\n",
        "#         alternatives_logprobs = []\n",
        "#         alternatives_evaluation = []\n",
        "\n",
        "#         for alt in alternatives:\n",
        "\n",
        "#             start = alt['start']\n",
        "#             end = alt['end']\n",
        "\n",
        "#             alt_logprobs = list(map(float, logprobs[start:end]))\n",
        "#             alt_n_toks = end - start\n",
        "#             prob = math.exp( (math.fsum(alt_logprobs) / alt_n_toks) )\n",
        "\n",
        "#             if(cot):\n",
        "#                 # ['A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' COR', 'RE', 'TA]\n",
        "#                 #                                          ^5\n",
        "#                 alternatives_logprobs.append( {'alternative': tokens[start + 5],\n",
        "#                                               'text':''.join(tokens[start:end]),\n",
        "#                                               'prob': prob,\n",
        "#                                               'temp_sum': math.fsum(alt_logprobs),\n",
        "#                                               'temp_alt_n_toks': alt_n_toks} )\n",
        "#             else:\n",
        "\n",
        "#                 if ( tokens[start] == '(' ):\n",
        "#                     # (C) ERRADA.\n",
        "#                     #  ^\n",
        "#                     _0sh_start = start + 1\n",
        "#                 else:\n",
        "#                     # C) ERRADA.\n",
        "#                     # ^\n",
        "#                     _0sh_start = start\n",
        "\n",
        "#                 alternatives_logprobs.append( {'alternative': tokens[_0sh_start],\n",
        "#                                               'text':''.join(tokens[start:end]),\n",
        "#                                               'prob': prob,\n",
        "#                                               'temp_sum': math.fsum(alt_logprobs),\n",
        "#                                               'temp_alt_n_toks': alt_n_toks} )\n",
        "\n",
        "#         model_right_answer = max(alternatives_logprobs, key=lambda x:x['prob'])\n",
        "\n",
        "#         return model_right_answer, alternatives_logprobs\n",
        "\n",
        "#     def ask_openai(self, prompt_string):\n",
        "    \n",
        "#         # print(repr(prompt_string))\n",
        "#         # print(des)\n",
        "\n",
        "#         response = self.openai.Completion.create(\n",
        "#             model=self.model,\n",
        "#             prompt=prompt_string,\n",
        "#             temperature=0,\n",
        "#             max_tokens=1024, # https://beta.openai.com/docs/guides/completion/inserting-text\n",
        "#             top_p=1,\n",
        "#             frequency_penalty=0,\n",
        "#             presence_penalty=0,\n",
        "#             echo=True,\n",
        "#             logprobs=5\n",
        "#         )\n",
        "\n",
        "#         # reply = response[\"choices\"][0]['text']\n",
        "#         # print(\"REPLY: \")\n",
        "#         # print(reply)\n",
        "#         # print(desnes)\n",
        "\n",
        "#         return response\n",
        "\n",
        "#     def parse_question(self, idx, cmd, cot = []):\n",
        "\n",
        "#         prompt_string = cmd + \"\\n\"\n",
        "\n",
        "#         # few-shot\n",
        "#         for id, exemplo in enumerate(cot):\n",
        "#             header = \"EXEMPLO \" + str(id+1)\n",
        "\n",
        "#             prompt_string += \"\\n\"\n",
        "#             prompt_string += (\"#\" * (len(header)+4)) + \"\\n# \" + header + \" #\\n\" + (\"#\" * (len(header)+4))\n",
        "#             prompt_string += \"\\n\\n\" + exemplo + \"\\n\"\n",
        "            \n",
        "#         # print(prompt_string)\n",
        "#         # print(des)\n",
        "\n",
        "#         # 0-shot\n",
        "#         header = \"PERGUNTA\"\n",
        "        \n",
        "#         prompt_string += \"\\n\"\n",
        "#         prompt_string +=  (\"#\" * (len(header)+4)) + \"\\n# \" + header + \" #\\n\" + (\"#\" * (len(header)+4))\n",
        "#         prompt_string += \"\\n\\n\" + 'Cabeçalho:\\n' + self.ENEM.headers[idx] + '\\n\\n' + 'Enunciado:\\n' + self.ENEM.statements[idx] + '\\n\\n' + 'Alternativas:\\n'\n",
        "\n",
        "#         for alternative, answer in zip(self.ENEM.answers[idx][0], self.ENEM.answers[idx][1]):\n",
        "#             prompt_string += '(' + alternative['id'] + \")\" + \" \" + answer + \"\\n\"\n",
        "\n",
        "#         prompt_string += \"\\nExplicação:\\n\"\n",
        "\n",
        "#         # print(prompt_string)\n",
        "#         # print(len(prompt_string))\n",
        "#         # print(des)\n",
        "\n",
        "#         return prompt_string\n",
        "\n",
        "#     def ask_ENEM_question(self, idx, cmd, cot = []):\n",
        "\n",
        "#         parsed_question = self.parse_question(idx, cmd, cot)\n",
        "\n",
        "#         openai_response = self.ask_openai(parsed_question)\n",
        "\n",
        "#         model_right_answer, alternatives_evaluation = self.evaluate_response(openai_response, cot)\n",
        "\n",
        "#         return parsed_question, openai_response, model_right_answer, alternatives_evaluation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FmAmdaTKEPy"
      },
      "outputs": [],
      "source": [
        "#@title 0-shot / cot-few-shot - v3 - WORKS\n",
        "\n",
        "######################\n",
        "# OPENAI MODEL SETUP #\n",
        "######################\n",
        "\n",
        "# RAWHIDE - CoT v3 and 0-shot\n",
        "\n",
        "class OPENAI_CLASS():\n",
        "    def __init__(self, api_key, model, ENEM):\n",
        "\n",
        "        self.ENEM = ENEM\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "        self.openai = openai\n",
        "        self.openai.api_key = api_key\n",
        "\n",
        "    def get_alternatives_positions(self, tokens):\n",
        "\n",
        "        ####################\n",
        "        # FIND LINE BREAKS #\n",
        "        ####################\n",
        "\n",
        "        line_breaks = []\n",
        "\n",
        "        for i, tok in enumerate(tokens):\n",
        "            res = re.search('\\n|<|endoftext|>', tok)\n",
        "            if (res != None):\n",
        "                line_breaks.append(i)\n",
        "\n",
        "        #####################\n",
        "        # FIND ALTERNATIVES #\n",
        "        #####################\n",
        "\n",
        "        alternatives = []\n",
        "\n",
        "        # In multiline mode, ^ matches the position immediately following a newline\n",
        "        # and $ matches the position immediately preceding a newline.\n",
        "        regex_alt = \".*(CORRETA|ERRADA).*\"\n",
        "        regex_cmd = \"^(Com base no cabeçalho e enunciado).*\"\n",
        "\n",
        "        for i in range(len(line_breaks)-1):\n",
        "            \n",
        "            string = \"\".join(tokens[line_breaks[i]+1:line_breaks[i+1]])\n",
        "\n",
        "            found_alt = re.search(regex_alt, string)#, re.MULTILINE)\n",
        "            found_cmd = re.search(regex_cmd, string)\n",
        "\n",
        "            if ( (found_alt != None) and (found_cmd == None) ):\n",
        "                alternatives.append( { 'start': (line_breaks[i]+1), 'end': (line_breaks[i+1]) } )\n",
        "\n",
        "        return alternatives\n",
        "\n",
        "    def evaluate_response(self, response, cot = []):\n",
        "\n",
        "        #########\n",
        "        # SETUP #\n",
        "        #########\n",
        "\n",
        "        # text = response[\"choices\"][0]['text']\n",
        "        tokens = response[\"choices\"][0][\"logprobs\"]['tokens']\n",
        "        logprobs = response[\"choices\"][0][\"logprobs\"]['token_logprobs']\n",
        "\n",
        "        # davinci-002 sometimes does not close the string at the end\n",
        "        last_token = tokens[(len(tokens)-1)]\n",
        "        if( last_token != '\\n' or last_token != '<|endoftext|>'):\n",
        "            tokens.append('\\n')\n",
        "            logprobs.append(0)\n",
        "\n",
        "        alternatives = self.get_alternatives_positions(tokens)\n",
        "\n",
        "        ################\n",
        "        # ALTERNATIVES #\n",
        "        ################\n",
        "\n",
        "        alternatives_logprobs = []\n",
        "\n",
        "        for alt in alternatives[-5:]:\n",
        "\n",
        "            start = alt['start']\n",
        "            end = alt['end']\n",
        "\n",
        "            alternative_text = ''.join(tokens[start:end])\n",
        "\n",
        "            alt_logprobs = list(map(float, logprobs[start:end]))\n",
        "            alt_n_toks = end - start\n",
        "            prob_logprobs = math.exp( (math.fsum(alt_logprobs) / alt_n_toks) )\n",
        "\n",
        "            if \"CORRETA\" in alternative_text:\n",
        "                score = prob_logprobs\n",
        "            elif \"ERRADA\" in alternative_text:\n",
        "                score = 1 - prob_logprobs\n",
        "\n",
        "            # REGEX few-shot:\n",
        "            # 1 - A alternativa (A) está ERRADA\n",
        "            # 2 - A alternativa (A) bla bla bla. Portanto, a alternativa (A) está ERRADA.\n",
        "            \n",
        "            # REGEX 0shot:\n",
        "            # 1 - B) ERRADA.\n",
        "            # 2 - (C) ERRADA.\n",
        "\n",
        "            if(cot):\n",
        "                # ['A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' COR', 'RE', 'TA]\n",
        "                #                                          ^5\n",
        "                alternatives_logprobs.append( {'alternative': tokens[start + 5],\n",
        "                                              'text':alternative_text,\n",
        "                                              'prob': score,\n",
        "                                              'temp_fsum': math.fsum(alt_logprobs),\n",
        "                                              'temp_alt_n_toks': alt_n_toks} )\n",
        "            else:\n",
        "\n",
        "                if ( tokens[start] == '(' ):\n",
        "                    # (C) ERRADA.\n",
        "                    _0sh_start = start + 1\n",
        "                else:\n",
        "                    # C) ERRADA.\n",
        "                    _0sh_start = start\n",
        "\n",
        "                alternatives_logprobs.append( {'alternative': tokens[_0sh_start],\n",
        "                                              'text':alternative_text,\n",
        "                                              'prob': score,\n",
        "                                              'temp_sum': math.fsum(alt_logprobs),\n",
        "                                              'temp_alt_n_toks': alt_n_toks} )\n",
        "\n",
        "        model_right_answer = max(alternatives_logprobs, key=lambda x:x['prob'])\n",
        "\n",
        "        return model_right_answer, alternatives_logprobs\n",
        "\n",
        "    def ask_openai(self, prompt_string):\n",
        "    \n",
        "        # print(repr(prompt_string))\n",
        "        # print(des)\n",
        "\n",
        "        response = self.openai.Completion.create(\n",
        "            model=self.model,\n",
        "            prompt=prompt_string,\n",
        "            temperature=0,\n",
        "            max_tokens=1024, # https://beta.openai.com/docs/guides/completion/inserting-text\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0,\n",
        "            echo=True,\n",
        "            logprobs=5\n",
        "        )\n",
        "\n",
        "        # reply = response[\"choices\"][0]['text']\n",
        "        # print(\"\\n###### REPLY ######\\n\")\n",
        "        # print(reply)\n",
        "        # print(\"\\n###### REPLY ######\\n\")\n",
        "        # print(desnes)\n",
        "\n",
        "        return response\n",
        "\n",
        "    # def parse_question(self, idx, cmd, cot = []):\n",
        "\n",
        "    #     prompt_string = cmd + \"\\n\"\n",
        "\n",
        "    #     # few-shot\n",
        "    #     for id, exemplo in enumerate(cot):\n",
        "    #         header = \"EXEMPLO \" + str(id+1)\n",
        "\n",
        "    #         prompt_string += \"\\n\"\n",
        "    #         prompt_string += (\"#\" * (len(header)+4)) + \"\\n# \" + header + \" #\\n\" + (\"#\" * (len(header)+4))\n",
        "    #         prompt_string += \"\\n\\n\" + exemplo + \"\\n\"\n",
        "            \n",
        "    #     # print(prompt_string)\n",
        "    #     # print(des)\n",
        "\n",
        "    #     # 0-shot\n",
        "    #     header = \"PERGUNTA\"\n",
        "        \n",
        "    #     prompt_string += \"\\n\"\n",
        "    #     prompt_string +=  (\"#\" * (len(header)+4)) + \"\\n# \" + header + \" #\\n\" + (\"#\" * (len(header)+4))\n",
        "    #     prompt_string += \"\\n\\n\" + 'Cabeçalho:\\n' + self.ENEM.headers[idx] + '\\n\\n' + 'Enunciado:\\n' + self.ENEM.statements[idx] + '\\n\\n' + 'Alternativas:\\n'\n",
        "\n",
        "    #     for alternative, answer in zip(self.ENEM.answers[idx][0], self.ENEM.answers[idx][1]):\n",
        "    #         prompt_string += '(' + alternative['id'] + \")\" + \" \" + answer + \"\\n\"\n",
        "\n",
        "    #     prompt_string += \"\\nExplicação:\\n\"\n",
        "\n",
        "    #     # print(prompt_string)\n",
        "    #     # print(len(prompt_string))\n",
        "    #     # print(des)\n",
        "\n",
        "    #     return prompt_string\n",
        "\n",
        "    def parse_question(self, idx, cmd, cot = []):\n",
        "\n",
        "        prompt_string = \"\"\n",
        "        exemplo_id = 1000\n",
        "\n",
        "        # few-shot\n",
        "        for id, exemplo in enumerate(cot):\n",
        "            prompt_string += \"QUESTÃO \" + str(exemplo_id) + \"\\n\\n\" + cmd + \"\\n\\n\" + exemplo + \"\\n\\n\"\n",
        "            exemplo_id +=1\n",
        "\n",
        "        # print(prompt_string)\n",
        "        # print(des)\n",
        "\n",
        "        # 0-shot\n",
        "        prompt_string += \"QUESTÃO \" + str(idx) + \"\\n\\n\" + cmd + \"\\n\\n\" + 'Cabeçalho:\\n' + self.ENEM.headers[idx] + '\\n\\n' + 'Enunciado:\\n' + self.ENEM.statements[idx] + '\\n\\n' + 'Alternativas:\\n'\n",
        "\n",
        "        for alternative, answer in zip(self.ENEM.answers[idx][0], self.ENEM.answers[idx][1]):\n",
        "            prompt_string += '(' + alternative['id'] + \")\" + \" \" + answer + \"\\n\"\n",
        "\n",
        "        prompt_string += \"\\nExplicação:\\n\"\n",
        "\n",
        "        # print(prompt_string)\n",
        "        # print(len(prompt_string))\n",
        "        # print(des)\n",
        "\n",
        "        return prompt_string\n",
        "\n",
        "    def ask_ENEM_question(self, idx, cmd, cot = []):\n",
        "\n",
        "        parsed_question = self.parse_question(idx, cmd, cot)\n",
        "\n",
        "        openai_response = self.ask_openai(parsed_question)\n",
        "\n",
        "        model_right_answer, alternatives_evaluation = self.evaluate_response(openai_response, cot)\n",
        "\n",
        "        return parsed_question, openai_response, model_right_answer, alternatives_evaluation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GDOkvNJwNiY"
      },
      "outputs": [],
      "source": [
        "key = \"\"\n",
        "\n",
        "# model = \"text-davinci-002\"\n",
        "model = \"text-davinci-003\"\n",
        "# model = \"gpt-3.5-turbo\"\n",
        "\n",
        "OPENAI = OPENAI_CLASS(key, model, ENEM)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GPT3 devel [broken]\n",
        "        # if (self.model == \"gpt-3.5-turbo\"):\n",
        "\n",
        "        #     openai.Completion.create(model=\"gpt-3.5-turbo\", prompt=\"Gimme logprobs\", max_tokens=5, logprobs=3)\n",
        "\n",
        "        #     response = self.openai.ChatCompletion.create(\n",
        "        #         model=self.model,\n",
        "        #         messages=[{\"role\": \"user\", \"content\": prompt_string}],\n",
        "        #         temperature=0,\n",
        "        #         max_tokens=1024, # https://beta.openai.com/docs/guides/completion/inserting-text\n",
        "        #         top_p=1,\n",
        "        #         frequency_penalty=0,\n",
        "        #         presence_penalty=0,\n",
        "        #         logprobs=5\n",
        "        #     )\n",
        "\n",
        "        #     # print(response)\n",
        "        #     # print(desnes)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uVxIFsxgnQb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W1LMKuJaRfkl"
      },
      "outputs": [],
      "source": [
        "#@title # FIRST IMPORTANT DEBUG CELL #\n",
        "\n",
        "# DEBUG #\n",
        "\n",
        "# CELL TO SEND TO OPENAI A PROMPT\n",
        "\n",
        "#############\n",
        "# 0 shot 11 #\n",
        "#############\n",
        "\n",
        "# BUG FREE:\n",
        "# prompt_string = 'Com base no cabeçalho e enunciado, para cada uma das alternativas (A, B, C, D, E) decida se a pergunta está ERRADA ou CORRETA e dê uma explicação para cada alternativa. Apenas uma alternativa é CORRETA.\\n\\n############\\n# PERGUNTA #\\n############\\n\\nCabeçalho:\\nCerca de 1% do lixo urbano é constituído por resíduos sólidos contendo elementos tóxicos. Entre esses elementos estão metais pesados como o cádmio, o chumbo e o mercúrio, componentes de pilhas e baterias, que são perigosos à saúde humana e ao meio ambiente. Quando descartadas em lixos comuns, pilhas e baterias vão para aterros sanitários ou lixões a céu aberto, e o vazamento de seus componentes contamina o solo, os rios e o lençol freático, atingindo a flora e a fauna. Por serem bioacumulativos e não biodegradáveis, esses metais chegam de forma acumulada aos seres humanos, por meio da cadeia alimentar. A legislação vigente (Resolução CONAMA no 257/1999) regulamenta o destino de pilhas e baterias após seu esgotamento energético e determina aos fabricantes e/ou importadores a quantidade máxima permitida desses metais em cada tipo de pilha/bateria, porém o problema ainda persiste. Disponível em: http://www.mma.gov.br. Acesso em: 11 jul. 2009 (adaptado).\\n\\nEnunciado:\\nUma medida que poderia contribuir para acabar definitivamente com o problema da poluição ambiental por metais pesados relatado no texto seria\\n\\nAlternativas:\\n(A) deixar de consumir aparelhos elétricos que utilizem pilha ou bateria como fonte de energia.\\n(B) usar apenas pilhas ou baterias recarregáveis e de vida útil longa e evitar ingerir alimentos contaminados, especialmente peixes.\\n(C) devolver pilhas e baterias, após o esgotamento da energia armazenada, à rede de assistência técnica especializada para repasse a fabricantes e/ou importadores.\\n(D) criar nas cidades, especialmente naquelas com mais de 100 mil habitantes, pontos estratégicos de coleta de baterias e pilhas, para posterior repasse a fabricantes e/ou importadores.\\n(E) exigir que fabricantes invistam em pesquisa para a substituição desses metais tóxicos por substâncias menos nocivas ao homem e ao ambiente, e que não sejam bioacumulativas.\\n\\nExplicação:\\n'\n",
        "\n",
        "###############\n",
        "# few shot 11 #\n",
        "###############\n",
        "\n",
        "# BUG FREE:\n",
        "\n",
        "# cot = []\n",
        "# cot1 = \"Cabeçalho:\\nSegundo Aristóteles, “na cidade com o melhor conjunto de normas e naquela dotada de homens absolutamente justos, os cidadãos não devem viver uma vida de trabalho trivial ou de negócios — esses tipos de vida são desprezíveis e incompatíveis com as qualidades morais —, tampouco devem ser agricultores os aspirantes à cidadania, pois o lazer é indispensável ao desenvolvimento das qualidades morais e à prática das atividades políticas”. VAN ACKER, T. Grécia. A vida cotidiana na cidade-Estado. São Paulo: Atual, 1994.\\n\\nEnunciado:\\nO trecho, retirado da obra Política, de Aristóteles, permite compreender que a cidadania\\n\\nAlternativas:\\n(A) possui uma dimensão histórica que deve ser criticada, pois é condenável que os políticos de qualquer época fiquem entregues à ociosidade, enquanto o resto dos cidadãos tem de trabalhar.\\n(B) era entendida como uma dignidade própria dos grupos sociais superiores, fruto de uma concepção política profundamente hierarquizada da sociedade.\\n(C) estava vinculada, na Grécia Antiga, a uma percepção política democrática, que levava todos os habitantes da pólis a participarem da vida cívica.\\n(D) tinha profundas conexões com a justiça, razão pela qual o tempo livre dos cidadãos deveria ser dedicado às atividades vinculadas aos tribunais.\\n(E) vivida pelos atenienses era, de fato, restrita àqueles que se dedicavam à política e que tinham tempo para resolver os problemas da cidade.\\n\\nExplicação:\\nA alternativa (A) está ERRADA porque faz um julgamento de valor de uma passagem histórica. Não responde o que é cidadania conforme o texto.\\nA alternativa (B) está CORRETA porque interpreta acertadamente a sentença estabelecida por Aristóteles, que vincula o direito à cidadania a um grupo seleto de indivíduos limitando o pleno gozo da cidadania restringindo a um seleto grupo de pessoas superiores.\\nA alternativa (C) está ERRADA porque interpreta equivocadamente que todos habitantes teriam o mesmo direito cívico. O cabeçalho descreve que agricultores ou negociantes não deveriam ter o mesmo direito ao lazer como os políticos superiores.\\nA alternativa (D) está ERRADA porque interpreta equivocadamente o texto já que o cabeçalho não diz nada sobre tempo livre dos cidadãos e de que deveriam se dedicar aos tribunais.\\nA alternativa (E) está ERRADA porque interpreta equivocadamente o texto dizendo que os que tinham direito a cidadania eram aqueles que tinham tempo para se dedicar a política. Mas isso não é mencionado no cabeçalho. Ao contrário o texto restringe a cidadania a um seleto grupo de pessoas superiores.\"\n",
        "# cot2 = \"Cabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\n(A) induzir a imunidade, para proteger o organismo da contaminação viral.\\n(B) ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\n(C) produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\n(D) ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\n(E) estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\nA alternativa (A) está CORRETA porque precisamos induzir imunidade de um organismo para protegê-lo contra futura infecções.\\nA alternativa (B) está ERRADA pois não é possível fazer mudanças no genoma de um organismo.\\nA alternativa (C) está ERRADA pois antígenos não se ligam ao vírus.\\nA alternativa (D) está ERRADA pois pois HIV também é transmitido em humanos.\\nA alternativa (E) está ERRADA pois HIV não se transmite por gotículas de saliva.\"\n",
        "\n",
        "# cot.append(cot1)\n",
        "# cot.append(cot2)\n",
        "\n",
        "# prompt_string = 'Abaixo está uma lista de exemplos extraídos da prova do ENEM. Com base no cabeçalho e enunciado, para cada uma das alternativas (A, B, C, D, E) decida se a pergunta está ERRADA ou CORRETA e dê uma explicação para cada alternativa. Apenas uma alternativa é CORRETA.\\n\\n#############\\n# EXEMPLO 1 #\\n#############\\n\\nCabeçalho:\\nSegundo Aristóteles, “na cidade com o melhor conjunto de normas e naquela dotada de homens absolutamente justos, os cidadãos não devem viver uma vida de trabalho trivial ou de negócios — esses tipos de vida são desprezíveis e incompatíveis com as qualidades morais —, tampouco devem ser agricultores os aspirantes à cidadania, pois o lazer é indispensável ao desenvolvimento das qualidades morais e à prática das atividades políticas”. VAN ACKER, T. Grécia. A vida cotidiana na cidade-Estado. São Paulo: Atual, 1994.\\n\\nEnunciado:\\nO trecho, retirado da obra Política, de Aristóteles, permite compreender que a cidadania\\n\\nAlternativas:\\n(A) possui uma dimensão histórica que deve ser criticada, pois é condenável que os políticos de qualquer época fiquem entregues à ociosidade, enquanto o resto dos cidadãos tem de trabalhar.\\n(B) era entendida como uma dignidade própria dos grupos sociais superiores, fruto de uma concepção política profundamente hierarquizada da sociedade.\\n(C) estava vinculada, na Grécia Antiga, a uma percepção política democrática, que levava todos os habitantes da pólis a participarem da vida cívica.\\n(D) tinha profundas conexões com a justiça, razão pela qual o tempo livre dos cidadãos deveria ser dedicado às atividades vinculadas aos tribunais.\\n(E) vivida pelos atenienses era, de fato, restrita àqueles que se dedicavam à política e que tinham tempo para resolver os problemas da cidade.\\n\\nExplicação:\\nA alternativa (A) está ERRADA porque faz um julgamento de valor de uma passagem histórica. Não responde o que é cidadania conforme o texto.\\nA alternativa (B) está CORRETA porque interpreta acertadamente a sentença estabelecida por Aristóteles, que vincula o direito à cidadania a um grupo seleto de indivíduos limitando o pleno gozo da cidadania restringindo a um seleto grupo de pessoas superiores.\\nA alternativa (C) está ERRADA porque interpreta equivocadamente que todos habitantes teriam o mesmo direito cívico. O cabeçalho descreve que agricultores ou negociantes não deveriam ter o mesmo direito ao lazer como os políticos superiores.\\nA alternativa (D) está ERRADA porque interpreta equivocadamente o texto já que o cabeçalho não diz nada sobre tempo livre dos cidadãos e de que deveriam se dedicar aos tribunais.\\nA alternativa (E) está ERRADA porque interpreta equivocadamente o texto dizendo que os que tinham direito a cidadania eram aqueles que tinham tempo para se dedicar a política. Mas isso não é mencionado no cabeçalho. Ao contrário o texto restringe a cidadania a um seleto grupo de pessoas superiores.\\n\\n#############\\n# EXEMPLO 2 #\\n#############\\n\\nCabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\n(A) induzir a imunidade, para proteger o organismo da contaminação viral.\\n(B) ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\n(C) produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\n(D) ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\n(E) estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\nA alternativa (A) está CORRETA porque precisamos induzir imunidade de um organismo para protegê-lo contra futura infecções.\\nA alternativa (B) está ERRADA pois não é possível fazer mudanças no genoma de um organismo.\\nA alternativa (C) está ERRADA pois antígenos não se ligam ao vírus.\\nA alternativa (D) está ERRADA pois pois HIV também é transmitido em humanos.\\nA alternativa (E) está ERRADA pois HIV não se transmite por gotículas de saliva.\\n\\n############\\n# PERGUNTA #\\n############\\n\\nCabeçalho:\\nCerca de 1% do lixo urbano é constituído por resíduos sólidos contendo elementos tóxicos. Entre esses elementos estão metais pesados como o cádmio, o chumbo e o mercúrio, componentes de pilhas e baterias, que são perigosos à saúde humana e ao meio ambiente. Quando descartadas em lixos comuns, pilhas e baterias vão para aterros sanitários ou lixões a céu aberto, e o vazamento de seus componentes contamina o solo, os rios e o lençol freático, atingindo a flora e a fauna. Por serem bioacumulativos e não biodegradáveis, esses metais chegam de forma acumulada aos seres humanos, por meio da cadeia alimentar. A legislação vigente (Resolução CONAMA no 257/1999) regulamenta o destino de pilhas e baterias após seu esgotamento energético e determina aos fabricantes e/ou importadores a quantidade máxima permitida desses metais em cada tipo de pilha/bateria, porém o problema ainda persiste. Disponível em: http://www.mma.gov.br. Acesso em: 11 jul. 2009 (adaptado).\\n\\nEnunciado:\\nUma medida que poderia contribuir para acabar definitivamente com o problema da poluição ambiental por metais pesados relatado no texto seria\\n\\nAlternativas:\\n(A) deixar de consumir aparelhos elétricos que utilizem pilha ou bateria como fonte de energia.\\n(B) usar apenas pilhas ou baterias recarregáveis e de vida útil longa e evitar ingerir alimentos contaminados, especialmente peixes.\\n(C) devolver pilhas e baterias, após o esgotamento da energia armazenada, à rede de assistência técnica especializada para repasse a fabricantes e/ou importadores.\\n(D) criar nas cidades, especialmente naquelas com mais de 100 mil habitantes, pontos estratégicos de coleta de baterias e pilhas, para posterior repasse a fabricantes e/ou importadores.\\n(E) exigir que fabricantes invistam em pesquisa para a substituição desses metais tóxicos por substâncias menos nocivas ao homem e ao ambiente, e que não sejam bioacumulativas.\\n\\nExplicação:\\n'\n",
        "\n",
        "#############\n",
        "# 0 shot 13 #\n",
        "#############\n",
        "\n",
        "# BUG FREE:\n",
        "# prompt_string = 'Com base no cabeçalho e enunciado, para cada uma das alternativas (A, B, C, D, E) decida se a pergunta está ERRADA ou CORRETA e dê uma explicação para cada alternativa. Apenas uma alternativa é CORRETA.\\n\\n############\\n# PERGUNTA #\\n############\\n\\nCabeçalho:\\nO progresso da tecnologia introduziu diversos artefatos geradores de campos eletromagnéticos. Uma das mais empregadas invenções nessa área são os telefones celulares e smartphones. As tecnologias de transmissão de celular atualmente em uso no Brasil contemplam dois sistemas. O primeiro deles é operado entre as frequências de 800 MHz e 900 MHz e constitui os chamados sistemas TDMA/CDMA. Já a tecnologia GSM, ocupa a frequência de 1.800 MHz.\\n\\nEnunciado:\\nConsiderando que a intensidade de transmissão e o nível de recepção “celular” sejam os mesmos para as tecnologias de transmissão TDMA/CDMA ou GSM, se um engenheiro tiver de escolher entre as duas tecnologias para obter a mesma cobertura, levando em consideração apenas o número de antenas em uma região, ele deverá escolher:\\n\\nAlternativas:\\n(A) a tecnologia GSM, pois é a que opera com ondas de maior comprimento de onda.\\n(B) a tecnologia TDMA/CDMA, pois é a que apresenta Efeito Doppler mais pronunciado.\\n(C) a tecnologia GSM, pois é a que utiliza ondas que se propagam com maior velocidade.\\n(D) qualquer uma das duas, pois as diferenças nas frequências são compensadas pelas diferenças nos comprimentos de onda.\\n(E) qualquer uma das duas, pois nesse caso as intensidades decaem igualmente da mesma forma, independentemente da frequência.\\n\\nExplicação:\\n'\n",
        "\n",
        "###############\n",
        "# few shot 13 #\n",
        "###############\n",
        "\n",
        "# BUG FREE:\n",
        "\n",
        "# cot = []\n",
        "# cot1 = \"Cabeçalho:\\nSegundo Aristóteles, “na cidade com o melhor conjunto de normas e naquela dotada de homens absolutamente justos, os cidadãos não devem viver uma vida de trabalho trivial ou de negócios — esses tipos de vida são desprezíveis e incompatíveis com as qualidades morais —, tampouco devem ser agricultores os aspirantes à cidadania, pois o lazer é indispensável ao desenvolvimento das qualidades morais e à prática das atividades políticas”. VAN ACKER, T. Grécia. A vida cotidiana na cidade-Estado. São Paulo: Atual, 1994.\\n\\nEnunciado:\\nO trecho, retirado da obra Política, de Aristóteles, permite compreender que a cidadania\\n\\nAlternativas:\\n(A) possui uma dimensão histórica que deve ser criticada, pois é condenável que os políticos de qualquer época fiquem entregues à ociosidade, enquanto o resto dos cidadãos tem de trabalhar.\\n(B) era entendida como uma dignidade própria dos grupos sociais superiores, fruto de uma concepção política profundamente hierarquizada da sociedade.\\n(C) estava vinculada, na Grécia Antiga, a uma percepção política democrática, que levava todos os habitantes da pólis a participarem da vida cívica.\\n(D) tinha profundas conexões com a justiça, razão pela qual o tempo livre dos cidadãos deveria ser dedicado às atividades vinculadas aos tribunais.\\n(E) vivida pelos atenienses era, de fato, restrita àqueles que se dedicavam à política e que tinham tempo para resolver os problemas da cidade.\\n\\nExplicação:\\nA alternativa (A) está ERRADA porque faz um julgamento de valor de uma passagem histórica. Não responde o que é cidadania conforme o texto.\\nA alternativa (B) está CORRETA porque interpreta acertadamente a sentença estabelecida por Aristóteles, que vincula o direito à cidadania a um grupo seleto de indivíduos limitando o pleno gozo da cidadania restringindo a um seleto grupo de pessoas superiores.\\nA alternativa (C) está ERRADA porque interpreta equivocadamente que todos habitantes teriam o mesmo direito cívico. O cabeçalho descreve que agricultores ou negociantes não deveriam ter o mesmo direito ao lazer como os políticos superiores.\\nA alternativa (D) está ERRADA porque interpreta equivocadamente o texto já que o cabeçalho não diz nada sobre tempo livre dos cidadãos e de que deveriam se dedicar aos tribunais.\\nA alternativa (E) está ERRADA porque interpreta equivocadamente o texto dizendo que os que tinham direito a cidadania eram aqueles que tinham tempo para se dedicar a política. Mas isso não é mencionado no cabeçalho. Ao contrário o texto restringe a cidadania a um seleto grupo de pessoas superiores.\"\n",
        "# cot2 = \"Cabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\n(A) induzir a imunidade, para proteger o organismo da contaminação viral.\\n(B) ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\n(C) produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\n(D) ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\n(E) estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\nA alternativa (A) está CORRETA porque precisamos induzir imunidade de um organismo para protegê-lo contra futura infecções.\\nA alternativa (B) está ERRADA pois não é possível fazer mudanças no genoma de um organismo.\\nA alternativa (C) está ERRADA pois antígenos não se ligam ao vírus.\\nA alternativa (D) está ERRADA pois pois HIV também é transmitido em humanos.\\nA alternativa (E) está ERRADA pois HIV não se transmite por gotículas de saliva.\"\n",
        "\n",
        "# cot.append(cot1)\n",
        "# cot.append(cot2)\n",
        "\n",
        "# prompt_string = 'Abaixo está uma lista de exemplos extraídos da prova do ENEM. Com base no cabeçalho e enunciado, para cada uma das alternativas (A, B, C, D, E) decida se a pergunta está ERRADA ou CORRETA e dê uma explicação para cada alternativa. Apenas uma alternativa é CORRETA.\\n\\n#############\\n# EXEMPLO 1 #\\n#############\\n\\nCabeçalho:\\nSegundo Aristóteles, “na cidade com o melhor conjunto de normas e naquela dotada de homens absolutamente justos, os cidadãos não devem viver uma vida de trabalho trivial ou de negócios — esses tipos de vida são desprezíveis e incompatíveis com as qualidades morais —, tampouco devem ser agricultores os aspirantes à cidadania, pois o lazer é indispensável ao desenvolvimento das qualidades morais e à prática das atividades políticas”. VAN ACKER, T. Grécia. A vida cotidiana na cidade-Estado. São Paulo: Atual, 1994.\\n\\nEnunciado:\\nO trecho, retirado da obra Política, de Aristóteles, permite compreender que a cidadania\\n\\nAlternativas:\\n(A) possui uma dimensão histórica que deve ser criticada, pois é condenável que os políticos de qualquer época fiquem entregues à ociosidade, enquanto o resto dos cidadãos tem de trabalhar.\\n(B) era entendida como uma dignidade própria dos grupos sociais superiores, fruto de uma concepção política profundamente hierarquizada da sociedade.\\n(C) estava vinculada, na Grécia Antiga, a uma percepção política democrática, que levava todos os habitantes da pólis a participarem da vida cívica.\\n(D) tinha profundas conexões com a justiça, razão pela qual o tempo livre dos cidadãos deveria ser dedicado às atividades vinculadas aos tribunais.\\n(E) vivida pelos atenienses era, de fato, restrita àqueles que se dedicavam à política e que tinham tempo para resolver os problemas da cidade.\\n\\nExplicação:\\nA alternativa (A) está ERRADA porque faz um julgamento de valor de uma passagem histórica. Não responde o que é cidadania conforme o texto.\\nA alternativa (B) está CORRETA porque interpreta acertadamente a sentença estabelecida por Aristóteles, que vincula o direito à cidadania a um grupo seleto de indivíduos limitando o pleno gozo da cidadania restringindo a um seleto grupo de pessoas superiores.\\nA alternativa (C) está ERRADA porque interpreta equivocadamente que todos habitantes teriam o mesmo direito cívico. O cabeçalho descreve que agricultores ou negociantes não deveriam ter o mesmo direito ao lazer como os políticos superiores.\\nA alternativa (D) está ERRADA porque interpreta equivocadamente o texto já que o cabeçalho não diz nada sobre tempo livre dos cidadãos e de que deveriam se dedicar aos tribunais.\\nA alternativa (E) está ERRADA porque interpreta equivocadamente o texto dizendo que os que tinham direito a cidadania eram aqueles que tinham tempo para se dedicar a política. Mas isso não é mencionado no cabeçalho. Ao contrário o texto restringe a cidadania a um seleto grupo de pessoas superiores.\\n\\n#############\\n# EXEMPLO 2 #\\n#############\\n\\nCabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\n(A) induzir a imunidade, para proteger o organismo da contaminação viral.\\n(B) ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\n(C) produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\n(D) ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\n(E) estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\nA alternativa (A) está CORRETA porque precisamos induzir imunidade de um organismo para protegê-lo contra futura infecções.\\nA alternativa (B) está ERRADA pois não é possível fazer mudanças no genoma de um organismo.\\nA alternativa (C) está ERRADA pois antígenos não se ligam ao vírus.\\nA alternativa (D) está ERRADA pois pois HIV também é transmitido em humanos.\\nA alternativa (E) está ERRADA pois HIV não se transmite por gotículas de saliva.\\n\\n############\\n# PERGUNTA #\\n############\\n\\nCabeçalho:\\nO progresso da tecnologia introduziu diversos artefatos geradores de campos eletromagnéticos. Uma das mais empregadas invenções nessa área são os telefones celulares e smartphones. As tecnologias de transmissão de celular atualmente em uso no Brasil contemplam dois sistemas. O primeiro deles é operado entre as frequências de 800 MHz e 900 MHz e constitui os chamados sistemas TDMA/CDMA. Já a tecnologia GSM, ocupa a frequência de 1.800 MHz.\\n\\nEnunciado:\\nConsiderando que a intensidade de transmissão e o nível de recepção “celular” sejam os mesmos para as tecnologias de transmissão TDMA/CDMA ou GSM, se um engenheiro tiver de escolher entre as duas tecnologias para obter a mesma cobertura, levando em consideração apenas o número de antenas em uma região, ele deverá escolher:\\n\\nAlternativas:\\n(A) a tecnologia GSM, pois é a que opera com ondas de maior comprimento de onda.\\n(B) a tecnologia TDMA/CDMA, pois é a que apresenta Efeito Doppler mais pronunciado.\\n(C) a tecnologia GSM, pois é a que utiliza ondas que se propagam com maior velocidade.\\n(D) qualquer uma das duas, pois as diferenças nas frequências são compensadas pelas diferenças nos comprimentos de onda.\\n(E) qualquer uma das duas, pois nesse caso as intensidades decaem igualmente da mesma forma, independentemente da frequência.\\n\\nExplicação:\\n'\n",
        "\n",
        "#############\n",
        "# 0 shot 89 #\n",
        "#############\n",
        "\n",
        "# prompt_string = 'Com base no cabeçalho e enunciado, para cada uma das alternativas (A, B, C, D, E) decida se a pergunta está ERRADA ou CORRETA e dê uma explicação para cada alternativa. Apenas uma alternativa é CORRETA.\\n\\n############\\n# PERGUNTA #\\n############\\n\\nCabeçalho:\\nAntes, eram apenas as grandes cidades que se apresentavam como o império da técnica, objeto de modificações, suspensões, acréscimos, cada vez mais sofisticadas e carregadas de artifício. Esse mundo artificial inclui, hoje, o mundo rural. SANTOS, M. A Natureza do Espaço. São Paulo: Hucitec, 1996.\\n\\nEnunciado:\\nConsiderando a transformação mencionada no texto, uma consequência socioespacial que caracteriza o atual mundo rural brasileiro é\\n\\nAlternativas:\\n(A) a redução do processo de concentração de terras.\\n(B) o aumento do aproveitamento de solos menos férteis.\\n(C) a ampliação do isolamento do espaço rural.\\n(D) a estagnação da fronteira agrícola do país.\\n(E) a diminuição do nível de emprego formal.\\n\\nExplicação:\\n'\n",
        "\n",
        "###############\n",
        "# few shot 89 #\n",
        "###############\n",
        "\n",
        "# BUG FREE:\n",
        "\n",
        "# cot = []\n",
        "# cot1 = \"Cabeçalho:\\nSegundo Aristóteles, “na cidade com o melhor conjunto de normas e naquela dotada de homens absolutamente justos, os cidadãos não devem viver uma vida de trabalho trivial ou de negócios — esses tipos de vida são desprezíveis e incompatíveis com as qualidades morais —, tampouco devem ser agricultores os aspirantes à cidadania, pois o lazer é indispensável ao desenvolvimento das qualidades morais e à prática das atividades políticas”. VAN ACKER, T. Grécia. A vida cotidiana na cidade-Estado. São Paulo: Atual, 1994.\\n\\nEnunciado:\\nO trecho, retirado da obra Política, de Aristóteles, permite compreender que a cidadania\\n\\nAlternativas:\\n(A) possui uma dimensão histórica que deve ser criticada, pois é condenável que os políticos de qualquer época fiquem entregues à ociosidade, enquanto o resto dos cidadãos tem de trabalhar.\\n(B) era entendida como uma dignidade própria dos grupos sociais superiores, fruto de uma concepção política profundamente hierarquizada da sociedade.\\n(C) estava vinculada, na Grécia Antiga, a uma percepção política democrática, que levava todos os habitantes da pólis a participarem da vida cívica.\\n(D) tinha profundas conexões com a justiça, razão pela qual o tempo livre dos cidadãos deveria ser dedicado às atividades vinculadas aos tribunais.\\n(E) vivida pelos atenienses era, de fato, restrita àqueles que se dedicavam à política e que tinham tempo para resolver os problemas da cidade.\\n\\nExplicação:\\nA alternativa (A) está ERRADA porque faz um julgamento de valor de uma passagem histórica. Não responde o que é cidadania conforme o texto.\\nA alternativa (B) está CORRETA porque interpreta acertadamente a sentença estabelecida por Aristóteles, que vincula o direito à cidadania a um grupo seleto de indivíduos limitando o pleno gozo da cidadania restringindo a um seleto grupo de pessoas superiores.\\nA alternativa (C) está ERRADA porque interpreta equivocadamente que todos habitantes teriam o mesmo direito cívico. O cabeçalho descreve que agricultores ou negociantes não deveriam ter o mesmo direito ao lazer como os políticos superiores.\\nA alternativa (D) está ERRADA porque interpreta equivocadamente o texto já que o cabeçalho não diz nada sobre tempo livre dos cidadãos e de que deveriam se dedicar aos tribunais.\\nA alternativa (E) está ERRADA porque interpreta equivocadamente o texto dizendo que os que tinham direito a cidadania eram aqueles que tinham tempo para se dedicar a política. Mas isso não é mencionado no cabeçalho. Ao contrário o texto restringe a cidadania a um seleto grupo de pessoas superiores.\"\n",
        "# cot2 = \"Cabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\n(A) induzir a imunidade, para proteger o organismo da contaminação viral.\\n(B) ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\n(C) produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\n(D) ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\n(E) estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\nA alternativa (A) está CORRETA porque precisamos induzir imunidade de um organismo para protegê-lo contra futura infecções.\\nA alternativa (B) está ERRADA pois não é possível fazer mudanças no genoma de um organismo.\\nA alternativa (C) está ERRADA pois antígenos não se ligam ao vírus.\\nA alternativa (D) está ERRADA pois pois HIV também é transmitido em humanos.\\nA alternativa (E) está ERRADA pois HIV não se transmite por gotículas de saliva.\"\n",
        "\n",
        "# cot.append(cot1)\n",
        "# cot.append(cot2)\n",
        "\n",
        "# prompt_string = 'Abaixo está uma lista de exemplos extraídos da prova do ENEM. Com base no cabeçalho e enunciado, para cada uma das alternativas (A, B, C, D, E) decida se a pergunta está ERRADA ou CORRETA e dê uma explicação para cada alternativa. Apenas uma alternativa é CORRETA.\\n\\n#############\\n# EXEMPLO 1 #\\n#############\\n\\nCabeçalho:\\nSegundo Aristóteles, “na cidade com o melhor conjunto de normas e naquela dotada de homens absolutamente justos, os cidadãos não devem viver uma vida de trabalho trivial ou de negócios — esses tipos de vida são desprezíveis e incompatíveis com as qualidades morais —, tampouco devem ser agricultores os aspirantes à cidadania, pois o lazer é indispensável ao desenvolvimento das qualidades morais e à prática das atividades políticas”. VAN ACKER, T. Grécia. A vida cotidiana na cidade-Estado. São Paulo: Atual, 1994.\\n\\nEnunciado:\\nO trecho, retirado da obra Política, de Aristóteles, permite compreender que a cidadania\\n\\nAlternativas:\\n(A) possui uma dimensão histórica que deve ser criticada, pois é condenável que os políticos de qualquer época fiquem entregues à ociosidade, enquanto o resto dos cidadãos tem de trabalhar.\\n(B) era entendida como uma dignidade própria dos grupos sociais superiores, fruto de uma concepção política profundamente hierarquizada da sociedade.\\n(C) estava vinculada, na Grécia Antiga, a uma percepção política democrática, que levava todos os habitantes da pólis a participarem da vida cívica.\\n(D) tinha profundas conexões com a justiça, razão pela qual o tempo livre dos cidadãos deveria ser dedicado às atividades vinculadas aos tribunais.\\n(E) vivida pelos atenienses era, de fato, restrita àqueles que se dedicavam à política e que tinham tempo para resolver os problemas da cidade.\\n\\nExplicação:\\nA alternativa (A) está ERRADA porque faz um julgamento de valor de uma passagem histórica. Não responde o que é cidadania conforme o texto.\\nA alternativa (B) está CORRETA porque interpreta acertadamente a sentença estabelecida por Aristóteles, que vincula o direito à cidadania a um grupo seleto de indivíduos limitando o pleno gozo da cidadania restringindo a um seleto grupo de pessoas superiores.\\nA alternativa (C) está ERRADA porque interpreta equivocadamente que todos habitantes teriam o mesmo direito cívico. O cabeçalho descreve que agricultores ou negociantes não deveriam ter o mesmo direito ao lazer como os políticos superiores.\\nA alternativa (D) está ERRADA porque interpreta equivocadamente o texto já que o cabeçalho não diz nada sobre tempo livre dos cidadãos e de que deveriam se dedicar aos tribunais.\\nA alternativa (E) está ERRADA porque interpreta equivocadamente o texto dizendo que os que tinham direito a cidadania eram aqueles que tinham tempo para se dedicar a política. Mas isso não é mencionado no cabeçalho. Ao contrário o texto restringe a cidadania a um seleto grupo de pessoas superiores.\\n\\n#############\\n# EXEMPLO 2 #\\n#############\\n\\nCabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\n(A) induzir a imunidade, para proteger o organismo da contaminação viral.\\n(B) ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\n(C) produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\n(D) ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\n(E) estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\nA alternativa (A) está CORRETA porque precisamos induzir imunidade de um organismo para protegê-lo contra futura infecções.\\nA alternativa (B) está ERRADA pois não é possível fazer mudanças no genoma de um organismo.\\nA alternativa (C) está ERRADA pois antígenos não se ligam ao vírus.\\nA alternativa (D) está ERRADA pois pois HIV também é transmitido em humanos.\\nA alternativa (E) está ERRADA pois HIV não se transmite por gotículas de saliva.\\n\\n############\\n# PERGUNTA #\\n############\\n\\nCabeçalho:\\nAntes, eram apenas as grandes cidades que se apresentavam como o império da técnica, objeto de modificações, suspensões, acréscimos, cada vez mais sofisticadas e carregadas de artifício. Esse mundo artificial inclui, hoje, o mundo rural. SANTOS, M. A Natureza do Espaço. São Paulo: Hucitec, 1996.\\n\\nEnunciado:\\nConsiderando a transformação mencionada no texto, uma consequência socioespacial que caracteriza o atual mundo rural brasileiro é\\n\\nAlternativas:\\n(A) a redução do processo de concentração de terras.\\n(B) o aumento do aproveitamento de solos menos férteis.\\n(C) a ampliação do isolamento do espaço rural.\\n(D) a estagnação da fronteira agrícola do país.\\n(E) a diminuição do nível de emprego formal.\\n\\nExplicação:\\n'\n",
        "\n",
        "###########\n",
        "# OPEN AI #\n",
        "###########\n",
        "\n",
        "# response = openai.Completion.create(\n",
        "#     model=model,\n",
        "#     prompt=prompt_string,\n",
        "#     temperature=0,\n",
        "#     max_tokens=1024, # https://beta.openai.com/docs/guides/completion/inserting-text\n",
        "#     top_p=1,\n",
        "#     frequency_penalty=0,\n",
        "#     presence_penalty=0,\n",
        "#     echo=True,\n",
        "#     logprobs=5\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UYbCPbmVR2YT"
      },
      "outputs": [],
      "source": [
        "#@title # IMPORTANT DEBUG CELL 2 #\n",
        "\n",
        "# def get_alternatives_positions(question, pergunta_pos, cot = []):\n",
        "\n",
        "#     #########\n",
        "#     # SETUP #\n",
        "#     #########\n",
        "\n",
        "#     # few-shot:\n",
        "#     # A alternativa (A) está ERRADA\n",
        "    \n",
        "#     # 0shot:\n",
        "#     # B) ERRADA.\n",
        "#     # (C) ERRADA.\n",
        "    \n",
        "#     # PS: Escape ()s on regex\n",
        "#     # correta_0sh = ['\\n', '\\({0,1}', '[ABCDE]{1}', '\\)', ' COR', 'RE', 'TA', '.']\n",
        "#     # correta_cot = ['\\n', 'A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' COR', 'RE', 'TA']\n",
        "\n",
        "#     # errada_0sh =  ['\\n', '\\({0,1}', '[ABCDE]{1}', '\\)', ' ER', 'R', 'ADA', '.']\n",
        "#     # errada_cot = ['\\n', 'A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' ER', 'R', 'ADA']\n",
        "\n",
        "#     correta_0sh = ['^', '\\({0,1}', '[ABCDE]{1}', '\\)', ' COR', 'RE', 'TA', '.']\n",
        "#     correta_cot = ['^', 'A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' COR', 'RE', 'TA']\n",
        "\n",
        "#     errada_0sh =  ['^', '\\({0,1}', '[ABCDE]{1}', '\\)', ' ER', 'R', 'ADA', '.']\n",
        "#     errada_cot = ['^', 'A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' ER', 'R', 'ADA']\n",
        "\n",
        "#     # TODO: investigate finding directly\n",
        "#     # found_right = re.search(''.join(correta_cot), repr(question))\n",
        "#     # print(found_right)\n",
        "\n",
        "#     ###########################################\n",
        "#     # FIND TOKENS POSITIONS FROM ALTERNATIVES #\n",
        "#     ###########################################\n",
        "\n",
        "#     found_right = None\n",
        "#     found_wrong = None\n",
        "    \n",
        "#     alternatives = []\n",
        "\n",
        "#     for i in range(len(question)-1):\n",
        "\n",
        "#         # print(len(alternatives))\n",
        "\n",
        "#         # if (len(alternatives) == 1):\n",
        "#         #     break\n",
        "\n",
        "#         if (cot):\n",
        "#             right = ''.join(question[i:i+len(correta_cot)])\n",
        "#             found_right = re.search(''.join(correta_cot), right)\n",
        "\n",
        "#             wrong = ''.join(question[i:i+len(errada_cot)])\n",
        "#             found_wrong = re.search(''.join(errada_cot), wrong)\n",
        "#         else:\n",
        "#             right = ''.join(question[i:i+len(correta_0sh)])\n",
        "#             found_right = re.search(''.join(correta_0sh), right)\n",
        "\n",
        "#             wrong = ''.join(question[i:i+len(errada_0sh)])\n",
        "#             found_wrong = re.search(''.join(errada_0sh), wrong)\n",
        "\n",
        "# #        print(\"\".join(correta_cot))\n",
        "#         # print(len(correta_cot))\n",
        "#         # print(len(\"\".join(correta_cot)))\n",
        "#         # print(repr(right))\n",
        "\n",
        "#         if ( found_right or found_wrong ):\n",
        "\n",
        "#             # print(\"FOUND SOMETHING\")\n",
        "\n",
        "#             # if(found_right != None):\n",
        "#             #     print(found_right)\n",
        "\n",
        "#             # if(found_wrong != None):\n",
        "#             #     print(found_wrong)\n",
        "\n",
        "#             j = i\n",
        "\n",
        "#             # j+1 because of alternatives starting with \\n\n",
        "#             #while question[j+1] != \"\\n\" and question[j+1] != '<|endoftext|>':\n",
        "#             while question[j] != \"\\n\" and question[j] != '<|endoftext|>':\n",
        "#                 j += 1\n",
        "\n",
        "#             alternatives.append( { 'start': (i + pergunta_pos), 'end': (j + pergunta_pos) } )\n",
        "#             # alternatives.append( { 'start': (i), 'end': (j) } )\n",
        "\n",
        "#             # print(repr(\"\".join(question[i:i+j])))\n",
        "#             # print(alternatives)\n",
        "#             # print(len(alternatives))\n",
        "\n",
        "#             found_right = None\n",
        "#             found_wrong = None\n",
        "\n",
        "#     # POG\n",
        "#     # Sometimes '(A) ERRADA' is matched twice\n",
        "#     if (len(alternatives) == 10):\n",
        "#         alternatives = alternatives[0:10:2]\n",
        "\n",
        "#     # for alt in alternatives:\n",
        "\n",
        "#     #     start = alt['start']\n",
        "#     #     end = alt['end']\n",
        "\n",
        "#     #     print(repr(''.join(question[start:end])))\n",
        "\n",
        "#     # Alternatives positions from reference of last question\n",
        "#     return alternatives\n",
        "\n",
        "# def evaluate_response(response, cot = []):\n",
        "\n",
        "#     text = response[\"choices\"][0]['text']\n",
        "#     tokens = response[\"choices\"][0][\"logprobs\"]['tokens']\n",
        "#     logprobs = response[\"choices\"][0][\"logprobs\"]['token_logprobs']\n",
        "\n",
        "#     # print(text)\n",
        "#     # print(repr(text))\n",
        "#     # print(tokens)\n",
        "#     # print()\n",
        "\n",
        "#     pergunta = ['########', '####', '\\n', '#', ' PER', 'G', 'UN', 'TA', ' #', '\\n', '########', '####']\n",
        "#     pergunta_pos = 0\n",
        "\n",
        "#     for i in range(len(tokens)):\n",
        "\n",
        "#         question = ''.join(tokens[i:i+len(pergunta)])\n",
        "#         res = re.search(''.join(pergunta), question)\n",
        "\n",
        "#         if (res != None):\n",
        "#             pergunta_pos = i\n",
        "\n",
        "#     question = tokens[pergunta_pos:]\n",
        "\n",
        "#     # print(pergunta_pos)\n",
        "#     # print(tokens[pergunta_pos:pergunta_pos+15])\n",
        "#     # print(question)\n",
        "#     # print(\"\".join(question))\n",
        "\n",
        "#     alternatives = get_alternatives_positions(question, pergunta_pos, cot)\n",
        "\n",
        "#     # print(len(alternatives))\n",
        "\n",
        "#     # for alt in alternatives:\n",
        "\n",
        "#     #     start = alt['start']\n",
        "#     #     end = alt['end']\n",
        "\n",
        "#     #     print(repr(''.join(tokens[start:end])))\n",
        "#     # #     print(''.join(tokens[start:end]))\n",
        "\n",
        "#             # print()\n",
        "#             # print(\"$$$$$$$$$$$$$$\")\n",
        "#             # print(tokens)\n",
        "#             # print(last_question_pos)\n",
        "#             # print(alternatives)\n",
        "#             # print(logprobs)\n",
        "#             # print(len(alternatives))\n",
        "#             # print(\"$$$$$$$$$$$$$$\")\n",
        "#             # print()\n",
        "\n",
        "#     alternatives_logprobs = []\n",
        "#     alternatives_evaluation = []\n",
        "\n",
        "#     # print()\n",
        "\n",
        "#     for alt in alternatives:\n",
        "\n",
        "#         start = alt['start']\n",
        "#         end = alt['end']\n",
        "\n",
        "#         # if (tokens[end+1] == '<|endoftext|>'):\n",
        "#         #     end += 1\n",
        "\n",
        "#         alt_logprobs = list(map(float, logprobs[start:end]))\n",
        "#         alt_n_toks = end - start\n",
        "#         prob = math.exp( (math.fsum(alt_logprobs) / alt_n_toks) )\n",
        "\n",
        "#         # print(repr(''.join(tokens[start:end])))\n",
        "#         # print(logprobs[start:end])\n",
        "\n",
        "#         # print(prob)\n",
        "#         # print(logprobs[start:end])\n",
        "#         # print()\n",
        "\n",
        "#         if(cot):\n",
        "#             # ['A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' COR', 'RE', 'TA]\n",
        "#             #                                          ^\n",
        "#             alternatives_logprobs.append( {'alternative': tokens[start + 5],\n",
        "#                                           'text':''.join(tokens[start:end]),\n",
        "#                                           'prob': prob,\n",
        "#                                           'temp_sum': math.fsum(alt_logprobs),\n",
        "#                                           'temp_alt_n_toks': alt_n_toks} )\n",
        "#         else:\n",
        "\n",
        "#             if ( tokens[start] == '(' ):\n",
        "#                 # (C) ERRADA.\n",
        "#                 _0sh_start = start + 1\n",
        "#             else:\n",
        "#                 # C) ERRADA.\n",
        "#                 _0sh_start = start\n",
        "\n",
        "#             alternatives_logprobs.append( {'alternative': tokens[_0sh_start],\n",
        "#                                           'text':''.join(tokens[start:end]),\n",
        "#                                           'prob': prob,\n",
        "#                                           'temp_sum': math.fsum(alt_logprobs),\n",
        "#                                           'temp_alt_n_toks': alt_n_toks} )\n",
        "\n",
        "#         #alternatives_evaluation.append(alternatives_logprobs[-1])\n",
        "\n",
        "#     model_right_answer = max(alternatives_logprobs, key=lambda x:x['prob'])\n",
        "\n",
        "#     #print(model_right_answer)\n",
        "\n",
        "#     # print(alternatives_evaluation)\n",
        "\n",
        "#     return model_right_answer, alternatives_logprobs\n",
        "\n",
        "# ###################\n",
        "# # CHANGE COT HERE #\n",
        "# ###################\n",
        "\n",
        "# model_right_answer, alternatives_evaluation = evaluate_response(response)\n",
        "# # model_right_answer, alternatives_evaluation = evaluate_response(response, cot)\n",
        "\n",
        "# print(model_right_answer['alternative'])\n",
        "\n",
        "# for alt in alternatives_evaluation:\n",
        "#     print(alt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4dRT9TbZSSZ4"
      },
      "outputs": [],
      "source": [
        "#@title # IMPORTANT DEBUG CELL 0 #\n",
        "\n",
        "# toks = tokenizer(cmd, max_length = max_length, padding = True, truncation = True)\n",
        "\n",
        "# len_cmd = len(cmd)\n",
        "# len_tokens = len(tokenizer.decode(toks['input_ids']))-2\n",
        "\n",
        "# print(len_cmd)\n",
        "# print(len_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tlubq6Z2Wnz7"
      },
      "outputs": [],
      "source": [
        "#@title # IMPORTANT DEBUG CELL 1 #\n",
        "\n",
        "# s = ['\\n', 'A', ' altern', 'at', 'iva', ' (', 'E', ')', ' est', 'á', ' COR', 'RE', 'TA']\n",
        "# string = ''.join(s)\n",
        "\n",
        "# correta_toks = ['\\n', 'A', ' altern', 'at', 'iva', ' \\(', '[ABCDE]{1}', '\\)', ' est', 'á', ' COR', 'RE', 'TA']\n",
        "# correta_str = \"\".join(correta_toks)\n",
        "# correta_len = len(correta_str)\n",
        "\n",
        "# print(f'correta_len: {correta_len}')\n",
        "# print(f\"s: {len(string)}\")\n",
        "\n",
        "# right = ''.join(s[0:13])\n",
        "# found_right = re.search(correta_str, right)\n",
        "\n",
        "# print(repr(correta_str))\n",
        "# print(repr(right))\n",
        "\n",
        "# print(found_right)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# s = ['\\n', 'A', ')', ' COR', 'RE', 'TA', '.']\n",
        "# string = ''.join(s)\n",
        "\n",
        "# correta_0sh = ['\\n', '[ABCDE]{1}', '\\)', ' COR', 'RE', 'TA', '.']\n",
        "# correta_str = \"\".join(correta_0sh)\n",
        "# correta_len = len(correta_str)\n",
        "\n",
        "# print(f'correta_len: {correta_len}')\n",
        "# print(f\"s: {len(string)}\")\n",
        "\n",
        "# right = ''.join(s)\n",
        "# found_right = re.search(correta_str, right)\n",
        "\n",
        "# print(repr(correta_str))\n",
        "# print(repr(right))\n",
        "\n",
        "# print(found_right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twoUnzTAuxnB"
      },
      "outputs": [],
      "source": [
        "#=========#\n",
        "# OLD COT #\n",
        "#=========#\n",
        "\n",
        "# cot = []\n",
        "\n",
        "# decide_after = 0\n",
        "\n",
        "# if(decide_after):\n",
        "#     cot1 = 'Cabeçalho:\\nSegundo Aristóteles, “na cidade com o melhor conjunto de normas e naquela dotada de homens absolutamente justos, os cidadãos não devem viver uma vida de trabalho trivial ou de negócios — esses tipos de vida são desprezíveis e incompatíveis com as qualidades morais —, tampouco devem ser agricultores os aspirantes à cidadania, pois o lazer é indispensável ao desenvolvimento das qualidades morais e à prática das atividades políticas”. VAN ACKER, T. Grécia. A vida cotidiana na cidade-Estado. São Paulo: Atual, 1994.\\n\\nEnunciado:\\nO trecho, retirado da obra Política, de Aristóteles, permite compreender que a cidadania\\n\\nAlternativas:\\n(A) possui uma dimensão histórica que deve ser criticada, pois é condenável que os políticos de qualquer época fiquem entregues à ociosidade, enquanto o resto dos cidadãos tem de trabalhar.\\n(B) era entendida como uma dignidade própria dos grupos sociais superiores, fruto de uma concepção política profundamente hierarquizada da sociedade.\\n(C) estava vinculada, na Grécia Antiga, a uma percepção política democrática, que levava todos os habitantes da pólis a participarem da vida cívica.\\n(D) tinha profundas conexões com a justiça, razão pela qual o tempo livre dos cidadãos deveria ser dedicado às atividades vinculadas aos tribunais.\\n(E) vivida pelos atenienses era, de fato, restrita àqueles que se dedicavam à política e que tinham tempo para resolver os problemas da cidade.\\n\\nExplicação:\\nA alternativa (A) faz um julgamento de valor de uma passagem histórica. Não responde o que é cidadania conforme o texto. Portanto, a alternativa (A) está está ERRADA.\\nA alternativa (B) interpreta acertadamente a sentença estabelecida por Aristóteles, que vincula o direito à cidadania a um grupo seleto de indivíduos limitando o pleno gozo da cidadania restringindo a um seleto grupo de pessoas superiores. Portanto, a alternativa (B) está está CORRETA.\\nA alternativa (C) interpreta equivocadamente que todos habitantes teriam o mesmo direito cívico. O cabeçalho descreve que agricultores ou negociantes não deveriam ter o mesmo direito ao lazer como os políticos superiores. Portanto, a alternativa (C) está ERRADA.\\nA alternativa (D) interpreta equivocadamente o texto já que o cabeçalho não diz nada sobre tempo livre dos cidadãos e de que deveriam se dedicar aos tribunais. Portanto, a alternativa (D) está ERRADA.\\nA alternativa (E) interpreta equivocadamente o texto dizendo que os que tinham direito a cidadania eram aqueles que tinham tempo para se dedicar a política. Mas isso não é mencionado no cabeçalho. Ao contrário o texto restringe a cidadania a um seleto grupo de pessoas superiores. Portanto, a alternativa (E) está ERRADA.'\n",
        "#     cot2 = 'Cabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\n(A) induzir a imunidade, para proteger o organismo da contaminação viral.\\n(B) ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\n(C) produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\n(D) ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\n(E) estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\nA alternativa (A) interpreta acertadamente que precisamos induzir imunidade de um organismo para protegê-lo contra futura infecções. Portanto, a alternativa (A) está CORRETA.\\nA alternativa (B) interpreta equivocadamente que é necessário fazer mudanças no genoma de um organismo. Portanto, a alternativa (B) está ERRADA.\\nA alternativa (C) interpreta equivocadamente que antígenos se ligam a moléculas de anticorpos ou receptores de células e não ao vírus. Portanto, a alternativa (C) está ERRADA.\\nA alternativa (D) interpreta equivocadamente que HIV só é transmitido de animais para seres humanos. Portanto, a alternativa (D) está ERRADA.\\nA alternativa (E) interpretaq equivocadamente que HIV é transmitido por gotículas de saliva. Portanto, a alternativa (E) está ERRADA.'\n",
        "#     cot3 = 'Cabeçalho:\\nUrgência emocional. Se tudo é para ontem, se a vida engata uma primeira e sai em disparada, se não há mais tempo para paradas estratégicas, caímos fatalmente no vício de querer que os amores sejam igualmente resolvidos num átimo de segundo. Temos pressa para ouvir \"eu te amo\". Não vemos a hora de que fiquem estabelecidas as regras de convívio: somos namorados, ficantes, casados, amantes? Urgência emocional. Uma cilada. Associamos diversas palavras ao AMOR: paixão, romance, sexo, adrenalina, palpitação. Esquecemos, no entanto, da palavra que viabiliza esse sentimento: \"paciência\". Amor sem paciência não vinga. Amor não pode ser mastigado e engolido com emergência, com fome desesperada. É uma refeição que pode durar uma vida. MEDEIROS, M. Disponível em: http://porumavidasimples.blogspot.com.br. Acesso em: 20 ago. 2017 (adaptado).\\n\\nEnunciado:\\nNesse texto de opinião, as marcas linguísticas revelam uma situação distensa e de pouca formalidade, o que se evidencia pelo(a)\\n\\nAlternativas:\\n(A) impessoalização ao longo do texto, como em: \"se não há mais tempo\".\\n(B) construção de uma atmosfera de urgência, em palavras como: \"pressa\".\\n(C) repetição de uma determinada estrutura sintática, como em: \"Se tudo é para ontem\".\\n(D) ênfase no emprego da hipérbole, como em: \"uma refeição que pode durar uma vida\".\\n(E) emprego de metáforas, como em: \"a vida engata uma primeira e sai em disparada\".\\n\\nExplicação:\\nA alternativa (A) interpreta erroneamente que a impessoalização não é uma marca de pouca formalidade. Aliás, na sentença apontada na alternativa, o uso do verbo haver seria uma marca de formalidade. Portanto, a alternativa (A) está ERRADA.\\nA alternativa (B) interpreta erroneamente o uso da palavra pressa, pois embora que o texto até tenha criado uma atmosfera de urgência, o texto na verdade fala exatamente sobre a importância da paciência e não da pressa. Portanto, a alternativa (B) está ERRADA.\\nA alternativa (C) interpreta erroneamente que a estrutura sintática é repetida sistematicamente ao longo do texto. Portanto, a alternativa (C) está ERRADA.\\nA alternativa (D) interpreta erroneamente que o texto enfatiza essa figura de linguagem, pois, para afirmar isto, a figura de linguagem deveria aparecer mais vezes. Portanto a alternativa (D) está ERRADA.\\nA alternativa (E) interpreta acertadamente que o texto possui comparações implícitas que se caracterizam como emprego de metáforas. Portanto, a alternativa (E) está CORRETA.'\n",
        "# else:\n",
        "#     cot1 = 'Cabeçalho:\\nSegundo Aristóteles, “na cidade com o melhor conjunto de normas e naquela dotada de homens absolutamente justos, os cidadãos não devem viver uma vida de trabalho trivial ou de negócios — esses tipos de vida são desprezíveis e incompatíveis com as qualidades morais —, tampouco devem ser agricultores os aspirantes à cidadania, pois o lazer é indispensável ao desenvolvimento das qualidades morais e à prática das atividades políticas”. VAN ACKER, T. Grécia. A vida cotidiana na cidade-Estado. São Paulo: Atual, 1994.\\n\\nEnunciado:\\nO trecho, retirado da obra Política, de Aristóteles, permite compreender que a cidadania\\n\\nAlternativas:\\n(A) possui uma dimensão histórica que deve ser criticada, pois é condenável que os políticos de qualquer época fiquem entregues à ociosidade, enquanto o resto dos cidadãos tem de trabalhar.\\n(B) era entendida como uma dignidade própria dos grupos sociais superiores, fruto de uma concepção política profundamente hierarquizada da sociedade.\\n(C) estava vinculada, na Grécia Antiga, a uma percepção política democrática, que levava todos os habitantes da pólis a participarem da vida cívica.\\n(D) tinha profundas conexões com a justiça, razão pela qual o tempo livre dos cidadãos deveria ser dedicado às atividades vinculadas aos tribunais.\\n(E) vivida pelos atenienses era, de fato, restrita àqueles que se dedicavam à política e que tinham tempo para resolver os problemas da cidade.\\n\\nExplicação:\\nA alternativa (A) está ERRADA porque faz um julgamento de valor de uma passagem histórica. Não responde o que é cidadania conforme o texto.\\nA alternativa (B) está CORRETA porque interpreta acertadamente a sentença estabelecida por Aristóteles, que vincula o direito à cidadania a um grupo seleto de indivíduos limitando o pleno gozo da cidadania restringindo a um seleto grupo de pessoas superiores.\\nA alternativa (C) está ERRADA porque interpreta equivocadamente que todos habitantes teriam o mesmo direito cívico. O cabeçalho descreve que agricultores ou negociantes não deveriam ter o mesmo direito ao lazer como os políticos superiores.\\nA alternativa (D) está ERRADA porque interpreta equivocadamente o texto já que o cabeçalho não diz nada sobre tempo livre dos cidadãos e de que deveriam se dedicar aos tribunais.\\nA alternativa (E) está ERRADA porque interpreta equivocadamente o texto dizendo que os que tinham direito a cidadania eram aqueles que tinham tempo para se dedicar a política. Mas isso não é mencionado no cabeçalho. Ao contrário o texto restringe a cidadania a um seleto grupo de pessoas superiores.'\n",
        "#     cot2 = 'Cabeçalho:\\nEstima-se que haja atualmente no mundo 40 milhões de pessoas infectadas pelo HIV (o vírus que causa a AIDS), sendo que as taxas de novas infecções continuam crescendo, principalmente na África, Ásia e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV teria imenso impacto, pois salvaria milhões de vidas. Certamente seria um marco na história planetária e também uma esperança para as populações carentes de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado).\\n\\nEnunciado:\\nConsiderando o texto, uma vacina eficiente contra o HIV deveria:\\n\\nAlternativas:\\n(A) induzir a imunidade, para proteger o organismo da contaminação viral.\\n(B) ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras.\\n(C) produzir antígenos capazes de se ligarem ao vírus, impedindo que este entre nas células do organismo humano.\\n(D) ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos.\\n(E) estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva.\\n\\nExplicação:\\nA alternativa (A) está CORRETA porque precisamos induzir imunidade de um organismo para protegê-lo contra futura infecções.\\nA alternativa (B) está ERRADA pois não é possível fazer mudanças no genoma de um organismo.\\nA alternativa (C) está ERRADA pois antígenos não se ligam ao vírus.\\nA alternativa (D) está ERRADA pois pois HIV também é transmitido em humanos.\\nA alternativa (E) está ERRADA pois HIV não se transmite por gotículas de saliva.'\n",
        "#     cot3 = 'Cabeçalho:\\nUrgência emocional. Se tudo é para ontem, se a vida engata uma primeira e sai em disparada, se não há mais tempo para paradas estratégicas, caímos fatalmente no vício de querer que os amores sejam igualmente resolvidos num átimo de segundo. Temos pressa para ouvir \"eu te amo\". Não vemos a hora de que fiquem estabelecidas as regras de convívio: somos namorados, ficantes, casados, amantes? Urgência emocional. Uma cilada. Associamos diversas palavras ao AMOR: paixão, romance, sexo, adrenalina, palpitação. Esquecemos, no entanto, da palavra que viabiliza esse sentimento: \"paciência\". Amor sem paciência não vinga. Amor não pode ser mastigado e engolido com emergência, com fome desesperada. É uma refeição que pode durar uma vida. MEDEIROS, M. Disponível em: http://porumavidasimples.blogspot.com.br. Acesso em: 20 ago. 2017 (adaptado).\\n\\nEnunciado:\\nNesse texto de opinião, as marcas linguísticas revelam uma situação distensa e de pouca formalidade, o que se evidencia pelo(a)\\n\\nAlternativas:\\n(A) impessoalização ao longo do texto, como em: \"se não há mais tempo\".\\n(B) construção de uma atmosfera de urgência, em palavras como: \"pressa\".\\n(C) repetição de uma determinada estrutura sintática, como em: \"Se tudo é para ontem\".\\n(D) ênfase no emprego da hipérbole, como em: \"uma refeição que pode durar uma vida\".\\n(E) emprego de metáforas, como em: \"a vida engata uma primeira e sai em disparada\".\\n\\nExplicação:\\nA alternativa (A) está ERRADA porque impessoalização não é uma marca de pouca formalidade. Aliás, na sentença apontada na alternativa, o uso do verbo haver seria uma marca de formalidade.\\nA alternativa (B) está ERRADA porque o texto até criou uma atmosfera de urgência, embora tenha sido para criticá-la. Na verdade o texto fala exatamente sobre a importância da paciência e não da pressa.\\nA alternativa (C) está ERRADA porque a estrutura sintática não é repetida sistematicamente ao longo do texto.\\nA alternativa (D) está ERRADA porque, embora possua hipérboles, para afirmar que o texto enfatiza essa figura de linguagem, ela deveria aparecer mais vezes.\\nA alternativa (E) está CORRETA porque o texto possui comparações implícitas que se caracterizam como metáforas. Logo o texto emprega metáforas.'\n",
        "\n",
        "# cmd_cot = 'Abaixo está uma lista de exemplos extraídos da prova do ENEM. Com base no cabeçalho e enunciado, para cada uma das alternativas (A, B, C, D, E) decida se a pergunta está ERRADA ou CORRETA e dê uma explicação para cada alternativa. Apenas uma alternativa é CORRETA.'\n",
        "\n",
        "###################\n",
        "# 0SHOT/COT SETUP #\n",
        "###################\n",
        "\n",
        "decide_after = 1\n",
        "\n",
        "#=======#\n",
        "# 0SHOT #\n",
        "#=======#\n",
        "\n",
        "# MELHOR ?\n",
        "# Explica só a 13, mas nao o resto\n",
        "# cmd_0shot = \"Com base no cabeçalho e enunciado, responda a pergunta de múltipla escolha abaixo. Resposta desejada: para cada alternativa (A, B, C, D, E), classifique como CORRETA ou ERRADA e dê uma explicação.\"\n",
        "\n",
        "cmd_0shot = \"Com base no cabeçalho e enunciado, responda a pergunta de múltipla escolha abaixo. Resposta desejada: classifique cada alternativa (A, B, C, D, E) como CORRETA ou ERRADA e dê uma explicação.\"\n",
        "\n",
        "#=====#\n",
        "# COT #\n",
        "#=====#\n",
        "\n",
        "# cmd_cot = \"Com base no cabeçalho e enunciado, para cada uma das alternativas (A, B, C, D, E) decida se a pergunta está ERRADA ou CORRETA e dê uma explicação para cada alternativa. Apenas uma alternativa é CORRETA.\"\n",
        "# cmd_cot = \"Formule uma explicação em cadeia que permita responder à questão de múltipla escolha abaixo. Apenas uma alternativa é CORRETA. Formato desejado: para cada alternativa, escreva uma sentença que classifica a alternativa como CORRETA ou ERRADA e justifica a resposta.\"\n",
        "# cmd_cot = \"Formule uma explicação em cadeia que permita responder à questão de múltipla escolha abaixo. Com base no cabeçalho e enunciado, para cada uma das alternativas (A, B, C, D, E) decida se a pergunta está ERRADA ou CORRETA e dê uma explicação para cada alternativa. Apenas uma alternativa é CORRETA.\"\n",
        "cmd_cot = cmd_0shot\n",
        "\n",
        "#########\n",
        "# COT 1 #\n",
        "#########\n",
        "\n",
        "header1 = \"Urgência emocional. Se tudo é para ontem, se a vida engata uma primeira e sai em disparada, se não há mais tempo para paradas estratégicas, caímos fatalmente no vício de querer que os amores sejam igualmente resolvidos num átimo de segundo. Temos pressa para ouvir \\\"eu te amo\\\". Não vemos a hora de que fiquem estabelecidas as regras de convívio: somos namorados, ficantes, casados, amantes? Urgência emocional. Uma cilada. Associamos diversas palavras ao AMOR: paixão, romance, sexo, adrenalina, palpitação. Esquecemos, no entanto, da palavra que viabiliza esse sentimento: \\\"paciência\\\". Amor sem paciência não vinga. Amor não pode ser mastigado e engolido com emergência, com fome desesperada. É uma refeição que pode durar uma vida. MEDEIROS, M. Disponível em: http://porumavidasimples.blogspot.com.br. Acesso em: 20 ago. 2017 (adaptado).\"\n",
        "statem1 = \"Nesse texto de opinião, as marcas linguísticas revelam uma situação distensa e de pouca formalidade, o que se evidencia pelo(a)\"\n",
        "altA = \"impessoalização ao longo do texto, como em: \\\"se não há mais tempo\\\".\"\n",
        "altB = \"construção de uma atmosfera de urgência, em palavras como: \\\"pressa\\\".\"\n",
        "altC = \"repetição de uma determinada estrutura sintática, como em: \\\"Se tudo é para ontem\\\".\"\n",
        "altD = \"ênfase no emprego da hipérbole, como em: \\\"uma refeição que pode durar uma vida\\\".\"\n",
        "altE = \"emprego de metáforas, como em: \\\"a vida engata uma primeira e sai em disparada\\\".\"\n",
        "\n",
        "question1 = \"Cabeçalho:\\n\" + header1 + \"\\n\\n\" + \"Enunciado:\\n\" + statem1 + \"\\n\\n\" + \"Alternativas:\\n\" + \"(A) \" + altA + \"\\n(B) \" + altB + \"\\n(C) \" + altC+ \"\\n(D) \" + altD+ \"\\n(E) \" + altE\n",
        "\n",
        "if(decide_after):\n",
        "    expA = \"A alternativa (A) interpreta erroneamente que a impessoalização não é uma marca de pouca formalidade, inclusive o uso do verbo haver representa uma marca de formalidade. Portanto, a alternativa (A) está ERRADA.\"\n",
        "    expB = \"A alternativa (B) interpreta erroneamente que o texto até criou uma atmosfera de urgência, embora tenha sido para criticá-la, e discute exatamente a importância da paciência e não da pressa. Portanto, a alternativa (B) está ERRADA.\"\n",
        "    expC = \"A alternativa (C) interpreta erroneamente que a estrutura sintática não é repetida sistematicamente ao longo do texto. Portanto, a alternativa (C) está ERRADA.\"\n",
        "    expD = \"A alternativa (D) interpreta erroneamente que, embora o texto possua hipérboles, para afirmar que a figura de linguagem é enfatizada, ela deveria aparecer mais vezes. Portanto, a alternativa (D) está ERRADA.\"\n",
        "    expE = \"A alternativa (E) interpreta corretamente que o texto possui comparações implícitas que se caracterizam como metáforas. Logo o texto emprega metáforas. Portanto, a alternativa (E) está CORRETA.\"\n",
        "else:\n",
        "    expA = \"A alternativa (A) está ERRADA porque impessoalização não é uma marca de pouca formalidade, inclusive o uso do verbo haver representa uma marca de formalidade.\"\n",
        "    expB = \"A alternativa (B) está ERRADA porque o texto até criou uma atmosfera de urgência, embora tenha sido para criticá-la, e discute exatamente a importância da paciência e não da pressa.\"\n",
        "    expC = \"A alternativa (C) está ERRADA porque a estrutura sintática não é repetida sistematicamente ao longo do texto.\"\n",
        "    expD = \"A alternativa (D) está ERRADA porque, embora o texto possua hipérboles, para afirmar que a figura de linguagem é enfatizada, ela deveria aparecer mais vezes.\"\n",
        "    expE = \"A alternativa (E) está CORRETA porque o texto possui comparações implícitas que se caracterizam como metáforas. Logo o texto emprega metáforas.\"\n",
        "\n",
        "cot1 = question1 + \"\\n\\nExplicação:\\n\" + expA + \"\\n\" + expB + \"\\n\" + expC + \"\\n\" + expD + \"\\n\" + expE\n",
        "\n",
        "#########\n",
        "# COT 2 #\n",
        "#########\n",
        "\n",
        "header2 = \"Sempre que a relevância do discurso entra em jogo, a questão torna-se política por definição, pois é o discurso que faz do homem um ser político. E tudo que os homens fazem, sabem ou experimentam só tem sentido na medida em que pode ser discutido. Haverá, talvez, verdades que ficam além da linguagem e que podem ser de grande relevância para o homem no singular, isto é, para o homem que, seja o que for, não é um ser político. Mas homens no plural, isto é, os homens que vivem e se movem e agem neste mundo, só podem experimentar o significado das coisas por poderem falar e ser inteligíveis entre si e consigo mesmos. ARENDT, H. A condição humana. Rio de Janeiro: Forense Universitária, 2004.\"\n",
        "statem2 = \"No trecho, a filósofa Hannah Arendt mostra a importância da linguagem no processo de\"\n",
        "altA = \"entendimento da cultura.\"\n",
        "altB = \"aumento da criatividade.\"\n",
        "altC = \"percepção da individualidade.\"\n",
        "altD = \"melhoria da técnica.\"\n",
        "altE = \"construção da sociabilidade.\"\n",
        "\n",
        "question2 = \"Cabeçalho:\\n\" + header2 + \"\\n\\n\" + \"Enunciado:\\n\" + statem2 + \"\\n\\n\" + \"Alternativas:\\n\" + \"(A) \" + altA + \"\\n(B) \" + altB + \"\\n(C) \" + altC+ \"\\n(D) \" + altD+ \"\\n(E) \" + altE\n",
        "\n",
        "if(decide_after):\n",
        "    expA = \"A alternativa (A) interpreta erroneamente que Hannah Arendt não trata do entendimento da cultura, mas da relação social entre as pessoas dessa cultura. Portanto, a alternativa (A) está ERRADA.\"\n",
        "    expB = \"A alternativa (B) interpreta erroneamente que Hannah Arendt não fala sobre criatividade, mas sobre a construção de laços entre as pessoas. Portanto, a alternativa (B) está ERRADA.\"\n",
        "    expC = \"A alternativa (C) interpreta erroneamente que a linguagem é utilizada no oposto da individualidade, em algo mais coletivo e social. Portanto, a alternativa (C) está ERRADA.\"\n",
        "    expD = \"A alternativa (D) interpreta erroneamente que o texto não fala de técnica, mas de laços. Portanto, a alternativa (D) está ERRADA.\"\n",
        "    expE = \"A alternativa (E) interpreta corretamente que a nossa sociabilidade se constrói a partir da linguagem, o que faz de nós seres políticos, no sentido de viver em sociedade, em ambientes coletivos. Portanto, a alternativa (E) está CORRETA.\"\n",
        "else:\n",
        "    expA = \"A alternativa (A) está ERRADA porque Hannah Arendt não trata do entendimento da cultura, mas da relação social entre as pessoas dessa cultura.\"\n",
        "    expB = \"A alternativa (B) está ERRADA porque Hannah Arendt não fala sobre criatividade, mas sobre a construção de laços entre as pessoas.\"\n",
        "    expC = \"A alternativa (C) está ERRADA porque a linguagem é utilizada no oposto da individualidade, em algo mais coletivo e social.\"\n",
        "    expD = \"A alternativa (D) está ERRADA porque o texto não fala de técnica, mas de laços.\"\n",
        "    expE = \"A alternativa (E) está CORRETA porque a nossa sociabilidade se constrói a partir da linguagem, o que faz de nós seres políticos, no sentido de viver em sociedade, em ambientes coletivos.\"\n",
        "\n",
        "cot2 = question2 + \"\\n\\nExplicação:\\n\" + expA + \"\\n\" + expB + \"\\n\" + expC + \"\\n\" + expD + \"\\n\" + expE\n",
        "\n",
        "#######\n",
        "# COT #\n",
        "#######\n",
        "\n",
        "cot = []\n",
        "cot.append(cot1)\n",
        "cot.append(cot2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-IkVrvtXFHU",
        "outputId": "73b0e7cd-a98d-4c7f-d2ac-8c475ed9eddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "##############\n",
            "# Questão 89 #\n",
            "##############\n",
            "\n",
            "Ano/Versão: 2010-1\n",
            "\n",
            "Cabeçalho:\n",
            "\n",
            "Antes, eram apenas as grandes cidades que se apresentavam como o império da técnica, objeto de\n",
            "modificações, suspensões, acréscimos, cada vez mais sofisticadas e carregadas de artifício. Esse mundo artificial inclui,\n",
            "hoje, o mundo rural. SANTOS, M. A Natureza do Espaço. São Paulo: Hucitec, 1996. \n",
            "\n",
            "Enunciado:\n",
            "\n",
            "Considerando a transformação mencionada no texto, uma consequência socioespacial que caracteriza o atual mundo rural brasileiro\n",
            "é \n",
            "\n",
            "Alternativas:\n",
            " A  - a redução do processo de concentração de terras.\n",
            "[B] - o aumento do aproveitamento de solos menos férteis.\n",
            " C  - a ampliação do isolamento do espaço rural.\n",
            " D  - a estagnação da fronteira agrícola do país.\n",
            " E  - a diminuição do nível de emprego formal.\n",
            "\n",
            "###############\n",
            "# 0-shot test #\n",
            "###############\n",
            "\n",
            "0shot answer: C\n",
            "0shot prob: 0.8775152886746171\n",
            "0shot text: 'C) CORRETA - A ampliação do isolamento do espaço rural é uma consequência socioespacial que caracteriza o atual mundo rural brasileiro, pois a reforma agrária tem contribuído para a diminuição da concentração de terras, o que acaba por aumentar o isolamento do espaço rural.'\n",
            "\n",
            "{'alternative': 'A', 'text': 'A) CORRETA - A redução do processo de concentração de terras é uma consequência socioespacial que caracteriza o atual mundo rural brasileiro, pois a reforma agrária tem contribuído para a diminuição da concentração de terras.', 'prob': 0.760733400020271, 'temp_sum': -20.51042332412147, 'temp_alt_n_toks': 75}\n",
            "{'alternative': 'B', 'text': 'B) ERRADA - O aumento do aproveitamento de solos menos férteis não é uma consequência socioespacial que caracteriza o atual mundo rural brasileiro, pois a reforma agrária tem contribuído para a diminuição da concentração de terras, não para o aumento do aproveitamento de solos menos férteis.', 'prob': 0.11754088049059896, 'temp_sum': -13.25453836347317, 'temp_alt_n_toks': 106}\n",
            "{'alternative': 'C', 'text': 'C) CORRETA - A ampliação do isolamento do espaço rural é uma consequência socioespacial que caracteriza o atual mundo rural brasileiro, pois a reforma agrária tem contribuído para a diminuição da concentração de terras, o que acaba por aumentar o isolamento do espaço rural.', 'prob': 0.8775152886746171, 'temp_sum': -12.28212467547054, 'temp_alt_n_toks': 94}\n",
            "{'alternative': 'D', 'text': 'D) ERRADA - A estagnação da fronteira agrícola do país não é uma consequência socioespacial que caracteriza o atual mundo rural brasileiro, pois a reforma agrária tem contribuído para a diminuição da concentração de terras, não para a estagnação da fronteira agrícola do país.', 'prob': 0.010157314968102238, 'temp_sum': -1.0209252488265101, 'temp_alt_n_toks': 100}\n",
            "{'alternative': 'E', 'text': 'E) ERRADA - A diminuição do nível de emprego formal não é uma consequência socioespacial que caracteriza o atual mundo rural brasileiro, pois a reforma agrária tem contribuído para a diminuição da concentração de terras, não para a diminuição do nível de emprego formal.', 'prob': 0.000947529854802176, 'temp_sum': -0.08911003022858, 'temp_alt_n_toks': 94}\n",
            "\n",
            "#######################\n",
            "# (few/cot)-shot test #\n",
            "#######################\n",
            "\n",
            "cot-few-shot answer: C\n",
            "cot-few-shot prob: 0.8905008033740842\n",
            "cot-few-shot text: 'A alternativa (C) interpreta corretamente que o texto trata da transformação do mundo rural, que inclui o aumento do isolamento do espaço rural. Portanto, a alternativa (C) está CORRETA.'\n",
            "\n",
            "{'alternative': 'A', 'text': 'A alternativa (A) interpreta erroneamente que o texto trata da redução do processo de concentração de terras, quando, na verdade, ele trata da transformação do mundo rural. Portanto, a alternativa (A) está ERRADA.', 'prob': 0.18137130420544345, 'temp_fsum': -14.2088509180285, 'temp_alt_n_toks': 71}\n",
            "{'alternative': 'B', 'text': 'A alternativa (B) interpreta erroneamente que o texto trata do aproveitamento de solos menos férteis, quando, na verdade, ele trata da transformação do mundo rural. Portanto, a alternativa (B) está ERRADA.', 'prob': 0.024923625337789024, 'temp_fsum': -1.8172424206998, 'temp_alt_n_toks': 72}\n",
            "{'alternative': 'C', 'text': 'A alternativa (C) interpreta corretamente que o texto trata da transformação do mundo rural, que inclui o aumento do isolamento do espaço rural. Portanto, a alternativa (C) está CORRETA.', 'prob': 0.8905008033740842, 'temp_fsum': -7.3061902678054, 'temp_alt_n_toks': 63}\n",
            "{'alternative': 'D', 'text': 'A alternativa (D) interpreta erroneamente que o texto trata da estagnação da fronteira agrícola do país, quando, na verdade, ele trata da transformação do mundo rural. Portanto, a alternativa (D) está ERRADA.', 'prob': 0.006405930823986772, 'temp_fsum': -0.4691371897937, 'temp_alt_n_toks': 73}\n",
            "{'alternative': 'E', 'text': 'A alternativa (E) interpreta erroneamente que o texto trata da diminuição do nível de emprego formal, quando, na verdade, ele trata da transformação do mundo rural. Portanto, a alternativa (E) está ERRADA.', 'prob': 0.002075451212494306, 'temp_fsum': -0.14543255622062, 'temp_alt_n_toks': 70}\n",
            "\n",
            "###########\n",
            "# RESULTS #\n",
            "###########\n",
            "\n",
            "\u001b[91m0-shot explicado ERROU a resposta\u001b[0m\n",
            "\u001b[91mfew-shot-cot explicado ERROU a resposta\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#######################\n",
        "# QUERY ENEM QUESTION #\n",
        "#######################\n",
        "\n",
        "# PERTUNTA 11 (E) # \\o/\n",
        "# - 0shot sem explicaçao erra (C)\n",
        "# - 0shot com explicação acerta (E)\n",
        "# - few-shot-cot acerta (E) (mesmo tendo apontado duas CORRETAS)\n",
        "\n",
        "# PERGUNTA 13 (E) #\n",
        "# - 0shot sem explicaçao (D)\n",
        "# - 0shot com explicação erra (V = λ . f ?)\n",
        "# - few-shot-cot erra (até acerta no texto gerado, mas a alternativa perde nos logprobs)\n",
        "\n",
        "# PERGUNTA 16 (D) # \\o/\n",
        "# - 0shot sem explicaçao erra (B)\n",
        "# - 0shot com explicação erra (E)\n",
        "# - few-shot-cot acerta (D)\n",
        "\n",
        "# PERGUNTA 17 (B) #\n",
        "# - 0shot sem explicaçao erra (A)\n",
        "# - 0shot com explicação erra (D)\n",
        "# - few-shot-cot erra (D) (mas a certeza aumenta e a difença entre a B diminui)\n",
        "\n",
        "# PERGUNTA 55 (E) #\n",
        "# - 0shot sem explicaçao erra (A)\n",
        "# - 0shot com explicação erra (D)\n",
        "# - few-shot-cot erra (C)\n",
        "\n",
        "# PERGUNTA 89 (B) #\n",
        "# - 0shot sem explicaçao erra (C)\n",
        "# - 0shot com explicação erra (D)\n",
        "# - few-shot-cot erra (E) (mas a certeza aumenta e a difença entre a B diminui)\n",
        "\n",
        "# PERGUNTA 91 (B) #\n",
        "# - 0shot sem explicaçao erra (E)\n",
        "# - 0shot com explicação erra ()\n",
        "# - few-shot-cot erra ()\n",
        "\n",
        "question = 89\n",
        "# max_length = 1024\n",
        "\n",
        "############\n",
        "# QUESTION #\n",
        "############\n",
        "\n",
        "ENEM.print_question(question)\n",
        "#print()\n",
        "#print(f\"ENEM right answer: {ENEM.get_right_alternative(question)[0]}\")\n",
        "#print()\n",
        "\n",
        "##########\n",
        "# 0 SHOT #\n",
        "##########\n",
        "\n",
        "print(\"\\n###############\\n# 0-shot test #\\n###############\")\n",
        "\n",
        "parsed_question, openai_response, model_right_answer, alternatives_evaluation = OPENAI.ask_ENEM_question(question, cmd_0shot)\n",
        "\n",
        "print()\n",
        "print(f\"0shot answer: {model_right_answer['alternative']}\")\n",
        "print(f\"0shot prob: {model_right_answer['prob']}\")\n",
        "print(f\"0shot text: {repr(model_right_answer['text'])}\")\n",
        "print()\n",
        "for alt in alternatives_evaluation:\n",
        "    print(alt)\n",
        "\n",
        "_0shot_answer = model_right_answer['alternative']\n",
        "\n",
        "#################\n",
        "# FEW SHOTS COT #\n",
        "#################\n",
        "\n",
        "print(\"\\n#######################\\n# (few/cot)-shot test #\\n#######################\")\n",
        "\n",
        "parsed_question, openai_response, model_right_answer, alternatives_evaluation = OPENAI.ask_ENEM_question(question, cmd_cot, cot)\n",
        "\n",
        "print()\n",
        "print(f\"cot-few-shot answer: {model_right_answer['alternative']}\")\n",
        "print(f\"cot-few-shot prob: {model_right_answer['prob']}\")\n",
        "print(f\"cot-few-shot text: {repr(model_right_answer['text'])}\")\n",
        "print()\n",
        "for alt in alternatives_evaluation:\n",
        "    print(alt)\n",
        "\n",
        "few_cot_answer = model_right_answer['alternative']\n",
        "\n",
        "###########\n",
        "# RESULTS #\n",
        "###########\n",
        "\n",
        "print(\"\\n###########\\n# RESULTS #\\n###########\\n\")\n",
        "\n",
        "right_answer = ENEM.get_right_alternative(question)[0]\n",
        "\n",
        "if (_0shot_answer == right_answer):\n",
        "    print(f\"{bcolors.OKGREEN}0-shot explicado ACERTOU a resposta{bcolors.ENDC}\")\n",
        "else:\n",
        "    print(f\"{bcolors.FAIL}0-shot explicado ERROU a resposta{bcolors.ENDC}\")\n",
        "\n",
        "if (few_cot_answer == right_answer):\n",
        "    print(f\"{bcolors.OKGREEN}few-shot-cot explicado ACERTOU a resposta{bcolors.ENDC}\")\n",
        "else:\n",
        "    print(f\"{bcolors.FAIL}few-shot-cot explicado ERROU a resposta{bcolors.ENDC}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDc0Kg1hbk9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80d50dd-61c4-4aa9-a007-4dd0b81906c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############\n",
            "# PERGUNTA #\n",
            "############\n",
            "\n",
            "Cabeçalho:\n",
            "O progresso da tecnologia introduziu diversos artefatos geradores de campos eletromagnéticos. Uma das mais empregadas invençbytes:\\xc3bytes:\\xb5es nessabytes: \\xc3bytes:\\xa1rea são os telefones celulares e smartphones. As tecnologias de transmissão de celular atualmente em uso no Brasil contemplam dois sistemas. O primeiro deles é operado entre as frequências de 800 MHz e 900 MHz e constitui os chamados sistemas TDMA/CDMA. Já a tecnologia GSM, ocupa a frequência de 1.800 MHz.\n",
            "\n",
            "Enunciado:\n",
            "Considerando que a intensidade de transmissão e o nível de recepçãobytes: \\xe2\\x80bytes:\\x9ccelularbytes:\\xe2\\x80bytes:\\x9d sejam os mesmos para as tecnologias de transmissão TDMA/CDMA ou GSM, se um engenheiro tiver de escolher entre as duas tecnologias para obter a mesma cobertura, levando em consideração apenas o número de antenas em uma região, ele deverá escolher:\n",
            "\n",
            "Alternativas:\n",
            "(A) a tecnologia GSM, pois é a que opera com ondas de maior comprimento de onda.\n",
            "(B) a tecnologia TDMA/CDMA, pois é a que apresenta Efeito Doppler mais pronunciado.\n",
            "(C) a tecnologia GSM, pois é a que utiliza ondas que se propagam com maior velocidade.\n",
            "(D) qualquer uma das duas, pois as diferenças nas frequências são compensadas pelas diferenças nos comprimentos de onda.\n",
            "(E) qualquer uma das duas, pois nesse caso as intensidades decaem igualmente da mesma forma, independentemente da frequência.\n",
            "\n",
            "Explicação:\n",
            "A) A tecnologia GSM opera com ondas de maior comprimento de onda, mas isso não significa que ela tenha uma cobertura melhor.\n",
            "\n",
            "B) A tecnologia TDMA/CDMA apresenta Efeito Doppler mais pronunciado, mas isso não significa que ela tenha uma cobertura melhor.\n",
            "\n",
            "C) A tecnologia GSM utiliza ondas que se propagam com maior velocidade, mas isso não significa que ela tenha uma cobertura melhor.\n",
            "\n",
            "D) Qualquer uma das duas tecnologias pode ser escolhida, pois as diferenças nas frequências são compensadas pelas diferenças nos comprimentos de onda.\n",
            "\n",
            "E) Qualquer uma das duas tecnologias pode ser escolhida, pois nesse caso as intensidades decaem igualmente da mesma forma, independentemente da frequência.\n"
          ]
        }
      ],
      "source": [
        "#@title CHECK DATA FROM PLAYGROUND\n",
        "\n",
        "##############################\n",
        "# CHECK DATA FROM PLAYGROUND #\n",
        "##############################\n",
        "\n",
        "# ENEM.print_question(6)\n",
        "# ENEM.print_question(88)\n",
        "\n",
        "# print()\n",
        "# print(f\"A: {math.exp( -19.50 / 18 )}\")\n",
        "# print(f\"B: {math.exp( -21.99 / 23 )}\")\n",
        "# print(f\"C: {math.exp( -19.81 / 18 )}\")\n",
        "# print(f\"D: {math.exp( -22.02 / 20 )}\")\n",
        "# print(f\"E: {math.exp( -22.11 / 17 )}\")\n",
        "\n",
        "#################\n",
        "# PRINT RESULTS #\n",
        "#################\n",
        "\n",
        "# ENEM.print_question(11)\n",
        "# print(parsed_question)\n",
        "# print(openai_response[\"choices\"][0]['text'])\n",
        "# print(openai_response)\n",
        "\n",
        "# tokens = openai_response[\"choices\"][0][\"logprobs\"]['tokens']\n",
        "\n",
        "tokens = ['Com', ' base', ' no', ' c', 'abe', 'ç', 'al', 'ho', ' e', ' en', 'unci', 'ado', ',', ' para', ' c', 'ada', ' u', 'ma', ' d', 'as', ' altern', 'at', 'ivas', ' (', 'A', ',', ' B', ',', ' C', ',', ' D', ',', ' E', ')', ' dec', 'ida', ' se', ' a', ' per', 'g', 'unta', ' est', 'á', ' ER', 'R', 'ADA', ' o', 'u', ' COR', 'RE', 'TA', ' e', ' d', 'ê', ' u', 'ma', ' expl', 'ica', 'ç', 'ão', ' para', ' c', 'ada', ' altern', 'at', 'iva', '.', ' A', 'pen', 'as', ' u', 'ma', ' altern', 'at', 'iva', ' é', ' COR', 'RE', 'TA', '.', '\\n', '\\n', '########', '####', '\\n', '#', ' PER', 'G', 'UN', 'TA', ' #', '\\n', '########', '####', '\\n', '\\n', 'C', 'abe', 'ç', 'al', 'ho', ':', '\\n', 'O', ' prog', 'resso', ' da', ' te', 'cn', 'olog', 'ia', ' introdu', 'z', 'iu', ' divers', 'os', ' arte', 'fat', 'os', ' ger', 'ad', 'ores', ' de', ' camp', 'os', ' e', 'let', 'rom', 'agn', 'é', 'tic', 'os', '.', ' U', 'ma', ' d', 'as', ' m', 'ais', ' em', 'p', 'reg', 'adas', ' in', 'ven', 'ç', 'bytes:\\\\xc3', 'bytes:\\\\xb5', 'es', ' n', 'essa', 'bytes: \\\\xc3', 'bytes:\\\\xa1', 'rea', ' s', 'ão', ' os', ' tele', 'f', 'ones', ' cel', 'ul', 'ares', ' e', ' smartphones', '.', ' As', ' te', 'cn', 'olog', 'ias', ' de', ' trans', 'miss', 'ão', ' de', ' cel', 'ular', ' at', 'ual', 'ment', 'e', ' em', ' us', 'o', ' no', ' Bras', 'il', ' contempl', 'am', ' do', 'is', ' s', 'ist', 'em', 'as', '.', ' O', ' prime', 'iro', ' de', 'les', ' é', ' oper', 'ado', ' ent', 're', ' as', ' frequ', 'ê', 'n', 'ci', 'as', ' de', ' 800', ' MHz', ' e', ' 900', ' MHz', ' e', ' constit', 'ui', ' os', ' ch', 'am', 'ados', ' s', 'ist', 'em', 'as', ' TD', 'MA', '/', 'CD', 'MA', '.', ' J', 'á', ' a', ' te', 'cn', 'olog', 'ia', ' G', 'SM', ',', ' o', 'cup', 'a', ' a', ' frequ', 'ê', 'nc', 'ia', ' de', ' 1', '.', '800', ' MHz', '.', '\\n', '\\n', 'En', 'unci', 'ado', ':', '\\n', 'Consider', 'ando', ' que', ' a', ' intens', 'id', 'ade', ' de', ' trans', 'miss', 'ão', ' e', ' o', ' n', 'í', 'vel', ' de', ' rece', 'p', 'ç', 'ão', 'bytes: \\\\xe2\\\\x80', 'bytes:\\\\x9c', 'cel', 'ular', 'bytes:\\\\xe2\\\\x80', 'bytes:\\\\x9d', ' se', 'jam', ' os', ' mes', 'mos', ' para', ' as', ' te', 'cn', 'olog', 'ias', ' de', ' trans', 'miss', 'ão', ' TD', 'MA', '/', 'CD', 'MA', ' o', 'u', ' G', 'SM', ',', ' se', ' um', ' eng', 'en', 'he', 'iro', ' t', 'iver', ' de', ' esc', 'ol', 'her', ' ent', 're', ' as', ' du', 'as', ' te', 'cn', 'olog', 'ias', ' para', ' ob', 'ter', ' a', ' mes', 'ma', ' co', 'bert', 'ura', ',', ' lev', 'ando', ' em', ' consider', 'a', 'ç', 'ão', ' ap', 'en', 'as', ' o', ' n', 'ú', 'mer', 'o', ' de', ' anten', 'as', ' em', ' u', 'ma', ' reg', 'i', 'ão', ',', ' ele', ' de', 'ver', 'á', ' esc', 'ol', 'her', ':', '\\n', '\\n', 'Altern', 'at', 'ivas', ':', '\\n', '(', 'A', ')', ' a', ' te', 'cn', 'olog', 'ia', ' G', 'SM', ',', ' po', 'is', ' é', ' a', ' que', ' opera', ' com', ' on', 'd', 'as', ' de', ' ma', 'ior', ' comp', 'rim', 'ento', ' de', ' on', 'da', '.', '\\n', '(', 'B', ')', ' a', ' te', 'cn', 'olog', 'ia', ' TD', 'MA', '/', 'CD', 'MA', ',', ' po', 'is', ' é', ' a', ' que', ' ap', 'resent', 'a', ' E', 'fe', 'ito', ' Do', 'pp', 'ler', ' m', 'ais', ' pron', 'unci', 'ado', '.', '\\n', '(', 'C', ')', ' a', ' te', 'cn', 'olog', 'ia', ' G', 'SM', ',', ' po', 'is', ' é', ' a', ' que', ' util', 'iza', ' on', 'd', 'as', ' que', ' se', ' propag', 'am', ' com', ' ma', 'ior', ' vel', 'oc', 'id', 'ade', '.', '\\n', '(', 'D', ')', ' qual', 'quer', ' u', 'ma', ' d', 'as', ' du', 'as', ',', ' po', 'is', ' as', ' d', 'if', 'eren', 'ç', 'as', ' nas', ' frequ', 'ê', 'n', 'ci', 'as', ' s', 'ão', ' compens', 'adas', ' pel', 'as', ' d', 'if', 'eren', 'ç', 'as', ' nos', ' comp', 'rim', 'ent', 'os', ' de', ' on', 'da', '.', '\\n', '(', 'E', ')', ' qual', 'quer', ' u', 'ma', ' d', 'as', ' du', 'as', ',', ' po', 'is', ' n', 'esse', ' cas', 'o', ' as', ' intens', 'id', 'ades', ' dec', 'a', 'em', ' ig', 'ual', 'ment', 'e', ' da', ' mes', 'ma', ' form', 'a', ',', ' independent', 'ement', 'e', ' da', ' frequ', 'ê', 'nc', 'ia', '.', '\\n', '\\n', 'Expl', 'ica', 'ç', 'ão', ':', '\\n', 'A', ')', ' A', ' te', 'cn', 'olog', 'ia', ' G', 'SM', ' opera', ' com', ' on', 'd', 'as', ' de', ' ma', 'ior', ' comp', 'rim', 'ento', ' de', ' on', 'da', ',', ' mas', ' is', 'so', ' n', 'ão', ' signific', 'a', ' que', ' el', 'a', ' ten', 'ha', ' u', 'ma', ' co', 'bert', 'ura', ' mel', 'hor', '.', '\\n', '\\n', 'B', ')', ' A', ' te', 'cn', 'olog', 'ia', ' TD', 'MA', '/', 'CD', 'MA', ' ap', 'resent', 'a', ' E', 'fe', 'ito', ' Do', 'pp', 'ler', ' m', 'ais', ' pron', 'unci', 'ado', ',', ' mas', ' is', 'so', ' n', 'ão', ' signific', 'a', ' que', ' el', 'a', ' ten', 'ha', ' u', 'ma', ' co', 'bert', 'ura', ' mel', 'hor', '.', '\\n', '\\n', 'C', ')', ' A', ' te', 'cn', 'olog', 'ia', ' G', 'SM', ' util', 'iza', ' on', 'd', 'as', ' que', ' se', ' propag', 'am', ' com', ' ma', 'ior', ' vel', 'oc', 'id', 'ade', ',', ' mas', ' is', 'so', ' n', 'ão', ' signific', 'a', ' que', ' el', 'a', ' ten', 'ha', ' u', 'ma', ' co', 'bert', 'ura', ' mel', 'hor', '.', '\\n', '\\n', 'D', ')', ' Qual', 'quer', ' u', 'ma', ' d', 'as', ' du', 'as', ' te', 'cn', 'olog', 'ias', ' p', 'ode', ' ser', ' esc', 'ol', 'h', 'ida', ',', ' po', 'is', ' as', ' d', 'if', 'eren', 'ç', 'as', ' nas', ' frequ', 'ê', 'n', 'ci', 'as', ' s', 'ão', ' compens', 'adas', ' pel', 'as', ' d', 'if', 'eren', 'ç', 'as', ' nos', ' comp', 'rim', 'ent', 'os', ' de', ' on', 'da', '.', '\\n', '\\n', 'E', ')', ' Qual', 'quer', ' u', 'ma', ' d', 'as', ' du', 'as', ' te', 'cn', 'olog', 'ias', ' p', 'ode', ' ser', ' esc', 'ol', 'h', 'ida', ',', ' po', 'is', ' n', 'esse', ' cas', 'o', ' as', ' intens', 'id', 'ades', ' dec', 'a', 'em', ' ig', 'ual', 'ment', 'e', ' da', ' mes', 'ma', ' form', 'a', ',', ' independent', 'ement', 'e', ' da', ' frequ', 'ê', 'nc', 'ia', '.']\n",
        "\n",
        "# davinci-002 sometimes does not close the string at the end\n",
        "last_token = tokens[(len(tokens)-1)]\n",
        "if( last_token != '\\n' or last_token != '<|endoftext|>'):\n",
        "    tokens.append('<|endoftext|>')\n",
        "\n",
        "line_breaks = []\n",
        "for i, tok in enumerate(tokens):\n",
        "    res = re.search('\\n|<|endoftext|>', tok)\n",
        "    if (res != None):\n",
        "        line_breaks.append(i)\n",
        "\n",
        "for i in range(len(line_breaks)-1):    \n",
        "    string = \"\".join(tokens[line_breaks[i]+1:line_breaks[i+1]])\n",
        "    print(string)\n",
        "\n",
        "# alternatives = []\n",
        "\n",
        "# # # In multiline mode, ^ matches the position immediately following a newline\n",
        "# # # and $ matches the position immediately preceding a newline.\n",
        "# regex = \".*(CORRETA|ERRADA).*\"\n",
        "\n",
        "# for i in range(len(line_breaks)-1):\n",
        "    \n",
        "#     string = \"\".join(tokens[line_breaks[i]+1:line_breaks[i+1]])\n",
        "\n",
        "#     found_alternative = re.search(regex, string)#, re.MULTILINE)\n",
        "\n",
        "#     if (found_alternative != None):\n",
        "#       alternatives.append( { 'start': (line_breaks[i]+1), 'end': (line_breaks[i+1]) } )\n",
        "#       print(string)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TODO [broken]: Save data per question\n",
        "\n",
        "########################\n",
        "# REAL TESTS FEW SHOTS #\n",
        "########################\n",
        "\n",
        "# path = \"/content/drive/My Drive/doc_usp/IA024/artigo/\" + OPENAI.model + \"-\"\n",
        "\n",
        "# def query_model(OPENAI, cmd_0shot, cmd_cot, cot, range):\n",
        "\n",
        "#     right_answers = []\n",
        "#     question_year = []\n",
        "#     ___0shot_model_replies = []\n",
        "#     few_shot_model_replies = []\n",
        "\n",
        "#     for question in tqdm(range):\n",
        "\n",
        "#         right_answers.append(ENEM.get_right_alternative(question)[0])\n",
        "#         question_year.append(ENEM.get_question_year(question))\n",
        "\n",
        "#         #========#\n",
        "#         # 0 shot #\n",
        "#         #========#\n",
        "\n",
        "#         parsed_question, openai_response, model_right_answer, alternatives_evaluation = OPENAI.ask_ENEM_question(question, cmd_0shot)\n",
        "#         reply = {'parsed_question': parsed_question,\n",
        "#                   'openai_response': openai_response,\n",
        "#                   'model_right_answer': model_right_answer,\n",
        "#                   'alternatives_evaluation': alternatives_evaluation}  \n",
        "#         ___0shot_model_replies.append(reply)\n",
        "\n",
        "#         #====================#\n",
        "#         # SAVING each 0 shot #\n",
        "#         #====================#\n",
        "\n",
        "#         full_path = path + \"___0shot_bytearray_answers\" + \".data\"\n",
        "#         json_object = json.dumps(___0shot_model_replies[-1])\n",
        "#         with open(full_path, \"a\") as outfile:\n",
        "#             outfile.write(json_object)\n",
        "#         outfile.close()\n",
        "\n",
        "#         full_path = path + \"___0shot_answers\" + \".csv\"\n",
        "#         d = {'question_year': [question_year[-1]], 'model_answers': [reply['model_right_answer']['alternative']], 'right_answers': [right_answers[-1]]}\n",
        "#         df = pd.DataFrame(d)\n",
        "#         with open(full_path, 'a') as f:\n",
        "#           if (question != 0):\n",
        "#             df.to_csv(f, header=False)\n",
        "#           else:\n",
        "#             df.to_csv(f)\n",
        "\n",
        "#         f.close()\n",
        "\n",
        "#         #========#\n",
        "#         # f shot #\n",
        "#         #========#\n",
        "\n",
        "#         parsed_question, openai_response, model_right_answer, alternatives_evaluation = OPENAI.ask_ENEM_question(question, cmd_cot, cot)\n",
        "#         reply = {'parsed_question': parsed_question,\n",
        "#                   'openai_response': openai_response,\n",
        "#                   'model_right_answer': model_right_answer,\n",
        "#                   'alternatives_evaluation': alternatives_evaluation}  \n",
        "#         few_shot_model_replies.append(reply)\n",
        "\n",
        "#         #======================#\n",
        "#         # SAVING each few shot #\n",
        "#         #======================#\n",
        "\n",
        "#         full_path = path + \"few_shot_bytearray_answers\" + \".data\"\n",
        "#         json_object = json.dumps(few_shot_model_replies[-1])\n",
        "#         with open(full_path, \"a\") as outfile:\n",
        "#             outfile.write(json_object)\n",
        "#         outfile.close()\n",
        "\n",
        "#         full_path = path + \"few_shot_answers\" + \".csv\"\n",
        "#         d = {'question_year': [question_year[-1]], 'model_answers': [reply['model_right_answer']['alternative']], 'right_answers': [right_answers[-1]]}\n",
        "#         df = pd.DataFrame(d)\n",
        "#         with open(full_path, 'a') as f:\n",
        "#           if (question != 0):\n",
        "#             df.to_csv(f, header=False)\n",
        "#           else:\n",
        "#             df.to_csv(f)\n",
        "\n",
        "#         f.close()\n",
        "\n",
        "#         # Follow the free request rate limit on OpenAI\n",
        "#         time.sleep(10)\n",
        "\n",
        "#     ___0shot_answers = [d['model_right_answer']['alternative'] for d in ___0shot_model_replies]\n",
        "#     few_shot_answers = [d['model_right_answer']['alternative'] for d in few_shot_model_replies]\n",
        "\n",
        "#     ___0shot_accuracy = sum(x == y for x, y in zip(___0shot_answers, right_answers))\n",
        "#     few_shot_accuracy = sum(x == y for x, y in zip(few_shot_answers, right_answers))\n",
        "\n",
        "#     return ___0shot_model_replies, ___0shot_answers, ___0shot_accuracy, few_shot_model_replies, few_shot_answers, few_shot_accuracy, right_answers"
      ],
      "metadata": {
        "id": "AEZDyBG0ZaOd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBcuOBwUNcTW"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# REAL TESTS FEW SHOTS #\n",
        "########################\n",
        "\n",
        "path = \"/content/drive/My Drive/doc_usp/IA024/artigo/\" + OPENAI.model + \"-\"\n",
        "\n",
        "def query_model(OPENAI, cmd_0shot, cmd_cot, cot, range):\n",
        "\n",
        "    right_answers = []\n",
        "    question_year = []\n",
        "    ___0shot_model_replies = []\n",
        "    few_shot_model_replies = []\n",
        "\n",
        "    for question in tqdm(range):\n",
        "\n",
        "        right_answers.append(ENEM.get_right_alternative(question)[0])\n",
        "        question_year.append(ENEM.get_question_year(question))\n",
        "\n",
        "        #========#\n",
        "        # 0 shot #\n",
        "        #========#\n",
        "\n",
        "        parsed_question, openai_response, model_right_answer, alternatives_evaluation = OPENAI.ask_ENEM_question(question, cmd_0shot)\n",
        "        reply = {'parsed_question': parsed_question,\n",
        "                  'openai_response': openai_response,\n",
        "                  'model_right_answer': model_right_answer,\n",
        "                  'alternatives_evaluation': alternatives_evaluation}  \n",
        "        ___0shot_model_replies.append(reply)\n",
        "\n",
        "        #========#\n",
        "        # f shot #\n",
        "        #========#\n",
        "\n",
        "        parsed_question, openai_response, model_right_answer, alternatives_evaluation = OPENAI.ask_ENEM_question(question, cmd_cot, cot)\n",
        "        reply = {'parsed_question': parsed_question,\n",
        "                  'openai_response': openai_response,\n",
        "                  'model_right_answer': model_right_answer,\n",
        "                  'alternatives_evaluation': alternatives_evaluation}  \n",
        "        few_shot_model_replies.append(reply)\n",
        "\n",
        "        # Follow the free request rate limit on OpenAI\n",
        "        time.sleep(10)\n",
        "\n",
        "    ___0shot_answers = [d['model_right_answer']['alternative'] for d in ___0shot_model_replies]\n",
        "    few_shot_answers = [d['model_right_answer']['alternative'] for d in few_shot_model_replies]\n",
        "\n",
        "    ___0shot_accuracy = sum(x == y for x, y in zip(___0shot_answers, right_answers))\n",
        "    few_shot_accuracy = sum(x == y for x, y in zip(few_shot_answers, right_answers))\n",
        "\n",
        "    #===================#\n",
        "    # SAVING all 0 shot #\n",
        "    #===================#\n",
        "\n",
        "    full_path = path + \"___0shot_bytearray_answers\" + \".data\"\n",
        "    json_object = json.dumps(___0shot_model_replies)\n",
        "    with open(full_path, \"w\") as outfile:\n",
        "        outfile.write(json_object)\n",
        "    outfile.close()\n",
        "\n",
        "    full_path = path + \"___0shot_answers\" + \".csv\"\n",
        "    d = {'question_year': question_year, 'model_answers': ___0shot_answers, 'right_answers': right_answers}\n",
        "    df = pd.DataFrame(d)\n",
        "    with open(full_path, 'w') as f:\n",
        "      df.to_csv(f)\n",
        "    f.close()\n",
        "\n",
        "    #=====================#\n",
        "    # SAVING all few shot #\n",
        "    #=====================#\n",
        "\n",
        "    full_path = path + \"few_shot_bytearray_answers\" + \".data\"\n",
        "    json_object = json.dumps(few_shot_model_replies)\n",
        "    with open(full_path, \"w\") as outfile:\n",
        "        outfile.write(json_object)\n",
        "    outfile.close()\n",
        "\n",
        "    full_path = path + \"few_shot_answers\" + \".csv\"\n",
        "    d = {'question_year': question_year, 'model_answers': few_shot_answers, 'right_answers': right_answers}\n",
        "    df = pd.DataFrame(d)\n",
        "    with open(full_path, 'w') as f:\n",
        "      df.to_csv(f)\n",
        "    f.close()\n",
        "\n",
        "    return ___0shot_model_replies, ___0shot_answers, ___0shot_accuracy, few_shot_model_replies, few_shot_answers, few_shot_accuracy, right_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pT0WGgImOR5",
        "outputId": "5c78781e-0ca5-44fe-bcec-d0d15ac14d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "###############################\n",
            "# GPT-3.5 ACCURACY EVALUATION #\n",
            "###############################\n",
            "\n",
            "Evaluation of text-davinci-003\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 89/89 [52:18<00:00, 35.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy - 0shot: 52.81 %\n",
            "Accuracy - fshot: 68.54 %\n",
            "\n",
            "############################\n",
            "# 0 shot wrong predictions #\n",
            "############################\n",
            "\n",
            "Wrong Predictions - 0shot:\n",
            "\n",
            "{'question': 1, 'model_answer': 'C', 'right_answer': 'A'}\n",
            "{'question': 3, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 8, 'model_answer': 'B', 'right_answer': 'C'}\n",
            "{'question': 11, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 12, 'model_answer': 'C', 'right_answer': 'D'}\n",
            "{'question': 13, 'model_answer': 'B', 'right_answer': 'E'}\n",
            "{'question': 15, 'model_answer': 'B', 'right_answer': 'C'}\n",
            "{'question': 16, 'model_answer': 'B', 'right_answer': 'D'}\n",
            "{'question': 17, 'model_answer': 'A', 'right_answer': 'B'}\n",
            "{'question': 20, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 21, 'model_answer': 'D', 'right_answer': 'A'}\n",
            "{'question': 23, 'model_answer': 'B', 'right_answer': 'C'}\n",
            "{'question': 25, 'model_answer': 'D', 'right_answer': 'A'}\n",
            "{'question': 28, 'model_answer': 'D', 'right_answer': 'E'}\n",
            "{'question': 29, 'model_answer': 'D', 'right_answer': 'E'}\n",
            "{'question': 30, 'model_answer': 'C', 'right_answer': 'A'}\n",
            "{'question': 33, 'model_answer': 'C', 'right_answer': 'B'}\n",
            "{'question': 34, 'model_answer': 'A', 'right_answer': 'B'}\n",
            "{'question': 35, 'model_answer': 'B', 'right_answer': 'E'}\n",
            "{'question': 36, 'model_answer': 'A', 'right_answer': 'E'}\n",
            "{'question': 37, 'model_answer': 'B', 'right_answer': 'D'}\n",
            "{'question': 38, 'model_answer': 'A', 'right_answer': 'E'}\n",
            "{'question': 39, 'model_answer': 'D', 'right_answer': 'B'}\n",
            "{'question': 41, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 44, 'model_answer': 'A', 'right_answer': 'E'}\n",
            "{'question': 49, 'model_answer': 'A', 'right_answer': 'C'}\n",
            "{'question': 52, 'model_answer': 'D', 'right_answer': 'B'}\n",
            "{'question': 53, 'model_answer': 'A', 'right_answer': 'E'}\n",
            "{'question': 54, 'model_answer': 'B', 'right_answer': 'A'}\n",
            "{'question': 55, 'model_answer': 'D', 'right_answer': 'E'}\n",
            "{'question': 56, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 59, 'model_answer': 'C', 'right_answer': 'D'}\n",
            "{'question': 66, 'model_answer': 'D', 'right_answer': 'E'}\n",
            "{'question': 71, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 72, 'model_answer': 'A', 'right_answer': 'E'}\n",
            "{'question': 75, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 78, 'model_answer': 'A', 'right_answer': 'B'}\n",
            "{'question': 80, 'model_answer': 'B', 'right_answer': 'D'}\n",
            "{'question': 81, 'model_answer': 'A', 'right_answer': 'E'}\n",
            "{'question': 82, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 84, 'model_answer': 'A', 'right_answer': 'D'}\n",
            "{'question': 85, 'model_answer': 'B', 'right_answer': 'D'}\n",
            "\n",
            "############################\n",
            "# f shot wrong predictions #\n",
            "############################\n",
            "\n",
            "Wrong Predictions - fshot:\n",
            "\n",
            "{'question': 1, 'model_answer': 'C', 'right_answer': 'A'}\n",
            "{'question': 11, 'model_answer': 'D', 'right_answer': 'E'}\n",
            "{'question': 12, 'model_answer': 'A', 'right_answer': 'D'}\n",
            "{'question': 13, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 16, 'model_answer': 'E', 'right_answer': 'D'}\n",
            "{'question': 19, 'model_answer': 'E', 'right_answer': 'A'}\n",
            "{'question': 20, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 21, 'model_answer': 'D', 'right_answer': 'A'}\n",
            "{'question': 24, 'model_answer': 'C', 'right_answer': 'A'}\n",
            "{'question': 25, 'model_answer': 'D', 'right_answer': 'A'}\n",
            "{'question': 30, 'model_answer': 'D', 'right_answer': 'A'}\n",
            "{'question': 33, 'model_answer': 'C', 'right_answer': 'B'}\n",
            "{'question': 34, 'model_answer': 'E', 'right_answer': 'B'}\n",
            "{'question': 35, 'model_answer': 'A', 'right_answer': 'E'}\n",
            "{'question': 39, 'model_answer': 'D', 'right_answer': 'B'}\n",
            "{'question': 40, 'model_answer': 'D', 'right_answer': 'A'}\n",
            "{'question': 41, 'model_answer': 'D', 'right_answer': 'E'}\n",
            "{'question': 47, 'model_answer': 'B', 'right_answer': 'A'}\n",
            "{'question': 52, 'model_answer': 'D', 'right_answer': 'B'}\n",
            "{'question': 54, 'model_answer': 'E', 'right_answer': 'A'}\n",
            "{'question': 55, 'model_answer': 'D', 'right_answer': 'E'}\n",
            "{'question': 56, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 59, 'model_answer': 'C', 'right_answer': 'D'}\n",
            "{'question': 66, 'model_answer': 'D', 'right_answer': 'E'}\n",
            "{'question': 78, 'model_answer': 'E', 'right_answer': 'B'}\n",
            "{'question': 82, 'model_answer': 'C', 'right_answer': 'E'}\n",
            "{'question': 84, 'model_answer': 'A', 'right_answer': 'D'}\n",
            "{'question': 87, 'model_answer': 'E', 'right_answer': 'A'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#######################\n",
        "# FEW SHOW EVALUATION #\n",
        "#######################\n",
        "\n",
        "print()\n",
        "print(\"###############################\")\n",
        "print(\"# GPT-3.5 ACCURACY EVALUATION #\")\n",
        "print(\"###############################\")\n",
        "print()\n",
        "print(\"Evaluation of \" + OPENAI.model)\n",
        "print()\n",
        "\n",
        "# EXAME TESTE\n",
        "# questions_to_ask = range(0,5)\n",
        "\n",
        "# EXAME 2009\n",
        "questions_to_ask = range(0,89)\n",
        "\n",
        "# EXAME TOTAL\n",
        "# questions_to_ask = range(0,len(ENEM))\n",
        "\n",
        "___0shot_model_replies, ___0shot_answers, ___0shot_accuracy, few_shot_model_replies, few_shot_answers, few_shot_accuracy, right_answers = query_model(OPENAI, cmd_0shot, cmd_cot, cot, questions_to_ask)\n",
        "# ___0shot_model_answers, few_shot_model_answers, right_answers = query_model(OPENAI, cmd_0shot, cmd_cot, cot, questions_to_ask)\n",
        "\n",
        "#========#\n",
        "# 0 shot #\n",
        "#========#\n",
        "\n",
        "incorrect_0shot = [{'question': q, 'model_answer': i, 'right_answer': j} for i, j, q in\n",
        "                   zip(___0shot_answers, right_answers, range(len(right_answers))) if i != j]\n",
        "\n",
        "print()\n",
        "print(\"Accuracy - 0shot: {0:.2f} %\".format(___0shot_accuracy/len(questions_to_ask) * 100))\n",
        "\n",
        "#========#\n",
        "# f shot #\n",
        "#========#\n",
        "\n",
        "incorrect_fshot = [{'question': q, 'model_answer': i, 'right_answer': j} for i, j, q in\n",
        "                   zip(few_shot_answers, right_answers, range(len(right_answers))) if i != j]\n",
        "\n",
        "print(\"Accuracy - fshot: {0:.2f} %\".format(few_shot_accuracy/len(questions_to_ask) * 100))\n",
        "print()\n",
        "\n",
        "print(\"############################\")\n",
        "print(\"# 0 shot wrong predictions #\")\n",
        "print(\"############################\")\n",
        "print()\n",
        "print(\"Wrong Predictions - 0shot:\\n\")\n",
        "print(*incorrect_0shot, sep='\\n')\n",
        "print()\n",
        "\n",
        "print(\"############################\")\n",
        "print(\"# f shot wrong predictions #\")\n",
        "print(\"############################\")\n",
        "print()\n",
        "print(\"Wrong Predictions - fshot:\\n\")\n",
        "print(*incorrect_fshot, sep='\\n')\n",
        "print()\n",
        "\n",
        "###############\n",
        "# ALL ANSWERS #\n",
        "###############\n",
        "\n",
        "# ___0shot = [{'question': q, 'model_answer': i, 'right_answer': j} for i, j, q in\n",
        "#            zip(___0shot_answers, right_answers, range(len(right_answers)))]\n",
        "\n",
        "# print(\"######################\")\n",
        "# print(\"# 0 shot all answers #\")\n",
        "# print(\"######################\")\n",
        "# print()\n",
        "# print(\"All Predictions - 0shot:\\n\")\n",
        "# print(*___0shot, sep='\\n')\n",
        "# print()\n",
        "\n",
        "# few_shot = [{'question': q, 'model_answer': i, 'right_answer': j} for i, j, q in\n",
        "#            zip(few_shot_answers, right_answers, range(len(right_answers)))]\n",
        "\n",
        "# print(\"######################\")\n",
        "# print(\"# f shot all answers #\")\n",
        "# print(\"######################\")\n",
        "# print()\n",
        "# print(\"All Predictions - fshot:\\n\")\n",
        "# print(*few_shot, sep='\\n')\n",
        "# print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#==============#\n",
        "# READING data #\n",
        "#==============#\n",
        "\n",
        "# path = \"/content/drive/My Drive/doc_usp/IA024/artigo/\" + OPENAI.model + \"-\"\n",
        "\n",
        "# full_path = path + \"___0shot_bytearray_answers\" + \".data\"\n",
        "# # full_path = path + \"few_shot_bytearray_answers\" + \".data\"\n",
        "\n",
        "# with open(full_path, 'r') as openfile:\n",
        "#     data = json.load(openfile)\n",
        " \n",
        "# print(data)\n",
        "# print()\n",
        "# print(type(data))\n",
        "# print()\n",
        "# for d in data:\n",
        "#   print(d['model_right_answer']['alternative'])"
      ],
      "metadata": {
        "id": "sWJELr68jrb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EisWdqbZarEA"
      },
      "outputs": [],
      "source": [
        "#############\n",
        "# STOP HERE #\n",
        "#############\n",
        "\n",
        "print(FIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh2D6-B4XI_g"
      },
      "outputs": [],
      "source": [
        "###########\n",
        "# PART II #\n",
        "###########\n",
        "\n",
        "# Ricardo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDLxUSJnNzxW"
      },
      "source": [
        "### Saving embeddings from BERTimbau\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0-1wCGMW3XR",
        "outputId": "2a2c0f00-031b-4d72-b656-321b89c7b680"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "##############\n",
        "# EMBEDDINGS #\n",
        "##############\n",
        "\n",
        "from transformers import BertModel\n",
        "bert_pretrained = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "def get_BERT_embeddings(ENEM_data, model, q_id):\n",
        "    with torch.no_grad():\n",
        "        reps_q = model( torch.tensor([ENEM_data.headers_ids[q_id]]),\n",
        "                       attention_mask = torch.tensor([ENEM_data.headers_masks[q_id]]), \n",
        "                       output_hidden_states=True).last_hidden_state.squeeze(0).numpy()\n",
        "\n",
        "        reps_s = model( torch.tensor([ENEM_data.statements_ids[q_id]]),\n",
        "                       attention_mask = torch.tensor([ENEM_data.statements_masks[q_id]]), \n",
        "                       output_hidden_states=True).last_hidden_state.squeeze(0).numpy()    \n",
        "        \n",
        "        reps_o = model( torch.tensor(ENEM_data.answers[q_id][0]),\n",
        "                       attention_mask = torch.tensor(ENEM_data.answers[q_id][1]), \n",
        "                       output_hidden_states=True).last_hidden_state.squeeze(0).numpy()            \n",
        "    return(reps_q, reps_s, reps_o ) \n",
        "\n",
        "\n",
        "#embeddings_data = []\n",
        "#for v, i in zip(ENEM.enem_version, ENEM.questions):\n",
        "#  q, s, o = get_BERT_embeddings(ENEM_data, model= bert_pretrained, q_id = int(i['id']))\n",
        "#  embeddings_data.append({'version':v, 'id': i['id'], 'q':q, 's':s, 'o':o})\n",
        "\n",
        "#embeddings_data[0]\n",
        "\n",
        "#import json\n",
        "#with open('ebmeddings.json', 'w') as f:\n",
        "#    json.dump(embeddings_data , f)\n",
        "\n",
        "#import pickle\n",
        "#with open('embeddings.pkl', 'wb') as f:\n",
        "#    pickle.dump(embeddings_data, f)\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "#print(q.shape)\n",
        "#print(s.shape)\n",
        "#print(o.shape)\n",
        "\n",
        "\n",
        "#text_question = pd.read_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_enem/text_question.csv\") \n",
        "#text_option = pd.read_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_enem/text_option.csv\") \n",
        "\n",
        "#reps.last_hidden_state[:, 0]\n",
        "#reps.hidden_states[-1].shape\n",
        "#torch.equal(reps.hidden_states[-1], reps.last_hidden_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQUiBUdwPwdb"
      },
      "source": [
        "* Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuI4dwbRPv_B",
        "outputId": "646bcf95-7dff-468f-c7de-c1716cda5627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#############\n",
            "# Questão 0 #\n",
            "#############\n",
            "\n",
            "Ano/Versão: 2009-1\n",
            "\n",
            "Cabeçalho:\n",
            " A  atmosfera  terrestre  é  composta  pelos  gases nitrogênio (N2) e oxigênio (O2), que somam cerca de 99%, e por gases traços, entre eles o gás carbônico (CO2), vapor de água (H2O), metano (CH4), ozônio (O3) e o óxido nitroso (N2O), que compõem o restante 1% do ar que respiramos. Os  gases  traços,  por  serem  constituídos  por  pelo  menos três  átomos,  conseguem  absorver  o  calor  irradiado  pela Terra, aquecendo o planeta. Esse fenômeno, que acontece há bilhões de anos, é chamado de efeito estufa. A partir da Revolução  Industrial  (século  XIX),  a  concentração  de gases  traços  na  atmosfera,  em  particular  o CO2,  tem aumentado significativamente, o que resultou no aumento da  temperatura  em  escala  global.  Mais  recentemente, outro fator tornou-se diretamente envolvido no aumento da concentração de CO2 na atmosfera: o desmatamento.  BROWN, I. F.; ALECHANDRE, A. S. Conceitos básicos sobre clima,  carbono, florestas e comunidades. A.G. Moreira & S.  Schwartzman. As mudanças climáticas globais e os  ecossistemas brasileiros. Brasília: Instituto de Pesquisa Ambiental da Amazônia, 2000 (adaptado). \n",
            "\n",
            "Enunciado:\n",
            "Considerando  o texto,  uma  alternativa  viável  para combater o efeito estufa é \n",
            "\n",
            "Alternativas:\n",
            " A  -  reduzir  o  calor irradiado  pela  Terra  mediante  a substituição da produção primária pela industrialização refrigerada. \n",
            " B  -   promover a queima da biomassa vegetal, responsável pelo  aumento  do  efeito  estufa  devido  à  produção  de CH4. \n",
            "[C] -  reduzir  o  desmatamento,  mantendo-se,  assim,  o potencial  da  vegetação  em  absorver  o  CO2  da atmosfera. \n",
            " D  -   aumentar  a  concentração  atmosférica  de  H2O, molécula  capaz  de  absorver  grande  quantidade  de calor. \n",
            " E  -  remover  moléculas  orgânicas  polares  da  atmosfera, diminuindo a capacidade delas de reter calor. \n",
            "None\n",
            "\n",
            "Question: 01 Dimensions of the header: (472, 768)\n",
            "Question: 01 Dimensions of the statment: (160, 768)\n",
            "Question: 01 Dimensions of options: (5, 24, 768)\n",
            "\n",
            "[101, 177, 7538, 9597, 253, 3779, 954, 11746, 18569, 7696, 113, 248, 22313, 114, 122, 12028, 113, 231, 22313, 114, 117, 179, 6921, 22287, 1384, 125, 16113, 110, 117, 122, 240, 11746, 10917, 117, 420, 1061, 146, 5721, 6328, 4038, 113, 6213, 22313, 114, 117, 8886, 125, 1991, 113, 330, 22313, 22317, 114, 117, 5436, 300, 113, 187, 22340, 22336, 114, 117, 146, 22305, 2087, 113, 231, 22335, 114, 122, 146, 2705, 14271, 243, 18569, 293, 113, 248, 22313, 22317, 114, 117, 179, 12992, 146, 7394, 205, 110, 171, 388, 179, 9815, 793, 119, 533, 11746, 10917, 117, 240, 2736, 8162, 22281, 240, 423, 1528, 864, 12184, 117, 11580, 6618, 391, 146, 6938, 15888, 679, 243, 412, 2690, 117, 10017, 2146, 146, 4659, 119, 3758, 8019, 117, 179, 6491, 1307, 6466, 125, 481, 117, 253, 1565, 125, 3901, 913, 1165, 119, 177, 1018, 180, 4952, 10430, 113, 1180, 3409, 114, 117, 123, 6755, 125, 11746, 10917, 229, 7538, 117, 173, 2754, 146, 6213, 22313, 117, 376, 16771, 8485, 246, 117, 146, 179, 6499, 202, 3536, 180, 4099, 173, 4721, 6813, 119, 2511, 5688, 117, 1342, 7620, 1204, 118, 176, 4188, 9417, 202, 3536, 180, 6755, 125, 6213, 22313, 229, 7538, 131, 146, 12156, 1869, 119, 8298, 22317, 22345, 22320, 117, 290, 119, 263, 119, 132, 14215, 5476, 18394, 22320, 20414, 22309, 117, 177, 119, 200, 119, 3928, 1789, 13508, 498, 4885, 117, 8668, 117, 9647, 122, 6063, 119, 177, 119, 278, 119, 10778, 111, 200, 119, 3016, 12598, 22305, 464, 119, 510, 4134, 18080, 22045, 122, 259, 14642, 11335, 4594, 119, 6191, 131, 2900, 125, 12606, 17949, 180, 12185, 117, 4236, 113, 12981, 114, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "[101, 20093, 146, 4054, 117, 230, 7849, 22241, 221, 10306, 146, 3901, 913, 1165, 253, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "([[101, 8333, 146, 6938, 15888, 679, 243, 412, 2690, 9402, 123, 8848, 180, 1468, 11122, 412, 4710, 910, 16373, 17743, 119, 102, 0, 0, 0, 0], [101, 5707, 123, 12909, 180, 4248, 486, 375, 14145, 117, 2806, 423, 3536, 171, 3901, 913, 1165, 1372, 353, 1468, 125, 187, 22340, 22336, 119, 102], [101, 8333, 146, 12156, 1869, 117, 7430, 118, 176, 117, 1016, 117, 146, 5323, 180, 8566, 173, 6618, 391, 146, 6213, 22313, 180, 7538, 119, 102], [101, 5683, 123, 6755, 14561, 1741, 125, 330, 22313, 22317, 117, 16538, 4051, 125, 6618, 391, 739, 3442, 125, 6938, 119, 102, 0, 0, 0, 0], [101, 16374, 10843, 15144, 22281, 12948, 143, 180, 7538, 117, 18412, 123, 2839, 4687, 125, 19652, 140, 6938, 119, 102, 0, 0, 0, 0, 0, 0]], [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])\n",
            "\n",
            "#############\n",
            "# Questão 1 #\n",
            "#############\n",
            "\n",
            "Ano/Versão: 2009-1\n",
            "\n",
            "Cabeçalho:\n",
            "Estima-se  que  haja  atualmente  no  mundo  40 milhões de pessoas infectadas pelo HIV (o vírus que causa a  AIDS),  sendo  que  as taxas  de  novas infecções continuam  crescendo,  principalmente  na  África,  Ásia  e Rússia. Nesse cenário de pandemia, uma vacina contra o HIV  teria  imenso  impacto,  pois  salvaria  milhões  de  vidas. Certamente  seria  um  marco  na  história  planetária  e também  uma  esperança  para  as  populações  carentes  de tratamento antiviral e de acompanhamento médico. TANURI, A.; FERREIRA JUNIOR, O. C. Vacina contra Aids: desafios e esperanças. Ciência Hoje (44) 26, 2009 (adaptado). \n",
            "\n",
            "Enunciado:\n",
            "Uma vacina eficiente contra o HIV deveria \n",
            "\n",
            "Alternativas:\n",
            "[A] -  induzir  a  imunidade,  para  proteger  o  organismo  da contaminação viral. \n",
            " B  -   ser capaz de alterar o genoma do organismo portador, induzindo a síntese de enzimas protetoras. \n",
            " C  -   produzir  antígenos  capazes  de  se  ligarem  ao  vírus, impedindo  que  este  entre  nas  células  do  organismo humano. \n",
            " D  -   ser amplamente aplicada em animais, visto que esses são os principais transmissores do vírus para os seres humanos. \n",
            " E  -   estimular a imunidade, minimizando a transmissão do vírus por gotículas de saliva. \n",
            "None\n",
            "\n",
            "Question: 03 Dimensions of the header: (472, 768)\n",
            "Question: 03 Dimensions of the statment: (160, 768)\n",
            "Question: 03 Dimensions of options: (5, 24, 768)\n",
            "\n",
            "[101, 15477, 118, 176, 179, 9966, 2750, 202, 1147, 3467, 1529, 125, 1101, 6735, 2721, 423, 22180, 113, 146, 9373, 179, 2318, 123, 177, 20009, 114, 117, 660, 179, 260, 9035, 125, 2534, 6735, 315, 10772, 15655, 117, 1953, 229, 3358, 117, 5472, 122, 3787, 119, 4114, 5391, 125, 9196, 769, 151, 117, 230, 13348, 387, 598, 146, 22180, 2471, 21024, 6026, 117, 1502, 7861, 151, 1529, 125, 9672, 119, 4341, 1121, 1467, 222, 10567, 229, 1081, 3034, 9024, 122, 407, 230, 8611, 221, 260, 7214, 12210, 358, 125, 3896, 6267, 12343, 22290, 122, 125, 15201, 4714, 119, 267, 7665, 15289, 22323, 117, 177, 119, 132, 263, 5054, 7286, 15710, 22301, 299, 11964, 15749, 22322, 117, 231, 119, 187, 119, 5716, 21946, 598, 177, 18355, 131, 13569, 122, 8611, 22281, 119, 9036, 6029, 113, 10534, 114, 2633, 117, 3665, 113, 12981, 114, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "[101, 1431, 13348, 387, 10746, 598, 146, 22180, 4360, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "([[101, 11754, 307, 123, 13577, 292, 117, 221, 7163, 146, 10269, 180, 8091, 2938, 5401, 22290, 119, 102, 0, 0, 0, 0, 0, 0], [101, 333, 4051, 125, 14465, 146, 18634, 148, 171, 10269, 4303, 947, 117, 11754, 557, 123, 12412, 125, 19851, 21839, 138, 119, 102, 0], [101, 4787, 856, 2373, 2726, 7227, 125, 176, 16692, 210, 320, 9373, 117, 19470, 179, 860, 420, 529, 4611, 171, 10269, 4481, 119, 102], [101, 333, 7068, 11107, 173, 3155, 117, 3382, 179, 3636, 453, 259, 1649, 2153, 15995, 143, 171, 9373, 221, 259, 6102, 3773, 119, 102], [101, 20149, 123, 13577, 292, 117, 14983, 4820, 123, 5171, 171, 9373, 240, 3746, 2512, 6053, 125, 1390, 1319, 119, 102, 0, 0, 0]], [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n",
            "\n",
            "#############\n",
            "# Questão 2 #\n",
            "#############\n",
            "\n",
            "Ano/Versão: 2009-1\n",
            "\n",
            "Cabeçalho:\n",
            "  Em um experimento, preparou-se um conjunto de plantas  por  técnica  de  clonagem  a  partir  de  uma  planta original  que  apresentava  folhas  verdes.  Esse  conjunto  foi dividido  em  dois  grupos,  que  foram  tratados  de  maneira idêntica, com exceção das condições de iluminação, sendo um  grupo  exposto  a  ciclos  de  iluminação  solar  natural  e outro  mantido  no  escuro.  Após  alguns  dias,  observou-se que o grupo exposto à luz apresentava folhas verdes como a planta original e o grupo cultivado no escuro apresentava folhas amareladas. \n",
            "\n",
            "Enunciado:\n",
            "Ao  final  do  experimento,  os  dois  grupos  de  plantas apresentaram \n",
            "\n",
            "Alternativas:\n",
            " A  -   os genótipos e os fenótipos idênticos. \n",
            "[B] -   os genótipos idênticos e os fenótipos diferentes. \n",
            " C  -   diferenças nos genótipos e fenótipos. \n",
            " D  -   o mesmo fenótipo e apenas dois genótipos diferentes. \n",
            " E  -   o mesmo fenótipo e grande variedade de genótipos.  \n",
            "None\n",
            "\n",
            "Question: 04 Dimensions of the header: (472, 768)\n",
            "Question: 04 Dimensions of the statment: (160, 768)\n",
            "Question: 04 Dimensions of options: (5, 14, 768)\n",
            "\n",
            "[101, 335, 222, 16580, 117, 19736, 118, 176, 222, 2154, 125, 4924, 240, 4204, 125, 20664, 20421, 123, 1018, 125, 230, 5540, 1606, 179, 10072, 7438, 14049, 119, 3758, 2154, 262, 6919, 173, 682, 2201, 117, 179, 506, 10882, 125, 2821, 10127, 232, 117, 170, 6648, 366, 2955, 125, 10554, 117, 660, 222, 939, 16786, 123, 15814, 125, 10554, 7939, 2711, 122, 1342, 9573, 202, 13389, 119, 1240, 1089, 1564, 117, 10719, 118, 176, 179, 146, 939, 16786, 353, 3377, 10072, 7438, 14049, 271, 123, 5540, 1606, 122, 146, 939, 9841, 201, 202, 13389, 10072, 7438, 15403, 591, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "[101, 1683, 774, 171, 16580, 117, 259, 682, 2201, 125, 4924, 12199, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "([[101, 259, 1677, 22141, 22281, 122, 259, 17029, 12500, 10127, 560, 119, 102, 0], [101, 259, 1677, 22141, 22281, 10127, 560, 122, 259, 17029, 12500, 1755, 119, 102], [101, 6574, 538, 1677, 22141, 22281, 122, 17029, 12500, 119, 102, 0, 0, 0], [101, 146, 653, 17029, 6418, 122, 820, 682, 1677, 22141, 22281, 1755, 119, 102], [101, 146, 653, 17029, 6418, 122, 739, 5402, 125, 1677, 22141, 22281, 119, 102]], [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/unicamp - IA024 /projeto_enem/embeddings.pkl', 'rb') as f:\n",
        "    embeddings_data = pickle.load(f)\n",
        "\n",
        "for i in range(3):\n",
        "  print(ENEM.print_question(i))\n",
        "  print()\n",
        "  print(\"Question: \" + embeddings_data[i]['id'] + \" Dimensions of the header: \" + str(embeddings_data[i]['q'].shape))\n",
        "  print(\"Question: \" + embeddings_data[i]['id'] + \" Dimensions of the statment: \" + str(embeddings_data[i]['s'].shape))\n",
        "  print(\"Question: \" + embeddings_data[i]['id'] + \" Dimensions of options: \" + str(embeddings_data[i]['o'].shape))\n",
        "  \n",
        "  print()\n",
        "  print(ENEM_data.headers_ids[i])\n",
        "  print()\n",
        "  print(ENEM_data.statements_ids[i])\n",
        "  print()\n",
        "  print(ENEM_data.answers[i])\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(embeddings_data[0]['q'].mean(axis=0), bins=20, color = \"red\")\n",
        "plt.show()\n",
        "\n",
        "plt.hist(embeddings_data[0]['q'][np.array(ENEM_data.headers_ids[0]) != 0].mean(axis=0), bins=20, color = \"red\")\n",
        "plt.show()\n",
        "\n",
        "embeddings_data[0]['q'].mean(axis=0) == embeddings_data[0]['q'][np.array(ENEM_data.headers_ids[0]) != 0].mean(axis=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFz5sNHC6D4b"
      },
      "outputs": [],
      "source": [
        "* Model 1: mean of embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6OKwGY-Q5gJd"
      },
      "outputs": [],
      "source": [
        "embeddings_data2 = []\n",
        "\n",
        "for i in ENEM.questions:\n",
        "  q_id  = int(i['id'])\n",
        "  q2 = embeddings_data[q_id]['q'][np.array(ENEM_data.headers_ids[q_id]) != 0].mean(axis=0)\n",
        "  s2 = embeddings_data[q_id]['s'][np.array(ENEM_data.statements_ids[q_id]) != 0].mean(axis=0)\n",
        "  answers = []\n",
        "  for a in (embeddings_data[q_id]['o']):\n",
        "    answers.append(np.array(a).mean(axis=0))\n",
        "  \n",
        "  embeddings_data2.append({'id': q_id, 'q2':q2, 's2':s2, 'o2':o2})\n",
        "\n",
        "#embeddings_data[0]['q'][np.array(ENEM_data.headers_ids[0]) != 0].mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oszmles7ATd"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in ENEM.questions:\n",
        "  print(i)\n",
        "\n",
        "answers = []\n",
        "for a in (embeddings_data[0]['o']):\n",
        "   print(a.shape)\n",
        "   print(a)\n",
        "   print(np.array(a).mean(axis=0).shape)\n",
        "  #o2 = a[0].mean(axis=1)\n",
        "  #answers.append(o2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQFyO6FVqBPS"
      },
      "source": [
        "### Fine tuning Bertimbau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR8tjFc2LEeg"
      },
      "source": [
        "#### Salvando a base em um dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kKCtypVY2sD",
        "outputId": "cd2a493e-9910-4ab7-95ed-c0873ac451e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 916 entries, 0 to 915\n",
            "Data columns (total 17 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   enem_version  916 non-null    object\n",
            " 1   header        916 non-null    object\n",
            " 2   statement     916 non-null    object\n",
            " 3   CE            916 non-null    object\n",
            " 4   DS            916 non-null    object\n",
            " 5   EK            916 non-null    object\n",
            " 6   IC            916 non-null    object\n",
            " 7   MR            916 non-null    object\n",
            " 8   TC            916 non-null    object\n",
            " 9   id            916 non-null    object\n",
            " 10  image         916 non-null    object\n",
            " 11  gab           916 non-null    object\n",
            " 12  A             916 non-null    object\n",
            " 13  B             916 non-null    object\n",
            " 14  C             916 non-null    object\n",
            " 15  D             916 non-null    object\n",
            " 16  E             916 non-null    object\n",
            "dtypes: object(17)\n",
            "memory usage: 121.8+ KB\n",
            "\n",
            "#############\n",
            "# Questão 0 #\n",
            "#############\n",
            "\n",
            "Ano/Versão: 2009-1\n",
            "\n",
            "Cabeçalho:\n",
            " A  atmosfera  terrestre  é  composta  pelos  gases nitrogênio (N2) e oxigênio (O2), que somam cerca de 99%, e por gases traços, entre eles o gás carbônico (CO2), vapor de água (H2O), metano (CH4), ozônio (O3) e o óxido nitroso (N2O), que compõem o restante 1% do ar que respiramos. Os  gases  traços,  por  serem  constituídos  por  pelo  menos três  átomos,  conseguem  absorver  o  calor  irradiado  pela Terra, aquecendo o planeta. Esse fenômeno, que acontece há bilhões de anos, é chamado de efeito estufa. A partir da Revolução  Industrial  (século  XIX),  a  concentração  de gases  traços  na  atmosfera,  em  particular  o CO2,  tem aumentado significativamente, o que resultou no aumento da  temperatura  em  escala  global.  Mais  recentemente, outro fator tornou-se diretamente envolvido no aumento da concentração de CO2 na atmosfera: o desmatamento.  BROWN, I. F.; ALECHANDRE, A. S. Conceitos básicos sobre clima,  carbono, florestas e comunidades. A.G. Moreira & S.  Schwartzman. As mudanças climáticas globais e os  ecossistemas brasileiros. Brasília: Instituto de Pesquisa Ambiental da Amazônia, 2000 (adaptado). \n",
            "\n",
            "Enunciado:\n",
            "Considerando  o texto,  uma  alternativa  viável  para combater o efeito estufa é \n",
            "\n",
            "Alternativas:\n",
            " A  -  reduzir  o  calor irradiado  pela  Terra  mediante  a substituição da produção primária pela industrialização refrigerada. \n",
            " B  -   promover a queima da biomassa vegetal, responsável pelo  aumento  do  efeito  estufa  devido  à  produção  de CH4. \n",
            "[C] -  reduzir  o  desmatamento,  mantendo-se,  assim,  o potencial  da  vegetação  em  absorver  o  CO2  da atmosfera. \n",
            " D  -   aumentar  a  concentração  atmosférica  de  H2O, molécula  capaz  de  absorver  grande  quantidade  de calor. \n",
            " E  -  remover  moléculas  orgânicas  polares  da  atmosfera, diminuindo a capacidade delas de reter calor. \n"
          ]
        }
      ],
      "source": [
        "data_enem0 = [ENEM.__getitem__(i) for i in range(len(ENEM))]\n",
        "\n",
        "data_enem0[0]\n",
        "\n",
        "data_enem =  pd.DataFrame(data_enem0, columns = ['enem_version', 'question.attrib', 'header', 'statement', 'answers'])  \n",
        "\n",
        "def df_column_to_columns(df, column_name):\n",
        "    df = pd.concat([df.drop([column_name], axis=1), df[column_name].apply(pd.Series)], axis=1)\n",
        "    return df\n",
        "\n",
        "data_enem = df_column_to_columns(data_enem, 'question.attrib')\n",
        "data_enem = df_column_to_columns(data_enem, 'answers')\n",
        "data_enem = df_column_to_columns(data_enem, 1)\n",
        "\n",
        "data_enem.columns = ['enem_version', 'header', 'statement','CE','DS','EK','IC','MR','TC','id','image',\n",
        "                 'gab', 'A','B','C','D','E']\n",
        "\n",
        "def select_list_element(df, column_name, key, value):\n",
        "    df[column_name] = df[column_name].apply(lambda x: [d for d in x if d[key] == value])\n",
        "    return df   \n",
        "\n",
        "\n",
        "data_enem = select_list_element(data_enem, 'gab', 'correct', 'Yes')\n",
        "\n",
        "\n",
        "def get_value_from_dict(df, column_name, key):\n",
        "    df[column_name] = df[column_name].apply(lambda x: x[0][key])\n",
        "    return df\n",
        "\n",
        "data_enem = get_value_from_dict(data_enem, 'gab', 'id')\n",
        "\n",
        "data_enem.info()\n",
        "\n",
        "ENEM.print_question(0)\n",
        "\n",
        "data_enem.to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_enem/data_enem0.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FTon48Yzp_kq",
        "outputId": "6683153b-5634-4a89-bf27-6b91b7a03a98"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-49816c04-c9ee-4a5a-aa84-95c6e60d5711\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>...1</th>\n",
              "      <th>enem_version</th>\n",
              "      <th>header</th>\n",
              "      <th>statement</th>\n",
              "      <th>CE</th>\n",
              "      <th>DS</th>\n",
              "      <th>EK</th>\n",
              "      <th>IC</th>\n",
              "      <th>MR</th>\n",
              "      <th>TC</th>\n",
              "      <th>id</th>\n",
              "      <th>image</th>\n",
              "      <th>gab</th>\n",
              "      <th>question_id</th>\n",
              "      <th>opcao</th>\n",
              "      <th>opcao_text</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>train_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>972</td>\n",
              "      <td>2014-2</td>\n",
              "      <td>A última edição deste periódico apresenta mais...</td>\n",
              "      <td>Esse editorial faz uma leitura diferenciada de...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>99</td>\n",
              "      <td>No</td>\n",
              "      <td>D</td>\n",
              "      <td>2014-2_99</td>\n",
              "      <td>D</td>\n",
              "      <td>interpretar criticamente fatos noticiados e co...</td>\n",
              "      <td>A última edição deste periódico apresenta mais...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>925</td>\n",
              "      <td>2014-1</td>\n",
              "      <td>Na  década  de  1940,  na  Região  Centro-Oest...</td>\n",
              "      <td>Para suprir o déficit nutricional a que os pro...</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>47</td>\n",
              "      <td>No</td>\n",
              "      <td>D</td>\n",
              "      <td>2014-1_47</td>\n",
              "      <td>D</td>\n",
              "      <td>aminoácidos essenciais.</td>\n",
              "      <td>Na  década  de  1940,  na  Região  Centro-Oest...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>483</td>\n",
              "      <td>2011-2</td>\n",
              "      <td>O que é possível dizer em 140 caracteres?Suces...</td>\n",
              "      <td>O Twitter se presta a diversas finalidades, en...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>135</td>\n",
              "      <td>No</td>\n",
              "      <td>E</td>\n",
              "      <td>2011-2_135</td>\n",
              "      <td>B</td>\n",
              "      <td>constitui recurso próprio para a aquisição da ...</td>\n",
              "      <td>O que é possível dizer em 140 caracteres?Suces...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>2016_2_-1</td>\n",
              "      <td>Até 1824 acreditava-se que as máquinas térmica...</td>\n",
              "      <td>Tal limitação ocorre porque essas máquinas</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>61</td>\n",
              "      <td>No</td>\n",
              "      <td>B</td>\n",
              "      <td>2016_2_-1_61</td>\n",
              "      <td>C</td>\n",
              "      <td>utilizam transformações adiabáticas.</td>\n",
              "      <td>Até 1824 acreditava-se que as máquinas térmica...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1452</td>\n",
              "      <td>2016_2_-1</td>\n",
              "      <td>Um  jovem  suspeita  que  não  é  filho  bioló...</td>\n",
              "      <td>A  condição  genotípica  que  possibilita  que...</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>47</td>\n",
              "      <td>No</td>\n",
              "      <td>A</td>\n",
              "      <td>2016_2_-1_47</td>\n",
              "      <td>A</td>\n",
              "      <td>o  pai  e  a  mãe  sejam  heterozigotos  para ...</td>\n",
              "      <td>Um  jovem  suspeita  que  não  é  filho  bioló...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7323</th>\n",
              "      <td>1590</td>\n",
              "      <td>2017-1</td>\n",
              "      <td>Quer suporte paraencontrar pessoasque comparti...</td>\n",
              "      <td>O  consumidor  do  século  XXI,  chamado  de  ...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>17</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A</td>\n",
              "      <td>2017-1_17</td>\n",
              "      <td>B</td>\n",
              "      <td>busca constante pelo menor preço.</td>\n",
              "      <td>Quer suporte paraencontrar pessoasque comparti...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7324</th>\n",
              "      <td>783</td>\n",
              "      <td>2013-1</td>\n",
              "      <td>Estudos  de  fluxo  de  energia  em  ecossiste...</td>\n",
              "      <td>Dos grupos de seres vivos citados, os que cont...</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>80</td>\n",
              "      <td>No</td>\n",
              "      <td>B</td>\n",
              "      <td>2013-1_80</td>\n",
              "      <td>D</td>\n",
              "      <td>insetos.</td>\n",
              "      <td>Estudos  de  fluxo  de  energia  em  ecossiste...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7325</th>\n",
              "      <td>899</td>\n",
              "      <td>2014-1</td>\n",
              "      <td>Estatuto da Frente Negra Brasileira (FNB)Art. ...</td>\n",
              "      <td>Quando  foi  fechada  pela  ditadura  do  Esta...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>21</td>\n",
              "      <td>No</td>\n",
              "      <td>A</td>\n",
              "      <td>2014-1_21</td>\n",
              "      <td>A</td>\n",
              "      <td>política, engajada na luta por direitos sociai...</td>\n",
              "      <td>Estatuto da Frente Negra Brasileira (FNB)Art. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7326</th>\n",
              "      <td>448</td>\n",
              "      <td>2011-2</td>\n",
              "      <td>TEXTO IVocê tem palacete reluzenteTem joias e ...</td>\n",
              "      <td>Um  texto  pertencente  ao  patrimônio  literá...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>100</td>\n",
              "      <td>No</td>\n",
              "      <td>A</td>\n",
              "      <td>2011-2_100</td>\n",
              "      <td>C</td>\n",
              "      <td>da maldade do povo a perguntar sobre a honesti...</td>\n",
              "      <td>TEXTO IVocê tem palacete reluzenteTem joias e ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7327</th>\n",
              "      <td>296</td>\n",
              "      <td>2010-2</td>\n",
              "      <td>“Todas  as  manhãs  quando  acordo,  experimen...</td>\n",
              "      <td>Assim  escreveu  o  pintor  dos  “relógios  mo...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>123</td>\n",
              "      <td>No</td>\n",
              "      <td>B</td>\n",
              "      <td>2010-2_123</td>\n",
              "      <td>B</td>\n",
              "      <td>do  onírico,  que  misturava  sonho  com  real...</td>\n",
              "      <td>“Todas  as  manhãs  quando  acordo,  experimen...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7328 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49816c04-c9ee-4a5a-aa84-95c6e60d5711')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49816c04-c9ee-4a5a-aa84-95c6e60d5711 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49816c04-c9ee-4a5a-aa84-95c6e60d5711');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      ...1 enem_version                                             header  \\\n",
              "0      972       2014-2  A última edição deste periódico apresenta mais...   \n",
              "1      925       2014-1  Na  década  de  1940,  na  Região  Centro-Oest...   \n",
              "2      483       2011-2  O que é possível dizer em 140 caracteres?Suces...   \n",
              "3     1464    2016_2_-1  Até 1824 acreditava-se que as máquinas térmica...   \n",
              "4     1452    2016_2_-1  Um  jovem  suspeita  que  não  é  filho  bioló...   \n",
              "...    ...          ...                                                ...   \n",
              "7323  1590       2017-1  Quer suporte paraencontrar pessoasque comparti...   \n",
              "7324   783       2013-1  Estudos  de  fluxo  de  energia  em  ecossiste...   \n",
              "7325   899       2014-1  Estatuto da Frente Negra Brasileira (FNB)Art. ...   \n",
              "7326   448       2011-2  TEXTO IVocê tem palacete reluzenteTem joias e ...   \n",
              "7327   296       2010-2  “Todas  as  manhãs  quando  acordo,  experimen...   \n",
              "\n",
              "                                              statement  CE   DS   EK  IC  MR  \\\n",
              "0     Esse editorial faz uma leitura diferenciada de...  No   No   No  No  No   \n",
              "1     Para suprir o déficit nutricional a que os pro...  No  Yes  Yes  No  No   \n",
              "2     O Twitter se presta a diversas finalidades, en...  No   No  Yes  No  No   \n",
              "3            Tal limitação ocorre porque essas máquinas  No   No  Yes  No  No   \n",
              "4     A  condição  genotípica  que  possibilita  que...  No  Yes   No  No  No   \n",
              "...                                                 ...  ..  ...  ...  ..  ..   \n",
              "7323  O  consumidor  do  século  XXI,  chamado  de  ...  No   No   No  No  No   \n",
              "7324  Dos grupos de seres vivos citados, os que cont...  No  Yes   No  No  No   \n",
              "7325  Quando  foi  fechada  pela  ditadura  do  Esta...  No   No  Yes  No  No   \n",
              "7326  Um  texto  pertencente  ao  patrimônio  literá...  No   No   No  No  No   \n",
              "7327  Assim  escreveu  o  pintor  dos  “relógios  mo...  No   No  Yes  No  No   \n",
              "\n",
              "       TC   id image gab   question_id opcao  \\\n",
              "0     Yes   99    No   D     2014-2_99     D   \n",
              "1     Yes   47    No   D     2014-1_47     D   \n",
              "2     Yes  135    No   E    2011-2_135     B   \n",
              "3     Yes   61    No   B  2016_2_-1_61     C   \n",
              "4     Yes   47    No   A  2016_2_-1_47     A   \n",
              "...   ...  ...   ...  ..           ...   ...   \n",
              "7323  Yes   17   Yes   A     2017-1_17     B   \n",
              "7324   No   80    No   B     2013-1_80     D   \n",
              "7325  Yes   21    No   A     2014-1_21     A   \n",
              "7326  Yes  100    No   A    2011-2_100     C   \n",
              "7327   No  123    No   B    2010-2_123     B   \n",
              "\n",
              "                                             opcao_text  \\\n",
              "0     interpretar criticamente fatos noticiados e co...   \n",
              "1                               aminoácidos essenciais.   \n",
              "2     constitui recurso próprio para a aquisição da ...   \n",
              "3                  utilizam transformações adiabáticas.   \n",
              "4     o  pai  e  a  mãe  sejam  heterozigotos  para ...   \n",
              "...                                                 ...   \n",
              "7323                  busca constante pelo menor preço.   \n",
              "7324                                           insetos.   \n",
              "7325  política, engajada na luta por direitos sociai...   \n",
              "7326  da maldade do povo a perguntar sobre a honesti...   \n",
              "7327  do  onírico,  que  misturava  sonho  com  real...   \n",
              "\n",
              "                                                   text  label  train_test  \n",
              "0     A última edição deste periódico apresenta mais...      1           1  \n",
              "1     Na  década  de  1940,  na  Região  Centro-Oest...      1           1  \n",
              "2     O que é possível dizer em 140 caracteres?Suces...      0           1  \n",
              "3     Até 1824 acreditava-se que as máquinas térmica...      0           0  \n",
              "4     Um  jovem  suspeita  que  não  é  filho  bioló...      1           1  \n",
              "...                                                 ...    ...         ...  \n",
              "7323  Quer suporte paraencontrar pessoasque comparti...      0           0  \n",
              "7324  Estudos  de  fluxo  de  energia  em  ecossiste...      0           1  \n",
              "7325  Estatuto da Frente Negra Brasileira (FNB)Art. ...      1           1  \n",
              "7326  TEXTO IVocê tem palacete reluzenteTem joias e ...      0           1  \n",
              "7327  “Todas  as  manhãs  quando  acordo,  experimen...      1           1  \n",
              "\n",
              "[7328 rows x 19 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bd_enem_long = pd.read_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_enem/data_enem_long.csv\") \n",
        "bd_enem_long['text'][0]\n",
        "\n",
        "bd_enem_long = bd_enem_long.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "bd_enem_long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BnJgAiPrkYS"
      },
      "outputs": [],
      "source": [
        "df_train = bd_enem_long.query('train_test ==1')[['text', 'label']]\n",
        "df_train.columns = ['sentence', 'label'] \n",
        "\n",
        "df_test = bd_enem_long.query('train_test ==0')[['text', 'label']]\n",
        "df_test.columns = ['sentence', 'label'] \n",
        "\n",
        "df_train[\"context_size\"] = df_train[\"sentence\"].apply(lambda x: len(x.split(\" \")))\n",
        "df_test[\"context_size\"] = df_test[\"sentence\"].apply(lambda x: len(x.split(\" \")))\n",
        "\n",
        "df_train = df_train.query('context_size <=510')[['sentence', 'label']] \n",
        "df_test = df_test.query('context_size <=510')[['sentence', 'label']] \n",
        "\n",
        "df_train.to_csv('df_train.csv', index=None)\n",
        "df_test.to_csv('df_test.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhj52mqEyWTO",
        "outputId": "1179a5d7-e704-4d40-b4ce-19cf0a183921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence,label\n",
            "\"A última edição deste periódico apresenta mais uma vez  tema relacionado ao tratamento dado ao lixo caseiro, aquele que produzimos no dia a dia. A informação agora passa pelo problema do material jogado na estrada vicinal que  liga  o  município  de  Rio  Claro  ao  distrito  de  Ajapi. Infelizmente, no local em questão, a reportagem encontrou mais  uma  forma  errada  de  destinação  do  lixo:  material atirado ao lado da pista como se  isso fosse o ideal. Muitos moradores, por exemplo, retiram o lixo de suas residências e,  em  vez  de  um  destino  correto,  procuram  dispensá-lo em outras regiões. Uma situação no mínimo incômoda. Se você sai de casa para jogar o lixo em outra localidade, por que não o fazer no local ideal? É muita falta de educação achar que aquilo que não é correto para sua região possa ser para outra. A reciclagem do lixo doméstico é um passo inteligente e de consciência. Olha o exemplo que passamos aos mais jovens! Quem aprende errado coloca em prática o errado. Um perigo!Disponível em: http://jornaldacidade.uol.com.br. Acesso em: 10 ago. 2012 (adaptado). Esse editorial faz uma leitura diferenciada de uma notícia veiculada  no  jornal.  Tal  diferença  traz  à  tona  uma  das funções sociais desse gênero textual, que é [SEP] interpretar criticamente fatos noticiados e considerados relevantes para a opinião pública.\",1\n",
            "\"Na  década  de  1940,  na  Região  Centro-Oeste, produtores  rurais,  cujos  bois,  porcos,  aves  e  cabras estavam morrendo por uma peste desconhecida, fizeram uma  promessa,  que  consistiu  em  não  comer  carne  e derivados até que a peste fosse debelada. Assim, durante três meses, arroz, feijão, verduras e legumes formaram o prato principal desses produtores. O Hoje, 15 out. 2011 (adaptado). Para suprir o déficit nutricional a que os produtores rurais se  submeteram  durante  o  período  da  promessa,  foi importante eles terem consumido alimentos ricos em [SEP] aminoácidos essenciais.\",1\n",
            "\"O que é possível dizer em 140 caracteres?Sucesso do Twitter no Brasil é oportunidade única de compreender a importância da concisão nos gêneros de escritaA máxima “menos é mais” nunca fez tanto sentido como no caso do microblog Twitter, cuja premissa é dizer algo — não importa o quê — em 140 caracteres. Desde que o serviço foi criado, em 2006, o número de usuários da ferramenta é cada vez maior, assim como a diversidade de uso que se faz dela. Do estilo “querido diário” àliteratura concisa, passando por aforismos, citações, jornalismo, fofoca, humor etc., tudo ganha o espaço de um tweet (“pio” em inglês), e entender seu sucesso pode indicar um caminho para o aprimoramento de um recurso vitalà escrita: a concisão. Disponível em: http://www.revistalingua.com.br. Acesso em: 28 abr. 2010 (adaptado). O Twitter se presta a diversas finalidades, entre elas, à comunicação concisa, por isso essa rede social [SEP] constitui recurso próprio para a aquisição da modalidade escrita da língua.\",0\n",
            "\"Um  jovem  suspeita  que  não  é  filho  biológico  de seus pais, pois descobriu que o seu tipo sanguíneo é O Rh negativo,  o  de  sua  mãe  é  B  Rh  positivo  e  de seu pai é A Rh positivo. A  condição  genotípica  que  possibilita  que  ele  seja realmente filho biológico de seus pais é que [SEP] o  pai  e  a  mãe  sejam  heterozigotos  para  o  sistema sanguíneo ABO e para o fator Rh.\",1\n",
            "\"Pesquisadores criaram um tipo de plaqueta artificial, feita com um polímero gelatinoso coberto de anticorpos, que promete agilizar o processo de coagulação quando injetada  no  corpo.  Se  houver  sangramento,  esses anticorpos  fazem  com  que  a  plaqueta  mude  sua  forma e se transforme em uma espécie de rede que gruda nas lesões dos vasos sanguíneos e da pele.MOUTINHO, S. Coagulação acelerada. Disponível em: http://cienciahoje.uol.com.br. Acesso em: 19 fev. 2013 (adaptado). Qual  a  doença  cujos  pacientes  teriam  melhora  de  seu estado de saúde com o uso desse material? [SEP] Hemofilia.\",1\n",
            "\"A elevação da temperatura das águas de rios, lagos e  mares  diminui  a  solubilidade  do oxigênio,  pondo  em risco as diversas formas de vida aquática que dependem desse  gás.  Se  essa  elevação  de  temperatura  acontece por meios artificiais, dizemos que existe poluição térmica. As usinas nucleares, pela própria natureza do processo de geração de energia, podem causar esse tipo de poluição. Que  parte  do  ciclo  de  geração  de  energia  das  usinas nucleares está associada a esse tipo de poluição? [SEP] Condensação do vapor-d'água no final do processo.\",1\n",
            "\"No caprichoO  Adãozinho,  meu  cumpade,  enquanto  esperava pelo  delegado,  olhava  para  um  quadro,  a  pintura  de uma senhora. Ao entrar a autoridade e percebendo que o cabôco admirava tal figura, perguntou: “Que tal? Gosta desse quadro?”E o Adãozinho, com toda a sinceridade que Deus dá ao cabôco da roça: “Mas pelo amor de Deus, hein, dotô! Que muié feia! Parece fiote de cruis-credo, parente dodeus-me-livre, mais horríver que briga de cego no escuro.” Ao  que  o  delegado  não  teve  como  deixar  de confessar, um pouco secamente: “É a minha mãe.” E o cabôco, em cima da bucha, não perde a linha: “Mais dotô, inté que é uma feiura caprichada.” BOLDRIN, R. Almanaque Brasil de Cultura Popular. São Paulo: Andreato Comunicação e Cultura, nº 62, 2004 (adaptado). Por suas características formais, por sua função e uso, o texto pertence ao gênero [SEP] anedota, pelo enredo e humor característicos.\",1\n",
            "\"A África também já serviu como ponto de partida para comédias bem vulgares, mas de muito sucesso, como Um príncipe em Nova York e Ace Ventura: um maluco  na  África;  em  ambas,  a  África  parece  um lugar  cheio  de  tribos  doidas  e  rituais  de  desenho animado. A animação O rei Leão, da Disney, o mais bem-sucedido filme americano ambientado na África, não chegava a contar com elenco de seres humanos.LEIBOWITZ, E. Filmes de Hollywood sobre África ficam no clichê. Disponível em: http://notícias.uol.com.br. Acesso em: 17 abr. 2010. A  produção  cinematográfica referida  no texto contribui para a constituição de uma memória sobre a África e seus habitantes. Essa memória enfatiza e negligencia, respectivamente, os seguintes aspectos do continente africano: [SEP] O exotismo e as culturas.\",1\n",
            "\"TEXTO IOs  problemas  ambientais  são  consequência  direta da  intervenção  humana  nos  diferentes  ecossistemas da  Terra,  causando  desequilíbrios  no  meio  ambiente  e comprometendo a qualidade de vida.TEXTO IIDisponível em: www.repository.utl.pt. Acesso em: 29 jul. 2012.Disponível em: www.netuno.eco.br. Acesso em: 29 jul. 2012. As  imagens  representam  as  geleiras  da  Groenlândia, que sofreram e sofrem impactos, resultantes do(a) [SEP] ilha de calor.\",0\n"
          ]
        }
      ],
      "source": [
        "!head df_train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "d6e434c3bc1c457aa7c65510ea632082",
            "ceae0f3203a14caab5447c741912c938",
            "aaadc4e445714eab9b97d4d1eabe387a",
            "5566b4e3050e433c9e598f4f57c5f9fa",
            "db66845e31574a96aa2530c7e37aeeb4",
            "0bbcc1127c2a416e9566346b0fc652fb"
          ]
        },
        "id": "8NRk5g68rtZM",
        "outputId": "a822d7c8-31e3-433f-fb96-5326792df868"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-1e157addff2c278c\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-1e157addff2c278c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6e434c3bc1c457aa7c65510ea632082",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ceae0f3203a14caab5447c741912c938",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files #0:   0%|          | 0/1 [00:00<?, ?obj/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaadc4e445714eab9b97d4d1eabe387a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files #1:   0%|          | 0/1 [00:00<?, ?obj/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5566b4e3050e433c9e598f4f57c5f9fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db66845e31574a96aa2530c7e37aeeb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-1e157addff2c278c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bbcc1127c2a416e9566346b0fc652fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 5850\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 1456\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_dataset = load_dataset(\n",
        "    'csv',\n",
        "     data_files={'train': 'df_train.csv',\n",
        "                 'test': 'df_test.csv'\n",
        "     }\n",
        " )\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "6347fca956cf427dbd822d8d6d700608",
            "a3475c6b2d8945a0899ee0f5d591f54d"
          ]
        },
        "id": "rraWlMjDymUP",
        "outputId": "8fb4b8c6-296b-4513-f5ed-b1110be9b98f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6347fca956cf427dbd822d8d6d700608",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3475c6b2d8945a0899ee0f5d591f54d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "checkpoint = 'neuralmind/bert-base-portuguese-cased'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint,do_lower_case=False)\n",
        "\n",
        "context_length =  510 # 512 - [CLS] [SEP]\n",
        "\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "  return tokenizer(batch['sentence'], truncation=True, max_length=context_length)\n",
        "  \n",
        "tokenized_datasets = raw_dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint, num_labels=2)\n",
        "\n",
        "\n",
        "#tokenized_datasets\n",
        "#df = pd.DataFrame(tokenized_datasets['test'])\n",
        "#df['context_size'] = df['input_ids'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg4vuz3ty-mt",
        "outputId": "7b37d236-2a51-4fcf-b255-d39fca0a9443"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "BertForSequenceClassification                           --\n",
              "├─BertModel: 1-1                                        --\n",
              "│    └─BertEmbeddings: 2-1                              --\n",
              "│    │    └─Embedding: 3-1                              22,881,792\n",
              "│    │    └─Embedding: 3-2                              393,216\n",
              "│    │    └─Embedding: 3-3                              1,536\n",
              "│    │    └─LayerNorm: 3-4                              1,536\n",
              "│    │    └─Dropout: 3-5                                --\n",
              "│    └─BertEncoder: 2-2                                 --\n",
              "│    │    └─ModuleList: 3-6                             85,054,464\n",
              "│    └─BertPooler: 2-3                                  --\n",
              "│    │    └─Linear: 3-7                                 590,592\n",
              "│    │    └─Tanh: 3-8                                   --\n",
              "├─Dropout: 1-2                                          --\n",
              "├─Linear: 1-3                                           1,538\n",
              "================================================================================\n",
              "Total params: 108,924,674\n",
              "Trainable params: 108,924,674\n",
              "Non-trainable params: 0\n",
              "================================================================================"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwbaIWPfzeYk"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "  output_dir='training_dir',\n",
        "  evaluation_strategy='epoch',\n",
        "  save_strategy='epoch',\n",
        "  num_train_epochs=3,\n",
        "  per_device_train_batch_size=16,\n",
        "  per_device_eval_batch_size=64,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX5pN9nXzhD5"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(logits_and_labels):\n",
        "  logits, labels = logits_and_labels\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  acc = np.mean(predictions == labels)\n",
        "  f1 = f1_score(labels, predictions, average='micro')\n",
        "  return {'accuracy': acc, 'f1': f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GngErum_zkTJ"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Obdscin0GQO"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oZ44aon0Dd5"
      },
      "outputs": [],
      "source": [
        "!ls training_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f-wIOhfzs_L"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint,do_lower_case=False)\n",
        "\n",
        "context_length =  510 # 512 - [CLS] [SEP]\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "  return tokenizer(batch['sentence'], truncation=True, max_length=context_length)\n",
        "  \n",
        "tokenized_datasets = raw_dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "savedmodel  = pipeline(\n",
        "    task='text-classification',\n",
        "    model='training_dir/checkpoint-1098', \n",
        "    tokenizer=tokenizer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcOafipgzkZ8"
      },
      "outputs": [],
      "source": [
        "test_pred = savedmodel(tokenized_datasets['test']['sentence'], truncation=True, max_length=context_length)\n",
        "\n",
        "#savedmodel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHnIM5PuRlGa"
      },
      "outputs": [],
      "source": [
        "def get_label(d):\n",
        "  return int(d['label'].split('_')[1])\n",
        "\n",
        "test_pred2 = [get_label(d) for d in test_pred]\n",
        "\n",
        "print(\"acc:\", accuracy_score(raw_dataset['test']['label'], test_pred2))\n",
        "print(\"f1:\", f1_score(raw_dataset['test']['label'], test_pred2, average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OM9W1vzSTxW"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn is transitioning to V1 but it's not available on Colab\n",
        "# The changes modify how confusion matrices are plotted\n",
        "def plot_cm(cm):\n",
        "  classes = ['0', '1']\n",
        "  df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
        "  ax = sn.heatmap(df_cm, annot=True, fmt='g')\n",
        "  ax.set_xlabel(\"Predicted\")\n",
        "  ax.set_ylabel(\"Target\")\n",
        "\n",
        "cm = confusion_matrix(tokenized_datasets['test']['label'], test_pred2, normalize='true')\n",
        "plot_cm(cm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOeyJHvvgmi2"
      },
      "outputs": [],
      "source": [
        "type(test_pred)\n",
        "\n",
        "test_results_bertimbau_base =  pd.DataFrame( test_pred)\n",
        "test_results_bertimbau_base[\"true_label\"] = tokenized_datasets['test']['label']\n",
        "\n",
        "test_results_bertimbau_base.head()\n",
        "\n",
        "test_results_bertimbau_base.to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_enem/test_results_bertimbau_base.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb27306e8f4045e6892b363e5601921a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b28e9e8c4d234a76b02be0063072f4fb",
              "IPY_MODEL_8bb8297e19bd49e5b1c211a71d8fb978",
              "IPY_MODEL_afe5b13132e9458ab3f6619165122be9"
            ],
            "layout": "IPY_MODEL_b646376fb3654b4cb4cf588f0cde7b44"
          }
        },
        "b28e9e8c4d234a76b02be0063072f4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90937e682abf42efa5eca89b9a13f5e2",
            "placeholder": "​",
            "style": "IPY_MODEL_e6cab4f9c4654b5d9759e706bcccafab",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "8bb8297e19bd49e5b1c211a71d8fb978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc36f4504f0b43c98d1c92b9d7aca71b",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f621995884a3434491b374f6388f621a",
            "value": 647
          }
        },
        "afe5b13132e9458ab3f6619165122be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065642e84f8f4b0dae0606379b3fb32a",
            "placeholder": "​",
            "style": "IPY_MODEL_e243d695f2424d87b70af1bdc63a50a5",
            "value": " 647/647 [00:00&lt;00:00, 14.1kB/s]"
          }
        },
        "b646376fb3654b4cb4cf588f0cde7b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90937e682abf42efa5eca89b9a13f5e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6cab4f9c4654b5d9759e706bcccafab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc36f4504f0b43c98d1c92b9d7aca71b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f621995884a3434491b374f6388f621a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "065642e84f8f4b0dae0606379b3fb32a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e243d695f2424d87b70af1bdc63a50a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cfaf560bac043ee842f5e3e19e3528c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f7ad21569014aa9911bc5a9cd5ac619",
              "IPY_MODEL_2a7b77d0bc5d422d961230bb2b6d64ba",
              "IPY_MODEL_1a74d7070fd8496990f13095d384e866"
            ],
            "layout": "IPY_MODEL_929d0753f9fd4f4185ab3d19a9452070"
          }
        },
        "2f7ad21569014aa9911bc5a9cd5ac619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a64ca82a7f048dda3b2aec0c4da2b1e",
            "placeholder": "​",
            "style": "IPY_MODEL_8955a4ed74b34454bf9eeab583260389",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "2a7b77d0bc5d422d961230bb2b6d64ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a76ddf04c6645c5bf16a555d1113239",
            "max": 438235074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da5bee844381412b9c96dafc333e0f65",
            "value": 438235074
          }
        },
        "1a74d7070fd8496990f13095d384e866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e3efb783824bc0a63b2fa242ad0399",
            "placeholder": "​",
            "style": "IPY_MODEL_bc5390fc195e4f998c7e7b2ddf0dc1fb",
            "value": " 438M/438M [00:02&lt;00:00, 188MB/s]"
          }
        },
        "929d0753f9fd4f4185ab3d19a9452070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a64ca82a7f048dda3b2aec0c4da2b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8955a4ed74b34454bf9eeab583260389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a76ddf04c6645c5bf16a555d1113239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da5bee844381412b9c96dafc333e0f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98e3efb783824bc0a63b2fa242ad0399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5390fc195e4f998c7e7b2ddf0dc1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cab87a16d2cc44b4a1ab37b4941e3bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cff9caa851c41e6a7c5d579dcba3426",
              "IPY_MODEL_4d28f433297649b8b483c3d26e683566",
              "IPY_MODEL_3906192cfc624400aa5fa0d0154ff8d6"
            ],
            "layout": "IPY_MODEL_cadd01cddf824d1fb95fb5e9f1ef34d7"
          }
        },
        "9cff9caa851c41e6a7c5d579dcba3426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b28c6f77aa4fb68f70c23c148926e6",
            "placeholder": "​",
            "style": "IPY_MODEL_c9dde88d906c4dce9b7bc9fa22c474d7",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "4d28f433297649b8b483c3d26e683566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d136816c2fd4b0faf4b934780fb2ca4",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a8aa4ecc171490cbf39615f76a377a2",
            "value": 43
          }
        },
        "3906192cfc624400aa5fa0d0154ff8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d44b65ada86444f18922a8c7e5edeab3",
            "placeholder": "​",
            "style": "IPY_MODEL_17c995187b2b45fc969cc1b8bcccbe5e",
            "value": " 43.0/43.0 [00:00&lt;00:00, 647B/s]"
          }
        },
        "cadd01cddf824d1fb95fb5e9f1ef34d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b28c6f77aa4fb68f70c23c148926e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9dde88d906c4dce9b7bc9fa22c474d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d136816c2fd4b0faf4b934780fb2ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8aa4ecc171490cbf39615f76a377a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d44b65ada86444f18922a8c7e5edeab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c995187b2b45fc969cc1b8bcccbe5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ae7699cfa9d4cdba7ec026d5d045ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0fbe88c9acd4729813b53af70d2b16f",
              "IPY_MODEL_e5899dd43cd047debe8d9d05c7689326",
              "IPY_MODEL_5be5d0a44e1641b3a65c55276de0e348"
            ],
            "layout": "IPY_MODEL_3cb5a6a5e94b451f9e9e0ec61727d41b"
          }
        },
        "f0fbe88c9acd4729813b53af70d2b16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_683ef738a5a2448da31aba165e50183a",
            "placeholder": "​",
            "style": "IPY_MODEL_a761cd596ebd417cb90542e72d3c9d0d",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "e5899dd43cd047debe8d9d05c7689326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9853673e032c40e28b940c964ac52fb5",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cbe32b4dc33422c8c87c035f7cd339a",
            "value": 209528
          }
        },
        "5be5d0a44e1641b3a65c55276de0e348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41b70a985be34a2792ccad4cb16e2df5",
            "placeholder": "​",
            "style": "IPY_MODEL_1ba9f528fea743b587368c9fd5603352",
            "value": " 210k/210k [00:00&lt;00:00, 706kB/s]"
          }
        },
        "3cb5a6a5e94b451f9e9e0ec61727d41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "683ef738a5a2448da31aba165e50183a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a761cd596ebd417cb90542e72d3c9d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9853673e032c40e28b940c964ac52fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cbe32b4dc33422c8c87c035f7cd339a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41b70a985be34a2792ccad4cb16e2df5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba9f528fea743b587368c9fd5603352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72a9b9258360486983d94214e654d8cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47648135613d4fee811510b6e36f6a2f",
              "IPY_MODEL_75b007adbf9a42fbbb9ddb9df34a7ba0",
              "IPY_MODEL_7350153aa8d44838863af90dc64ac8be"
            ],
            "layout": "IPY_MODEL_f9523f41c3fe4cf0b8eae100e0659e3c"
          }
        },
        "47648135613d4fee811510b6e36f6a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e24b4cfa9504a008bd9326207bd7520",
            "placeholder": "​",
            "style": "IPY_MODEL_e14be2e83fae4b71abd9d986a5099a6c",
            "value": "Downloading (…)in/added_tokens.json: 100%"
          }
        },
        "75b007adbf9a42fbbb9ddb9df34a7ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52848dd55d26413c9a5b61540f179621",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baede60fa3e74106925f0b76366838e0",
            "value": 2
          }
        },
        "7350153aa8d44838863af90dc64ac8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bdce323583040b3a3d57b1ed5d33f3c",
            "placeholder": "​",
            "style": "IPY_MODEL_3aaf57fa50eb4d2bba9e33fc63df46bc",
            "value": " 2.00/2.00 [00:00&lt;00:00, 58.3B/s]"
          }
        },
        "f9523f41c3fe4cf0b8eae100e0659e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e24b4cfa9504a008bd9326207bd7520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e14be2e83fae4b71abd9d986a5099a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52848dd55d26413c9a5b61540f179621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baede60fa3e74106925f0b76366838e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bdce323583040b3a3d57b1ed5d33f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aaf57fa50eb4d2bba9e33fc63df46bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "782595678e534938806bd68d139ddb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_510e52311bd042778c0889a6778303e5",
              "IPY_MODEL_8d2fb381b7964525812cc927fb24612a",
              "IPY_MODEL_112681987e034363adc44ebd6b1e978a"
            ],
            "layout": "IPY_MODEL_72e1e5a56ea44f2f8ddb9fdaa3e3fb51"
          }
        },
        "510e52311bd042778c0889a6778303e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b65db33ef46e4ebcab3f4325d1ab525e",
            "placeholder": "​",
            "style": "IPY_MODEL_4422bbca32bb4027b26a41fbb9fac831",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "8d2fb381b7964525812cc927fb24612a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4995ea22efdb4e7199c648438bb96bdc",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_262977a647f9445aa08fd3e99a215ab2",
            "value": 112
          }
        },
        "112681987e034363adc44ebd6b1e978a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ae4a6c591f4adfb02687c82ce19e98",
            "placeholder": "​",
            "style": "IPY_MODEL_86bd839a8e66445aa7925fcefc168073",
            "value": " 112/112 [00:00&lt;00:00, 2.14kB/s]"
          }
        },
        "72e1e5a56ea44f2f8ddb9fdaa3e3fb51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65db33ef46e4ebcab3f4325d1ab525e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4422bbca32bb4027b26a41fbb9fac831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4995ea22efdb4e7199c648438bb96bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "262977a647f9445aa08fd3e99a215ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5ae4a6c591f4adfb02687c82ce19e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bd839a8e66445aa7925fcefc168073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
